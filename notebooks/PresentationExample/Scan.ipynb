{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is the second in a series of notebooks illustrating how to interface a model to Certifai, run a scan and perform some simple analyses\n",
    "\n",
    "## Part 2 - Run a Certifai scan\n",
    "In this notebook we'll set up a scan to run fairness and explanation analyses of the two models we created in Part 1.\n",
    "\n",
    "First we'll reload those trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models.pkl', 'rb') as f:\n",
    "    model_dict = pickle.load(f)\n",
    "\n",
    "logistic_model = model_dict['logistic']\n",
    "dtree_model = model_dict['dtree']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Certifai scan\n",
    "\n",
    "In this cell we define the details of the scan we want to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue,\n",
    "                                      CertifaiFeatureRestriction)\n",
    "\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')\n",
    "\n",
    "scan = CertifaiScanBuilder.create('German_credit_use_case',\n",
    "                                  prediction_task=task)\n",
    "\n",
    "# We want to get explanations\n",
    "scan.add_evaluation_type('explanation')\n",
    "\n",
    "# We also want to look at fairness with respect to a couple of features - 'age' and 'status'\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "\n",
    "# We'll also tell Certifai to consider the 'age' and 'status' features to be fixed since\n",
    "# an individual cannot really intervene on them, so when presenting an explanation to the\n",
    "# target individual it's typically more useful to couch it in terms of mutable features.  Whether\n",
    "# this is appropriate for a particular use case is down to the purpose for which explanation is sought\n",
    "# A data scientist wishing to understand the model behavior in full generality would probably not want\n",
    "# to impose such restrictions\n",
    "scan.add_feature_restriction('status', CertifaiFeatureRestriction.constant())\n",
    "scan.add_feature_restriction('age', CertifaiFeatureRestriction.constant())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the datasets to use\n",
    "Here we tell Certifai what datasets to run the scans against.  We can specify files or pe-loaded Pandas DataFrames.  Here we'll use the raw CSV files we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll just use the full composite of the train/test split we used earlier, but thi could be any dataset\n",
    "# conforming to the same schema\n",
    "base_path = '..'\n",
    "all_data_file = f\"{base_path}/datasets/german_credit_eval.csv\"\n",
    "\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(all_data_file))\n",
    "scan.add_dataset(eval_dataset)\n",
    "\n",
    "# Because the dataset contains a ground truth outcome column which the model does not\n",
    "# expect to receive as input we need to state that in the dataset schema (since it cannot\n",
    "# be inferred from the CSV)\n",
    "scan.dataset_schema.outcome_feature_name = 'outcome'\n",
    "\n",
    "# The fairness scan uses the general 'evaluation' dataset\n",
    "scan.evaluation_dataset_id = 'evaluation'\n",
    "\n",
    "# Explanations scans use a separately specified 'explanation' dataset, typically because you don't necessarily\n",
    "# want individual explanations for all your data, but more typically specific examples.  However, here we'll just\n",
    "# explain everything and use the dataet we already connected to\n",
    "scan.explanation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach the models to the scan\n",
    "We finally need to define what models we are scanning, so here we attach the models we loaded earlier\n",
    "to the scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.add_model(CertifaiModel('logistic',\n",
    "                             local_predictor=CertifaiPredictorWrapper(logistic_model)))\n",
    "scan.add_model(CertifaiModel('dtree',\n",
    "                             local_predictor=CertifaiPredictorWrapper(dtree_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the scan\n",
    "Now we'll run the scan, and save the results in a scan report that can be read eitehr by the Certifai Console\n",
    "or by subsequent notebooks in this series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scan with model_use_case_id: 'German_credit_use_case' and scan_id: '75f0bc41147b'\n",
      "[--------------------] 2021-02-23 11:22:54.365713 - 0 of 4 reports (0.0% complete) - Running explanation evaluation for model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 11:30:15,859 root   WARNING  Insufficient examples of some fairness classes to guarantee convergence (smallest class size is for status='male : divorced/separated' with 50 samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#####---------------] 2021-02-23 11:30:15.848860 - 1 of 4 reports (25.0% complete) - Running fairness evaluation for model: logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 11:30:49,005 root   WARNING  Examples of protected class ('status', 'male : divorced/separated') exhausted before convergence after 50 samples\n",
      "2021-02-23 11:31:01,605 root   WARNING  Examples of protected class ('status', 'male : married/widowed') exhausted before convergence after 92 samples\n",
      "2021-02-23 11:31:28,027 root   WARNING  Examples of protected class ('age', '<= 25 years') exhausted before convergence after 190 samples\n",
      "2021-02-23 11:31:54,172 root   WARNING  Examples of protected class ('status', 'female : divorced/separated/married') exhausted before convergence after 310 samples\n",
      "2021-02-23 11:31:57,654 root   WARNING  Examples of protected class ('age', '> 25 years') exhausted before convergence after 810 samples\n",
      "2021-02-23 11:31:57,655 root   WARNING  Examples of protected class ('status', 'male : single') exhausted before convergence after 548 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########----------] 2021-02-23 11:32:06.376394 - 2 of 4 reports (50.0% complete) - Running explanation evaluation for model: dtree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 11:37:12,449 root   WARNING  Insufficient examples of some fairness classes to guarantee convergence (smallest class size is for status='male : divorced/separated' with 50 samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[###############-----] 2021-02-23 11:37:12.435667 - 3 of 4 reports (75.0% complete) - Running fairness evaluation for model: dtree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 11:37:48,373 root   WARNING  Examples of protected class ('status', 'male : divorced/separated') exhausted before convergence after 50 samples\n",
      "2021-02-23 11:37:57,586 root   WARNING  Examples of protected class ('status', 'male : married/widowed') exhausted before convergence after 92 samples\n",
      "2021-02-23 11:38:16,181 root   WARNING  Examples of protected class ('age', '<= 25 years') exhausted before convergence after 190 samples\n",
      "2021-02-23 11:38:33,969 root   WARNING  Examples of protected class ('status', 'female : divorced/separated/married') exhausted before convergence after 310 samples\n",
      "2021-02-23 11:38:45,619 root   WARNING  Examples of protected class ('age', '> 25 years') exhausted before convergence after 810 samples\n",
      "2021-02-23 11:38:45,620 root   WARNING  Examples of protected class ('status', 'male : single') exhausted before convergence after 548 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################] 2021-02-23 11:38:53.810463 - 4 of 4 reports (100.0% complete) - Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "_ = scan.run(write_reports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
