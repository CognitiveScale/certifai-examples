{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Certifai Pro scans on Azure ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENTS\n",
    "\n",
    "1. First we'll understand how to install Certifai Pro and its setup in an Azure cloud environment. Setup process includes configuring your Certifai Pro instance with storage parameters for a pre-existing container in an Azure Storage Account\n",
    "\n",
    "2. We will then install the required Certifai Toolkit python libraries so scans that generate information about the fairness, robustness and explainability of your ML models can be evaluated with the [CERTIFAI framework](https://cognitivescale.github.io/cortex-certifai/docs/about)\n",
    "\n",
    "3. Then, we will create sklearn models to classify [german credit loan risk](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) (predict whether loan will be granted or not)\n",
    "\n",
    "4. Register our model and deploy it as a webservice in ACI (AZURE CONTAINER INSTANCE) with authentication\n",
    "\n",
    "5. Test the deployed webservice\n",
    "\n",
    "6. Construct Certifai Scan Definitions for this Binary Classification model\n",
    "\n",
    "7. Upload the required datasets for the scan into the Azure Storage Account container used to configure Certifai Pro on Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prereqs'> - Certifai Pro\n",
    "\n",
    "Cortex Certifai Pro is a cloud based offering from [CognitiveScale](https://www.cognitivescale.com/certifai/) that allows data scientists to define, scan and analyse their models to determine their Fairness, Robustness and Explainability measures using the [CERTIFAI framework](https://arxiv.org/abs/1905.07857). \n",
    "\n",
    "You can find more details about Certifai on the [official documentation site](https://cognitivescale.github.io/cortex-certifai/docs/about).\n",
    "\n",
    "This tutorial helps users that use **Azure Machine Learning resources (Hosted Notebooks/Models/Endpoints)** to setup their model and ready it for scanning with Certifai Pro.\n",
    "\n",
    "Certifai Pro is a single user, VM installed version of Cortex Certifai that runs on an Azure VM and can be installed from the [Azure Marketplace](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cognitive-scale.cortex-certifai-pro). Certifai Pro VMs can run scans on your own models with the aid of the Certifai Toolkit, a downloadable set of Python packages and CLI tools that can run Certifai scans on your personal machines. The toolkit also enables you to connect to and run scans remotely on the Certifai Pro VM. You can find more details about the [Certifai Toolkit](https://cognitivescale.github.io/cortex-certifai/docs/toolkit/setup/download-toolkit)\n",
    "\n",
    "This guide walks you through using the Certifai Python API to help define Scan Definitions that can be passed on to the Certifai Pro instance along with Datasets and Secrets needed, if any\n",
    "be covered separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Install Certifai Pro from the Azure Marketplace\n",
    "\n",
    "You can find and create a personal instance of Cortex Certifai Pro from the [Azure Marketplace](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cognitive-scale.cortex-certifai-pro). Please follow the instructions from the official [Certifai docs](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup) for the Azure platform to get up and running.\n",
    "\n",
    "A brief summary of this process includes:\n",
    "- Certifai Pro instance setup from the Marketplace and initial authentication workflows\n",
    "- Configure your Certifai Pro instance with blob storage containers and credentials for an Azure Storage account of your choice.\n",
    "    - You may also install sample reports for a variety of usecases in Finance, Healthcare and Insurance to understand how the AI Trust Index scores generated by Certifai, accompanied by the extraordinarily helpful reports on Fairness, Robustness and Explainability can be used to improve your machine learning models\n",
    "- Configure Custom SSL certificates (if needed)\n",
    "\n",
    "So, please go ahead to the Azure Marketplace listing for [Cortex Certifai Pro](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cognitive-scale.cortex-certifai-pro) and setup your instance of Certifai Pro and head back here after you've completed the detailed instructions we've provided for Azure on the [official Certifai docs](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup).\n",
    "\n",
    "\n",
    "Once you're done, head back to this tutorial where we walk you through the widely known [German Credit dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) and build two classification models that determine whether a Bank should extend lines of Credit to customers based on demographic, financial and employment features.\n",
    "\n",
    "Both of the classification models (SVM and Logistic Regression) we'll build today use the `Scikit-learn` Python module. You can follow along to get a good sense of the contracts/patterns needed to deploy a machine learning model that your Certifai Pro installation understands and connects to (for inference).\n",
    "\n",
    "The following notebook cells walk you through the routine Data Science workflow (Pre-process, Data Splits, Model Training and Model Deployment). Feel free to use these notebooks as a starting point in your journey to scan your machine learning models with the CERTIFAI framework and gain a deeper understanding of their performance and behavior in terms of the following quantities:\n",
    "\n",
    "    1. Robustness to Data Variations\n",
    "    2. Explainability of Model Predictions\n",
    "    3. Fairness By Group\n",
    "\n",
    "Refer to the [Certifai Quickstart](https://cognitivescale.github.io/cortex-certifai/docs/quickstart) for a rehash on each of these topics and what they mean in general and what they can mean to your machine learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Cortex Certifai Toolkit from your Certifai Pro VM\n",
    "\n",
    "Follow the instructions described in [Certifai Pro Azure Setup](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup) to finish initial setup for your Certifai Pro VM. Now, click on the Help icon (top right) and select `Download Toolkit` to download a zip file containing the Cortex Certifai Toolkit to your computer.\n",
    "\n",
    "If you're running this notebook from an Azure Hosted Notebook, you'll need to upload the Certifai Toolkit zip file to the Hosted Notebook and make note of its path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Account Configuration for Certifai Pro VMs\n",
    "\n",
    "Follow the instructions described in the [Azure Storage Setup](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup#certifai-console-storage-setup) to configure your Azure based Certifai Console hosted via the Certifai Pro VM with an Azure Blob Container Storage Account of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites - Notebook Dependencies\n",
    "\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the \n",
    "[configuration-notebook](https://github.com/Azure/MachineLearningNotebooks/blob/c520bd1d4130d9a01ee46e0937459e2de95d15ec/configuration.ipynb) to create an Azure workspace. Creating local and remote environments/dependencies will be covered in the notebook\n",
    "\n",
    "**PleaseNote**: to step through this notebook, make sure you have necessary dependencies installed locally\n",
    "\n",
    "- python>=3.6.2,<3.7\n",
    "- scikit-learn=0.20.3\n",
    "- numpy=1.16.2\n",
    "- pandas\n",
    "- azureml-sdk=1.4.0\n",
    "- ipython\n",
    "- matplotlib\n",
    "- jupyter\n",
    "\n",
    "You can also use [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) to create the local environment using the `certifai_azure_model_env.yml` file provided with the notebook\n",
    "\n",
    "Open your favorite terminal and cd into folder where this notebook is located to execute the below commands\n",
    "\n",
    "- `conda env create -f certifai_azure_model_env.yml` : will create local conda env with the necessary python packages for working through the notebook\n",
    "- `jupyter-notebook` : to launch jupyter notebook sesssion. \n",
    "\n",
    "\n",
    "**Note**: Installing `Cortex-Certifai` packages will be covered separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certifai Pro on Azure\n",
    "\n",
    "First, we follow the instructions detailed on the official [Cortex Certifai documentation site](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup) to tick off the following items from our Pre-requisites:\n",
    "\n",
    "- [ ] [Install Certifai Pro](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup) from the Azure Marketplace into an Azure Virtual Machine\n",
    "- [ ] [Configure](https://cognitivescale.github.io/cortex-certifai/docs/platforms/azure/azure-setup#certifai-console-storage-setup) your Certifai Pro instance with storage credentials for a blob container inside an Azure Storage Account.\n",
    "\n",
    "Once you've configured your Certifai Pro instance with the Azure Storage Account credentials, download the Certifai Toolkit by clicking on the Help Icon on the top left of the site and selecting `Download Toolkit`\n",
    "- [ ] Download the Certifai Toolkit and upload it into your hosted Azure ML Notebook and make note of the path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cortex Certifai Toolkit path\n",
    "- update the `certifai_toolkit_path` to point to your downloaded Certifai Toolkit\n",
    "- this will be used later to install cortex certifai python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser, isfile\n",
    "home = expanduser(\"~\")\n",
    "certifai_toolkit_path = f'{home}/Downloads/toolkit'\n",
    "certifai_toolkit_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a [german credit](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) prediction model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports for model building and persistance \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to confirm correct version of scikit-learn and numpy are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sklearn_version_test\n",
    "assert sklearn_version_test.__version__ == '0.20.3', 'scikit-learn version mismatch, `pip install scikit-learn==0.20.3` to install right sklearn version for this notebook'\n",
    "assert np.__version__                   == '1.16.2', 'numpy version mismatch, `pip install numpy==1.16.2` to install right numpy version for this notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special import - \n",
    "# for multiprocessing to work in a Notebook,  pickled classes must be in a separate package or notebook\n",
    "# hence, the model encoder class has to be somewhere other than the current notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('.')))\n",
    "from scripts.cat_encoder import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  load data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into memory\n",
    "df = pd.read_csv('data/german_credit_eval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "label_column = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[label_column]\n",
    "X = df.drop(label_column, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset into the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode and scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CatEncoder(cat_columns, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build and train model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data, name, model_family, test=None):\n",
    "    if test is None:\n",
    "        test = data\n",
    "        \n",
    "    if model_family == 'SVM':\n",
    "        parameters = {'kernel':('linear', 'rbf', 'poly'), 'C':[0.1, .5, 1, 2, 4, 10], 'gamma':['auto']}\n",
    "        m = svm.SVC()\n",
    "    elif model_family == 'logistic':\n",
    "        parameters = {'C': (0.5, 1.0, 2.0), 'solver': ['lbfgs'], 'max_iter': [1000]}\n",
    "        m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(data[0], data[1])\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(test[0], test[1].values)\n",
    "    print(f\"Model '{name}' accuracy is {accuracy}\")\n",
    "    return model\n",
    "\n",
    "svm_model_name      = 'german_credit_svm'\n",
    "logistic_model_name = 'german_credit_logit'\n",
    "\n",
    "svm_model = build_model((encoder(X_train.values), y_train),\n",
    "                        svm_model_name,\n",
    "                        'SVM',\n",
    "                        test=(encoder(X_test.values), y_test))\n",
    "\n",
    "logistic_model = build_model((encoder(X_train.values), y_train),\n",
    "                        logistic_model_name,\n",
    "                        'logistic',\n",
    "                        test=(encoder(X_test.values), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dump the trained models (along with corresponding encoder object) to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder object is dumped(along with trained model) to apply same transformation during prediction\n",
    "def dump_model(model_name,model_obj,encoder_obj=encoder):\n",
    "    model_path = f'{model_name}.pkl'\n",
    "    model_obj = {\n",
    "        \"model\":model_obj,\n",
    "        \"encoder\":encoder_obj\n",
    "    }\n",
    "    joblib.dump(value=model_obj, filename=model_path)\n",
    "    print(f'model saved on disk {model_obj}')\n",
    "    return model_path\n",
    "\n",
    "# persist models to disk\n",
    "svm_model_disk_path      = dump_model(svm_model_name,svm_model)\n",
    "logistic_model_disk_path = dump_model(logistic_model_name,logistic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the section below we will:\n",
    "\n",
    "1. Configure Azure workspace\n",
    "2. Register models (built above) to the workspace\n",
    "3. Create a prediction environment in the remote Azure workspace (created above) and\n",
    "4. Deploy models (predict) as web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Initialize Azure workspace\n",
    "\n",
    "- Follow the instructions listed here [creating and managing azure-ml workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace) to create an azure-ml workspace\n",
    "\n",
    "**Once you have the workspace created easiest way to run through remaining steps is to download the `config.json` to the current directory and replace the exisiting config.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a [Workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace%28class%29?view=azure-ml-py) object from the persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register models to created  workspace\n",
    "\n",
    "Register a file or folder as a model by calling [Model.register()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-).\n",
    "\n",
    "In addition to the content of the model file itself (model + scaler object), our registered model will also store model metadata like model description, tags, etc. -- that will be useful when managing and deploying models in our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "logistic_model_azure = Model.register(model_path=logistic_model_disk_path,\n",
    "                       model_name=logistic_model_name,\n",
    "                       tags={'area': \"banking credit risk\", 'type': \"classification\"},\n",
    "                       description=\"Logistic Classifier model to predict credit loan approval\",\n",
    "                       workspace=ws)\n",
    "\n",
    "svm_model_azure = Model.register(model_path=svm_model_disk_path,\n",
    "                       model_name=svm_model_name,\n",
    "                       tags={'area': \"banking credit risk\", 'type': \"classification\"},\n",
    "                       description=\"Support Vector Machine Classifier model to predict credit loan approval\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom prediction environment inside azure-ml workspace\n",
    "\n",
    "If we want control over how our model is run, if it uses another framework, or if it has special runtime requirements, we can instead specify our own environment and scoring method. Custom environments can be used for any model we want to deploy.\n",
    "\n",
    "Specify the model's runtime environment by creating an [Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment%28class%29?view=azure-ml-py) object and providing the [CondaDependencies](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py) needed by the model\n",
    "\n",
    "In this example we will create a conda environment for our german credit model from file **myenv.yml** and register it to our workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"myenv.yml\", 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "environment = Environment(\"german-credit-env\")\n",
    "environment.python.conda_dependencies = CondaDependencies(\"myenv.yml\")\n",
    "environment.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Inference Configuration and deploy webservice\n",
    "\n",
    "**Inference Configuration** will contain:\n",
    "\n",
    "1. Scoring script\n",
    "2. Environment (created above)\n",
    "\n",
    "We create the scoring script, called **score.py**. The web service call uses this script to show how to use the model.\n",
    "\n",
    "We include below two required functions in the scoring script:\n",
    "\n",
    "1. The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "\n",
    "2. The `run(data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are also supported.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Deploy the registered model in the custom environment by providing an [InferenceConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py) object to [Model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config--deployment-config-none--deployment-target-none-). In this case we are also using the [AciWebservice.deploy_configuration()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none--) method to generate a custom deploy configuration\n",
    "        \n",
    "**Note**: This step can take several minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scripts/svm_score.py') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "inference_config_logistic = InferenceConfig(entry_script=\"logistic_score.py\",\n",
    "                                   environment=environment,source_directory=\"scripts\")\n",
    "inference_config_svm = InferenceConfig(entry_script=\"svm_score.py\",\n",
    "                                   environment=environment,source_directory=\"scripts\")\n",
    "\n",
    "logistic_service_name = 'german-credit-logistic-service'\n",
    "svm_service_name = 'german-credit-svm-service'\n",
    "\n",
    "aci_deployment_config = AciWebservice.deploy_configuration(auth_enabled=True)\n",
    "\n",
    "# Remove any existing services under the same name.\n",
    "try:\n",
    "    Webservice(ws, logistic_service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    Webservice(ws, svm_service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "\n",
    "service_logistic = Model.deploy(ws, logistic_service_name, [logistic_model_azure],inference_config=inference_config_logistic,deployment_config=aci_deployment_config)\n",
    "service_svm      = Model.deploy(ws, svm_service_name,      [svm_model_azure],     inference_config=inference_config_svm,     deployment_config=aci_deployment_config)\n",
    "service_logistic.wait_for_deployment(show_output=True)\n",
    "service_svm.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the webservice\n",
    "\n",
    "1. Get the webservice endpoint using `service.scoring_uri` :: string\n",
    "2. Get the authentication headers usinh `service.get_keys()` :: tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_logistic_uri  = service_logistic.scoring_uri\n",
    "service_logistic_keys = service_logistic.get_keys()\n",
    "\n",
    "service_svm_uri       = service_svm.scoring_uri\n",
    "service_svm_keys      = service_svm.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json test data sample(from csv)\n",
    "\n",
    "import json\n",
    "sample_input = json.dumps({\n",
    "\"payload\": {\n",
    "    \"instances\": [\n",
    "        [\n",
    "            \"... < 0 DM\",\n",
    "            6,\n",
    "            \"critical account/ other credits existing (not at this bank)\",\n",
    "            \"radio/television\",\n",
    "            1169,\n",
    "            \"unknown/ no savings account\",\n",
    "            \".. >= 7 years\",\n",
    "            4,\n",
    "            \"male : single\",\n",
    "            \"others - none\",\n",
    "            4,\n",
    "            \"real estate\",\n",
    "            \"> 25 years\",\n",
    "            \"none\",\n",
    "            \"own\",\n",
    "            2,\n",
    "            \"skilled employee / official\",\n",
    "            1,\n",
    "            \"phone - yes, registered under the customers name\",\n",
    "            \"foreign - yes\"\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "})\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {service_svm_keys[0]}'          \n",
    "          }\n",
    "\n",
    "response = requests.post(\n",
    "    service_svm_uri, data=sample_input, headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Cortex Certifai Scan locally\n",
    "\n",
    "1. Install the cortex certifai packages required to initiate model scan\n",
    "\n",
    "2. Configure scan details and execute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Cortex Certifai python packages\n",
    "\n",
    "initiating a Cortex Certifai scan requires following python packages to be installed in the current local environment\n",
    "\n",
    "`required-packages`\n",
    "\n",
    "- cortex-certifai-scanner\n",
    "- cortex-certifai-engine\n",
    "- cortex-certifai-common\n",
    "\n",
    "`optional-packages`\n",
    "\n",
    "- cortex-certifai-client\n",
    "- cortex-certifai-console\n",
    "\n",
    "Download [certifai toolkit](https://www.cognitivescale.com/download-certifai) and follow instructions in the `Readme.md` to install the python-packages in the current environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required certifai packages (optional packages are left for user to install)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find $certifai_toolkit_path/packages/all       -type f ! -name \"*console-*\" | xargs -I % sh -c 'pip install % ' ;\n",
    "!find $certifai_toolkit_path/packages/python3.6 -type f   -name \"*engine-*\"                      | xargs -I % sh -c 'pip install % ' ;\n",
    "!find $certifai_toolkit_path/packages/all -type f   -name \"*client-*\"                      | xargs -I % sh -c 'pip install % ' ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certifai.client.remote import remote_config, remote_list\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "remote_alias = 'cpro-az'\n",
    "pro_kubeconf_locn = 'certifai-kubeconfig.json'\n",
    "\n",
    "args = Namespace(file='certifai-kubeconfig.json',\n",
    "                alias=remote_alias,\n",
    "                context='current-context',\n",
    "                namespace='certifai',\n",
    "                timeout=15)\n",
    "\n",
    "r_conf = remote_config.remote_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Scan job on the Certifai Pro remote instance\n",
    "We use the following code block to list all scan jobs on the configured `remote_alias` using the `certifai-client` python package\n",
    "\n",
    "\n",
    "#### Equivalent CLI command\n",
    "```\n",
    "certifai remote list -a <remote_alias>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certifai.client.remote import remote_list\n",
    "list_args = Namespace(alias=remote_alias)\n",
    "remote_list.remote_list(list_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Scan definition for our models\n",
    "\n",
    "We'll now use the `certifai-scanner` python package to build a scan definition for the SVM and Logistic Regression models (via the Service Endpoints created earlier).\n",
    "\n",
    "Our Certifai Scan needs some mandatory parameters like:\n",
    "\n",
    "1. Prediction Task Outcomes and Values\n",
    "2. Model Details (names, endpoints and more)\n",
    "3. Datasets to evaluate the models on\n",
    "\n",
    "And optional parameters that depend on the desired evaluation reports. Evaluation types include:\n",
    "\n",
    "1. Fairness\n",
    "2. Robustness\n",
    "3. Explainability\n",
    "4. SHAP reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure certifai package was installed correctly\n",
    "from certifai.scanner.version import get_version\n",
    "get_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cortex Certifai Client python-package to launch a Remote Scan\n",
    "\n",
    "In the below code block, set the variable named `pro_kubeconf_locn` to the location of the KubeConfig file downloaded from your Certifai Pro instance. We configure the installed `certifai` cli tool via it's python library to configure and save the kuberentes connection settings to your Certifai Pro instance under the alias stored in variable `remote_alias`.\n",
    "\n",
    "We can now use this `remote_alias` (on successful connection) to list, submit and delete Certifai Scans on the running Certifai Pro instance\n",
    "\n",
    "#### Equivalent CLI commands\n",
    "\n",
    "```\n",
    "certifai remote config --file certifai-kubeconfig.json --alias <remote_alias>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports for creating a scan\n",
    "\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define cortex certifai task type\n",
    "\n",
    "- `CertifaiTaskOutcomes` : cortex certifai supports classification as well as regression models. here we have an example of binary-classification (e.g. predict whether loan should be granted or not)\n",
    "- `CertifaiOutcomeValue` : define the different outcomes possible from the model predictions. here we have a model that predicts either 1(loan granted) or 2(loan denied)\n",
    "\n",
    "**Note**: Please refer to [Certifai Api Docs](https://cognitivescale.github.io/cortex-certifai/certifai-api-ref/certifai.scanner.builder.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scan object from scratch using the ScanBuilder class with tasks and outcomes\n",
    "\n",
    "# First define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')\n",
    "\n",
    "#  create a certifai scan object and add the certifai task created above\n",
    "scan = CertifaiScanBuilder.create('model_auth_demo',\n",
    "                                  prediction_task=task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "# set credentials for azure storage account\n",
    "az_credentials = 'REDACTED'\n",
    "# set connection string as env var so the Certifai Library can pick it up\n",
    "os.environ['AZURE_CONNECTION_STRING'] = az_credentials\n",
    "# upload our evaluation dataset to an Azure Blob Storage Account Container.\n",
    "client = BlobServiceClient.from_connection_string(az_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload our eval dataset to the blob storage container\n",
    "az_container_name = 'set_container_name' # this container should already exist. You can create one from the Azure Portal\n",
    "german_credit_eval_data_file = \"data/german_credit_eval.csv\"\n",
    "az_german_credit_blob_name = 'az-certifai-examples/german_credit_eval.csv'\n",
    "\n",
    "blob_client = client.get_blob_client(container=az_container_name, blob=az_german_credit_blob_name)\n",
    "with open(german_credit_eval_data_file, 'rb') as f:\n",
    "    blob_client.upload_blob(f)\n",
    "\n",
    "container_client = client.get_container_client(az_container_name)\n",
    "blob_list = container_client.list_blobs()\n",
    "for blob in blob_list:\n",
    "    print(\"\\n\" + blob.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add logistic and svm models (created above) to scan object\n",
    "\n",
    "Additional parameters that maybe provided to the `CertifaiModel` class can be gleaned from the [API Reference for CertifaiModel](https://cognitivescale.github.io/cortex-certifai/certifai-api-ref-1.2.14/certifai.scanner.builder.html#certifai.scanner.builder.CertifaiModel)\n",
    "\n",
    "or `?CertifaiModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Certifai Model Object using the web service (from earlier) by passing the deployed web service url\n",
    "first_model = CertifaiModel('SVM',\n",
    "                            predict_endpoint=service_svm_uri)\n",
    "scan.add_model(first_model)\n",
    "\n",
    "second_model = CertifaiModel('logistic',\n",
    "                            predict_endpoint=service_logistic_uri)\n",
    "scan.add_model(second_model)\n",
    "\n",
    "# Add corresponding model headers for service authentication and content-type\n",
    "\n",
    "# add the default headers applicable to all models\n",
    "scan.add_model_header(header_name='Content-Type',header_value='application/json')\n",
    "\n",
    "# add defined headers corresponding to auth keys for respective model services\n",
    "scan.add_model_header(header_name='Authorization', header_value=f'Bearer {service_svm_keys[0]}', model_id='SVM')\n",
    "scan.add_model_header(header_name='Authorization', header_value=f'Bearer {service_logistic_keys[0]}', model_id='logistic')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the evaluation dataset to scan object\n",
    "\n",
    "- `evaluation dataset` dataset to be used by cortex certifai to evaluate the model against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an evaluation object and pass the evaluation dataset(csv) here \n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(url=f'abfs://{az_container_name}/{az_german_credit_blob_name}'))\n",
    "scan.add_dataset(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating model fairness \n",
    "\n",
    "- add `fairness` as evaluation type to scan object\n",
    "- create an `evaluation_dataset_id` to refer to added evaluation datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup an evaluation for fairness on the above dataset using the model\n",
    "# We'll look at disparity between groups defined by marital status and age\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset contains a ground truth outcome column which the model does not\n",
    "# expect to receive as input we need to state that in the dataset schema (since it cannot\n",
    "# be inferred from the CSV)\n",
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the triggered remote scan job\n",
    "!certifai remote logs -a cpro-az -n certifai-scanner-9a695932"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the reports from this Remote Scan\n",
    "\n",
    "Now, head on over to the URL to the Certifai Console of the Certifai Pro VM instance we created earlier in this tutorial. Use the `User Icon` on the top right and select `Storage Settings` from the dropdown. Update the `Scan Directory` field to the `reports_folder` variable configured in the previous cell. Please omit `abfs://` while pasting this variable's value in the `Scan Directory` field. \n",
    "\n",
    "Now, save your settings and wait while the page reloads and loads reports from the previous scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_scan_definition_file = 'data/german_credit_scan_definition.yaml'\n",
    "model_headers_template = f\"\"\"\n",
    "model_headers:\n",
    "  default:\n",
    "  - name: Content-Type\n",
    "    value: application/json\n",
    "  - name: accept\n",
    "    value: application/json\n",
    "  defined:\n",
    "  - model_id: SVM\n",
    "    name: Authorization\n",
    "    value: Bearer {service_svm_keys[0]}\n",
    "  - model_id: logistic\n",
    "    name: Authorization\n",
    "    value: Bearer {service_logistic_keys[0]}'\n",
    "\"\"\"\n",
    "\n",
    "with open(local_scan_definition_file, 'w') as f:\n",
    "    scan.save(f)\n",
    "# we also need to add the model headers section separately\n",
    "with open(local_scan_definition_file, 'a') as f:\n",
    "    f.write(model_headers_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a remote scan\n",
    "from certifai.client.remote import remote_scan\n",
    "\n",
    "reports_folder = f'abfs://{az_container_name}/az_certifai_examples/reports'\n",
    "\n",
    "!certifai remote scan --alias cpro-az --definition-file data/german_credit_scan_definition.yaml --output abfs://pkandarpa/az_certifai_examples/reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Resource Cleanup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this tutorial we\n",
    " - created and registered `logistic_model_azure` and `svm_model_azure` models to our Azure workspace\n",
    " - created `german-credit-logistic-service` and `german-credit-svm-service` ACI (Azure Container Instance) webservices \n",
    "\n",
    "- Once Cortex Certifai evaluation is complete, make sure to clear all azure resources in order to avoid cost\n",
    "- Follow the [Azure Ml resource cleanup docs][1] to remove all resources created above\n",
    "\n",
    "[1]:https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-1st-experiment-sdk-train#clean-up-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}