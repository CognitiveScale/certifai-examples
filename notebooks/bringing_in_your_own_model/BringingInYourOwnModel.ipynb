{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a scan programmatically with your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we will be demonstrating how to create a scan in Certifai using your own model. We will show some examples of how to use models and datasets to run scans**\n",
    "\n",
    "**Documentation for Certifai can be found at https://cognitivescale.github.io/cortex-certifai/docs/about**\n",
    "\n",
    "**To begin, we will import the libraries required to run Certifai scans via Jupyter Lab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from copy import copy\n",
    "import yaml\n",
    "\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For multiprocessing to work in a Notebook, we need the encoder to be outside of the notebook. This code imports the encoder in a way that works in hosted notebooks as well as locally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "from utils.cat_encoder import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP (1): Setting up the dataset and model to be scanned\n",
    "\n",
    "**Task 1): Setting up the dataset**\n",
    "\n",
    "**Load the data into a DataFrame for use in both training and later analysing the model. In this example we use the German Credit dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkingstatus</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>status</th>\n",
       "      <th>others</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>otherplans</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>job</th>\n",
       "      <th>liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>... &gt;= 200 DM / salary assignments for at leas...</td>\n",
       "      <td>6</td>\n",
       "      <td>critical account/ other credits existing (not ...</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1343</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>.. &gt;= 7 years</td>\n",
       "      <td>1</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>2</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>... &lt; 0 DM</td>\n",
       "      <td>28</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>4006</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>unskilled - resident</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>2284</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>4 &lt;= ... &lt; 7 years</td>\n",
       "      <td>4</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>1533</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>... &lt; 1 year</td>\n",
       "      <td>4</td>\n",
       "      <td>female : divorced/separated/married</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>stores</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>12</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1101</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : married/widowed</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      checkingstatus  duration  \\\n",
       "0  ... >= 200 DM / salary assignments for at leas...         6   \n",
       "1                                         ... < 0 DM        28   \n",
       "2                                no checking account        24   \n",
       "3                                no checking account        24   \n",
       "4                                no checking account        12   \n",
       "\n",
       "                                             history           purpose  \\\n",
       "0  critical account/ other credits existing (not ...         car (new)   \n",
       "1           existing credits paid back duly till now         car (new)   \n",
       "2           existing credits paid back duly till now  radio/television   \n",
       "3           existing credits paid back duly till now  radio/television   \n",
       "4           existing credits paid back duly till now         car (new)   \n",
       "\n",
       "   amount       savings              employ  installment  \\\n",
       "0    1343  ... < 100 DM       .. >= 7 years            1   \n",
       "1    4006  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "2    2284  ... < 100 DM  4 <= ... < 7 years            4   \n",
       "3    1533  ... < 100 DM        ... < 1 year            4   \n",
       "4    1101  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "\n",
       "                                status         others  ...  \\\n",
       "0                        male : single  others - none  ...   \n",
       "1                        male : single  others - none  ...   \n",
       "2                        male : single  others - none  ...   \n",
       "3  female : divorced/separated/married  others - none  ...   \n",
       "4               male : married/widowed  others - none  ...   \n",
       "\n",
       "                           property         age otherplans housing cards  \\\n",
       "0                       real estate  > 25 years       none     own     2   \n",
       "1  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "2  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "3  car or other, not in attribute 6  > 25 years     stores     own     1   \n",
       "4                       real estate  > 25 years       none     own     2   \n",
       "\n",
       "                           job liable  \\\n",
       "0  skilled employee / official      2   \n",
       "1         unskilled - resident      1   \n",
       "2  skilled employee / official      1   \n",
       "3  skilled employee / official      1   \n",
       "4  skilled employee / official      1   \n",
       "\n",
       "                                          telephone        foreign outcome  \n",
       "0                                      phone - none   foreign - no       1  \n",
       "1                                      phone - none  foreign - yes       2  \n",
       "2  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "3  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "4  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_file = \"datasets/german_credit_eval.csv\"\n",
    "df = pd.read_csv(all_data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2): Set the categorical columns of the dataset up for the encoder (in our case we will encapsulate this in the CatEncoder class, which may be found in the same directory as this notebook). We also note the column that contains the ground truth labels for training in 'label_column' (in this dataset this is 'outcome').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "label_column = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In our example we use a simple logistic classifier from sklearn. This is where you can add your own model. Rather than using the one provided, you can import and set up your model to be used here.**\n",
    "\n",
    "**Note that the predictor must be picklable.  Specifically if the predictor class itself is defined in a notebook rather than an imported module then it *must* be in a different notebook file for Python muti-processing to handle it correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Because the outcome column won't be presented to the model at prediction time we need to drop it from the dataset. We then split into a test and train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[label_column]\n",
    "X = df.drop(label_column, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Set the encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CatEncoder(cat_columns, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Fit the classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic classifier' accuracy is 0.76\n"
     ]
    }
   ],
   "source": [
    "def build_model(data, name, test=None):\n",
    "    if test is None:\n",
    "        test = data\n",
    "        \n",
    "\n",
    "    parameters = {'C': (0.5, 1.0, 2.0), 'solver': ['lbfgs'], 'max_iter': [1000]}\n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(data[0], data[1])\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(test[0], test[1].values)\n",
    "    print(f\"Model '{name}' accuracy is {accuracy}\")\n",
    "    return model\n",
    "\n",
    "logistic_model = build_model((encoder(X_train.values), y_train),\n",
    "                        'Logistic classifier',\n",
    "                        test=(encoder(X_test.values), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Wrap up the model and the encoder so that Certifai sees it as part of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_proxy = CertifaiPredictorWrapper(logistic_model, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Compute model's accuracy with the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier model accuracy on test data is 0.76\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = logistic_model.score(encoder(X_test.values), y_test.values)\n",
    "print(f\"Logistic classifier model accuracy on test data is {logistic_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (2) Create the scan object using the ScanBuilder class\n",
    "\n",
    "**To allow easy working with Certifai from notebooks, or other programmatic use cases, the `ScanBuilder` class abstracts the scan definition and provides an object model to manipulate it.  Building up a definition in this way allows either direct running of the scan in the notebook, or export as a scan definition file, which can be run by the Certifai scanner.**\n",
    "\n",
    "**Task 1) Define the outcomes of the classification task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Create the Certifai scan object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Create the Certifai dataset from the local dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(all_data_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Create the Certifai model from the local model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our local model\n",
    "first_model = CertifaiModel('logistic_regression',\n",
    "                            local_predictor=logistic_model_proxy)\n",
    "scan.add_model(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Setup an evaluation for fairness, robustness, and explainability on the above dataset using the model**\n",
    "\n",
    "**We can have one or many of the following analysis types:**\n",
    "- fairness\n",
    "- robustness\n",
    "- explainability\n",
    "- explanation\n",
    "- performance\n",
    "\n",
    "**More information on these analyses can be found at our docs: https://cognitivescale.github.io/cortex-certifai/docs/factors/fairness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.add_dataset(eval_dataset)\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.add_evaluation_type('explainability')\n",
    "scan.add_evaluation_type('robustness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Because the dataset contains a ground truth outcome column which the model does not expect to receive as input we need to state that in the dataset schema (since it cannot be inferred from the CSV) so that the scan can be rerun from the definition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Run the scan. \n",
    "    By default this will write the results into individual report files (one per model and evaluation\n",
    "    type) in the 'reports' directory relative to the notebook.  This may be disabled by specifying\n",
    "    `write_reports=False` as below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 11:37:32,370 root   INFO     Validating license...\n",
      "2020-05-19 11:37:32,372 root   INFO     License is valid - expires: n/a\n",
      "2020-05-19 11:37:32,385 root   INFO     Generated unique scan id: 0e3abbc7bb97\n",
      "2020-05-19 11:37:32,387 root   INFO     Validating input data...\n",
      "2020-05-19 11:37:32,388 root   INFO     Creating dataset with id: evaluation\n",
      "2020-05-19 11:37:32,412 root   INFO     Inferring dataset features and applying user overrides\n",
      "2020-05-19 11:37:32,415 root   INFO     Reading configs from: /Users/npasricha/.certifai/certifai_config.ini\n",
      "2020-05-19 11:37:32,418 root   INFO     Reading default config (fallback) from: /Users/npasricha/miniconda3/envs/certifai/lib/python3.6/site-packages/certifai/common/utils/default_certifai_config.ini\n",
      "2020-05-19 11:37:32,436 root   INFO     Read config marker: config['default']['marker'] = 0.1\n",
      "2020-05-19 11:37:32,438 root   INFO     Integer-valued feature 'duration' inferred to be numeric (sample cardinality 33)\n",
      "2020-05-19 11:37:32,441 root   INFO     Integer-valued feature 'amount' inferred to be numeric (sample cardinality 921)\n",
      "2020-05-19 11:37:32,443 root   INFO     Integer-valued feature 'installment' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-19 11:37:32,446 root   INFO     Integer-valued feature 'residence' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-19 11:37:32,449 root   INFO     Integer-valued feature 'cards' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-19 11:37:32,451 root   INFO     Integer-valued feature 'liable' inferred to be categorical (sample cardinality 2)\n",
      "2020-05-19 11:37:32,453 root   INFO     Integer-valued feature 'outcome' inferred to be categorical (sample cardinality 2)\n",
      "2020-05-19 11:37:32,455 root   WARNING  Couldn't find column by label as index: `outcome`, in df.columns: `Index(['checkingstatus', 'duration', 'history', 'purpose', 'amount', 'savings',\n",
      "       'employ', 'installment', 'status', 'others', 'residence', 'property',\n",
      "       'age', 'otherplans', 'housing', 'cards', 'job', 'liable', 'telephone',\n",
      "       'foreign'],\n",
      "      dtype='object')`.\n",
      "2020-05-19 11:37:32,456 root   INFO     Inferring dataset features and applying user overrides\n",
      "2020-05-19 11:37:32,459 root   INFO     Integer-valued feature 'duration' inferred to be numeric (sample cardinality 33)\n",
      "2020-05-19 11:37:32,465 root   INFO     Integer-valued feature 'amount' inferred to be numeric (sample cardinality 921)\n",
      "2020-05-19 11:37:32,468 root   INFO     Integer-valued feature 'installment' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-19 11:37:32,471 root   INFO     Integer-valued feature 'residence' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-19 11:37:32,475 root   INFO     Integer-valued feature 'cards' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-19 11:37:32,478 root   INFO     Integer-valued feature 'liable' inferred to be categorical (sample cardinality 2)\n",
      "2020-05-19 11:37:32,491 root   INFO     Input validation complete\n",
      "2020-05-19 11:37:32,494 root   INFO     Beginning to perform evaluations\n",
      "2020-05-19 11:37:32,498 root   INFO     performing evaluation: fairness, for model: logistic_regression\n",
      "2020-05-19 11:37:32,555 root   INFO     Validating license...\n",
      "2020-05-19 11:37:32,558 root   INFO     License is valid - expires: n/a\n",
      "2020-05-19 11:37:32,561 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.PARTITIONED (analysis = Fairness)\n",
      "2020-05-19 11:37:32,563 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-19 11:37:32,566 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-19 11:37:32,592 root   WARNING  Insufficient examples of some fairness classes to guarantee convergence (smallest class size is for 'male : divorced/separated' with 50 samples)\n",
      "2020-05-19 11:37:32,607 root   INFO     Running analysis variant 'prediction more beneficial'\n",
      "2020-05-19 11:37:34,741 root   INFO     Running with explanation reduction ON\n",
      "2020-05-19 11:37:34,742 root   INFO     Total dataset size is 1000\n",
      "2020-05-19 11:37:56,502 root   INFO     Batch run time per generation for instances 0 to 119: 0.09282\n",
      "2020-05-19 11:37:56,503 root   INFO     Current max sampling error 0.3749999793750012 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:37:56,504 root   INFO     Current min non-exhausted protected class samples 27 (min for early stop 100)\n",
      "2020-05-19 11:38:14,603 root   INFO     Batch run time per generation for instances 120 to 256: 0.08167\n",
      "2020-05-19 11:38:14,604 root   WARNING  Examples of protected class (8, 'male : divorced/separated') exhausted before convergence after 50 samples\n",
      "2020-05-19 11:38:14,605 root   INFO     Current max sampling error 0.31031642438453 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:38:14,606 root   INFO     Current min non-exhausted protected class samples 61 (min for early stop 100)\n",
      "2020-05-19 11:38:33,076 root   INFO     Batch run time per generation for instances 257 to 416: 0.08183\n",
      "2020-05-19 11:38:33,077 root   WARNING  Examples of protected class (8, 'male : married/widowed') exhausted before convergence after 92 samples\n",
      "2020-05-19 11:38:33,077 root   INFO     Current max sampling error 0.2068770298848812 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:38:33,079 root   INFO     Current min non-exhausted protected class samples 128 (min for early stop 100)\n",
      "2020-05-19 11:38:51,348 root   INFO     Batch run time per generation for instances 417 to 507: 0.07964\n",
      "2020-05-19 11:38:51,349 root   INFO     Current max sampling error 0.15953065063372715 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:38:51,350 root   INFO     Current min non-exhausted protected class samples 158 (min for early stop 100)\n",
      "2020-05-19 11:39:09,665 root   INFO     Batch run time per generation for instances 508 to 628: 0.08302\n",
      "2020-05-19 11:39:09,666 root   WARNING  Examples of protected class (12, '<= 25 years') exhausted before convergence after 190 samples\n",
      "2020-05-19 11:39:09,667 root   INFO     Current max sampling error 0.13428744550517044 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:39:09,668 root   INFO     Current min non-exhausted protected class samples 243 (min for early stop 100)\n",
      "2020-05-19 11:39:29,263 root   INFO     Batch run time per generation for instances 629 to 773: 0.08137\n",
      "2020-05-19 11:39:29,264 root   INFO     Current max sampling error 0.12022695360352868 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:39:29,265 root   INFO     Current min non-exhausted protected class samples 305 (min for early stop 100)\n",
      "2020-05-19 11:39:47,882 root   INFO     Batch run time per generation for instances 774 to 982: 0.08574\n",
      "2020-05-19 11:39:47,883 root   WARNING  Examples of protected class (8, 'female : divorced/separated/married') exhausted before convergence after 310 samples\n",
      "2020-05-19 11:39:47,884 root   INFO     Current max sampling error 0.0985571025511247 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:39:47,885 root   INFO     Current min non-exhausted protected class samples 531 (min for early stop 100)\n",
      "2020-05-19 11:39:50,549 root   INFO     Batch run time per generation for instances 983 to 999: 0.10610\n",
      "2020-05-19 11:39:50,550 root   WARNING  Examples of protected class (12, '> 25 years') exhausted before convergence after 810 samples\n",
      "2020-05-19 11:39:50,551 root   WARNING  Examples of protected class (8, 'male : single') exhausted before convergence after 548 samples\n",
      "2020-05-19 11:39:50,552 root   INFO     Early stopping after running 1000 instances\n",
      "2020-05-19 11:39:50,568 root   INFO     Estimating sample variance (2001 bags)\n",
      "2020-05-19 11:40:05,594 root   INFO     Group Burden is [{'feature': 'age', 'groups': [{'label': '<= 25 years', 'value': 0.09065934065934066, 'value_confidence_95_lower': 0.07535885167464115, 'value_confidence_95_upper': 0.10657894736842105, 'values': [0.09065934065934066], 'values_confidence_95_lower': [0.07535885167464115], 'values_confidence_95_upper': [0.10657894736842105], 'values_names': ['burden']}, {'label': '> 25 years', 'value': 0.05319148936170213, 'value_confidence_95_lower': 0.046625766871165646, 'value_confidence_95_upper': 0.0594944512946979, 'values': [0.05319148936170213], 'values_confidence_95_lower': [0.046625766871165646], 'values_confidence_95_upper': [0.0594944512946979], 'values_names': ['burden']}]}, {'feature': 'status', 'groups': [{'label': 'female : divorced/separated/married', 'value': 0.08883647798742138, 'value_confidence_95_lower': 0.07653061224489796, 'value_confidence_95_upper': 0.10096153846153846, 'values': [0.08883647798742138], 'values_confidence_95_lower': [0.07653061224489796], 'values_confidence_95_upper': [0.10096153846153846], 'values_names': ['burden']}, {'label': 'male : divorced/separated', 'value': 0.105, 'value_confidence_95_lower': 0.07407407407407407, 'value_confidence_95_upper': 0.13679245283018868, 'values': [0.105], 'values_confidence_95_lower': [0.07407407407407407], 'values_confidence_95_upper': [0.13679245283018868], 'values_names': ['burden']}, {'label': 'male : married/widowed', 'value': 0.03529411764705882, 'value_confidence_95_lower': 0.020348837209302327, 'value_confidence_95_upper': 0.05, 'values': [0.03529411764705882], 'values_confidence_95_lower': [0.020348837209302327], 'values_confidence_95_upper': [0.05], 'values_names': ['burden']}, {'label': 'male : single', 'value': 0.044144144144144144, 'value_confidence_95_lower': 0.03742802303262956, 'value_confidence_95_upper': 0.05136363636363636, 'values': [0.044144144144144144], 'values_confidence_95_lower': [0.03742802303262956], 'values_confidence_95_upper': [0.05136363636363636], 'values_names': ['burden']}]}]\n",
      "2020-05-19 11:40:05,596 root   INFO     Feature fairnesses are [{'feature': 'age', 'value': 74.07772574151672, 'value_confidence_95_lower': 64.34474349710983, 'value_confidence_95_upper': 84.42549371633751}, {'feature': 'status', 'value': 68.38787882659712, 'value_confidence_95_lower': 58.80694951727081, 'value_confidence_95_upper': 77.8514438311028}]\n",
      "2020-05-19 11:40:05,596 root   INFO     Model used: logistic_regression\n",
      "2020-05-19 11:40:05,597 root   INFO     CERScore is 1.0570175438596492\n",
      "2020-05-19 11:40:05,598 root   INFO     NCERScore is 0.07723889367830424\n",
      "2020-05-19 11:40:05,598 root   INFO     Normalization constant is 13.685042515783168\n",
      "2020-05-19 11:40:05,599 root   INFO     Total run time in seconds: 137.9947259426117\n",
      "2020-05-19 11:40:05,600 root   INFO     Total Samples: 1838\n",
      "2020-05-19 11:40:05,600 root   INFO     Average feature reduction applied to counterfactuals: 0.0\n",
      "2020-05-19 11:40:05,719 root   INFO     Completed fairness report for model logistic_regression\n",
      "2020-05-19 11:40:05,723 root   INFO     performing evaluation: explainability, for model: logistic_regression\n",
      "2020-05-19 11:40:05,752 root   INFO     Validating license...\n",
      "2020-05-19 11:40:05,753 root   INFO     License is valid - expires: n/a\n",
      "2020-05-19 11:40:05,755 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.PARTITIONED (analysis = Explainability)\n",
      "2020-05-19 11:40:05,756 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-19 11:40:05,757 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-19 11:40:05,773 root   INFO     Running analysis variant 'prediction changed'\n",
      "2020-05-19 11:40:07,680 root   INFO     Running with explanation reduction ON\n",
      "2020-05-19 11:40:07,683 root   INFO     Total dataset size is 1000\n",
      "2020-05-19 11:40:34,353 root   INFO     Batch run time per generation for instances 0 to 31: 0.08797\n",
      "2020-05-19 11:40:34,354 root   INFO     Current max sampling error 0.06546639277031954 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:40:34,354 root   INFO     Current min non-exhausted protected class samples 32 (min for early stop 100)\n",
      "2020-05-19 11:40:56,554 root   INFO     Batch run time per generation for instances 32 to 63: 0.07677\n",
      "2020-05-19 11:40:56,555 root   INFO     Current max sampling error 0.05031911907274441 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:40:56,556 root   INFO     Current min non-exhausted protected class samples 64 (min for early stop 100)\n",
      "2020-05-19 11:41:18,184 root   INFO     Batch run time per generation for instances 64 to 95: 0.07584\n",
      "2020-05-19 11:41:18,185 root   INFO     Current max sampling error 0.042420376901320216 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:41:18,185 root   INFO     Current min non-exhausted protected class samples 96 (min for early stop 100)\n",
      "2020-05-19 11:41:41,494 root   INFO     Batch run time per generation for instances 96 to 127: 0.07325\n",
      "2020-05-19 11:41:41,495 root   INFO     Current max sampling error 0.03896660347622054 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:41:41,496 root   INFO     Current min non-exhausted protected class samples 128 (min for early stop 100)\n",
      "2020-05-19 11:42:05,295 root   INFO     Batch run time per generation for instances 128 to 159: 0.07824\n",
      "2020-05-19 11:42:05,296 root   INFO     Current max sampling error 0.035014803086598774 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:42:05,297 root   INFO     Current min non-exhausted protected class samples 160 (min for early stop 100)\n",
      "2020-05-19 11:42:27,294 root   INFO     Batch run time per generation for instances 160 to 191: 0.07451\n",
      "2020-05-19 11:42:27,295 root   INFO     Current max sampling error 0.031137693081705983 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:42:27,296 root   INFO     Current min non-exhausted protected class samples 192 (min for early stop 100)\n",
      "2020-05-19 11:42:51,166 root   INFO     Batch run time per generation for instances 192 to 223: 0.07501\n",
      "2020-05-19 11:42:51,167 root   INFO     Current max sampling error 0.029287437469205934 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:42:51,168 root   INFO     Current min non-exhausted protected class samples 224 (min for early stop 100)\n",
      "2020-05-19 11:43:12,646 root   INFO     Batch run time per generation for instances 224 to 255: 0.07891\n",
      "2020-05-19 11:43:12,647 root   INFO     Current max sampling error 0.027564588088237054 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:43:12,648 root   INFO     Current min non-exhausted protected class samples 256 (min for early stop 100)\n",
      "2020-05-19 11:43:35,531 root   INFO     Batch run time per generation for instances 256 to 287: 0.07571\n",
      "2020-05-19 11:43:35,533 root   INFO     Current max sampling error 0.025846244336746142 (max for early stop 0.025510204081632654)\n",
      "2020-05-19 11:43:35,534 root   INFO     Current min non-exhausted protected class samples 288 (min for early stop 100)\n",
      "2020-05-19 11:43:56,830 root   INFO     Batch run time per generation for instances 288 to 319: 0.07388\n",
      "2020-05-19 11:43:56,832 root   INFO     Protected class (1.0,) now converged after 320 samples\n",
      "2020-05-19 11:43:56,833 root   INFO     Early stopping after running 320 instances\n",
      "2020-05-19 11:43:56,836 root   INFO     Model used: logistic_regression\n",
      "2020-05-19 11:43:56,837 root   INFO     CERScore is 1.4963297266514808\n",
      "2020-05-19 11:43:56,838 root   INFO     NCERScore is 0.10635759474479545\n",
      "2020-05-19 11:43:56,839 root   INFO     Normalization constant is 14.068856391891119\n",
      "2020-05-19 11:43:56,840 root   INFO     Total run time in seconds: 231.07973504066467\n",
      "2020-05-19 11:43:56,841 root   INFO     Total Samples: 3294\n",
      "2020-05-19 11:43:56,842 root   INFO     Average feature reduction applied to counterfactuals: 0.021875\n",
      "2020-05-19 11:43:56,958 root   INFO     Completed explainability report for model logistic_regression\n",
      "2020-05-19 11:43:56,964 root   INFO     performing evaluation: robustness, for model: logistic_regression\n",
      "2020-05-19 11:43:56,989 root   INFO     Validating license...\n",
      "2020-05-19 11:43:56,991 root   INFO     License is valid - expires: n/a\n",
      "2020-05-19 11:43:56,993 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.UNSTRUCTURED (analysis = Robustness)\n",
      "2020-05-19 11:43:56,995 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-19 11:43:56,997 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-19 11:43:57,013 root   INFO     Running analysis variant 'prediction changed'\n",
      "2020-05-19 11:43:59,171 root   INFO     Running with explanation reduction ON\n",
      "2020-05-19 11:43:59,171 root   INFO     Total dataset size is 1000\n",
      "2020-05-19 11:44:24,492 root   INFO     Batch run time per generation for instances 0 to 31: 0.08353\n",
      "2020-05-19 11:44:24,493 root   INFO     Current max sampling error 0.06546639277031954 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:44:24,494 root   INFO     Current min non-exhausted protected class samples 32 (min for early stop 100)\n",
      "2020-05-19 11:44:45,140 root   INFO     Batch run time per generation for instances 32 to 63: 0.07139\n",
      "2020-05-19 11:44:45,141 root   INFO     Current max sampling error 0.05031911907274441 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:44:45,142 root   INFO     Current min non-exhausted protected class samples 64 (min for early stop 100)\n",
      "2020-05-19 11:45:06,036 root   INFO     Batch run time per generation for instances 64 to 95: 0.07328\n",
      "2020-05-19 11:45:06,037 root   INFO     Current max sampling error 0.042426594774731714 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:45:06,038 root   INFO     Current min non-exhausted protected class samples 96 (min for early stop 100)\n",
      "2020-05-19 11:45:29,036 root   INFO     Batch run time per generation for instances 96 to 127: 0.07228\n",
      "2020-05-19 11:45:29,037 root   INFO     Current max sampling error 0.03899078371987135 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:45:29,038 root   INFO     Current min non-exhausted protected class samples 128 (min for early stop 100)\n",
      "2020-05-19 11:45:50,618 root   INFO     Batch run time per generation for instances 128 to 159: 0.07095\n",
      "2020-05-19 11:45:50,619 root   INFO     Current max sampling error 0.03503241401005545 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:45:50,620 root   INFO     Current min non-exhausted protected class samples 160 (min for early stop 100)\n",
      "2020-05-19 11:46:14,279 root   INFO     Batch run time per generation for instances 160 to 191: 0.08016\n",
      "2020-05-19 11:46:14,280 root   INFO     Current max sampling error 0.03125178863464429 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:46:14,281 root   INFO     Current min non-exhausted protected class samples 192 (min for early stop 100)\n",
      "2020-05-19 11:46:37,720 root   INFO     Batch run time per generation for instances 192 to 223: 0.07365\n",
      "2020-05-19 11:46:37,721 root   INFO     Current max sampling error 0.029384028228660534 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:46:37,722 root   INFO     Current min non-exhausted protected class samples 224 (min for early stop 100)\n",
      "2020-05-19 11:46:59,309 root   INFO     Batch run time per generation for instances 224 to 255: 0.07932\n",
      "2020-05-19 11:46:59,310 root   INFO     Current max sampling error 0.0276445435811736 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:46:59,311 root   INFO     Current min non-exhausted protected class samples 256 (min for early stop 100)\n",
      "2020-05-19 11:47:20,419 root   INFO     Batch run time per generation for instances 256 to 287: 0.06985\n",
      "2020-05-19 11:47:20,420 root   INFO     Current max sampling error 0.02591420282092695 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:47:20,421 root   INFO     Current min non-exhausted protected class samples 288 (min for early stop 100)\n",
      "2020-05-19 11:47:40,088 root   INFO     Batch run time per generation for instances 288 to 319: 0.06825\n",
      "2020-05-19 11:47:40,088 root   INFO     Current max sampling error 0.024621342221024915 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:47:40,089 root   INFO     Current min non-exhausted protected class samples 320 (min for early stop 100)\n",
      "2020-05-19 11:48:01,883 root   INFO     Batch run time per generation for instances 320 to 351: 0.06723\n",
      "2020-05-19 11:48:01,884 root   INFO     Current max sampling error 0.023707513830576427 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:48:01,884 root   INFO     Current min non-exhausted protected class samples 352 (min for early stop 100)\n",
      "2020-05-19 11:48:23,462 root   INFO     Batch run time per generation for instances 352 to 383: 0.06911\n",
      "2020-05-19 11:48:23,463 root   INFO     Current max sampling error 0.02294794940631691 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:48:23,464 root   INFO     Current min non-exhausted protected class samples 384 (min for early stop 100)\n",
      "2020-05-19 11:48:44,133 root   INFO     Batch run time per generation for instances 384 to 415: 0.07050\n",
      "2020-05-19 11:48:44,134 root   INFO     Current max sampling error 0.022245367638674435 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:48:44,134 root   INFO     Current min non-exhausted protected class samples 416 (min for early stop 100)\n",
      "2020-05-19 11:49:05,161 root   INFO     Batch run time per generation for instances 416 to 447: 0.07123\n",
      "2020-05-19 11:49:05,161 root   INFO     Current max sampling error 0.021226350581498507 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:49:05,162 root   INFO     Current min non-exhausted protected class samples 448 (min for early stop 100)\n",
      "2020-05-19 11:49:25,557 root   INFO     Batch run time per generation for instances 448 to 479: 0.07279\n",
      "2020-05-19 11:49:25,558 root   INFO     Current max sampling error 0.02072906437878101 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:49:25,559 root   INFO     Current min non-exhausted protected class samples 480 (min for early stop 100)\n",
      "2020-05-19 11:49:48,035 root   INFO     Batch run time per generation for instances 480 to 511: 0.07246\n",
      "2020-05-19 11:49:48,036 root   INFO     Current max sampling error 0.019979091643995712 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:49:48,037 root   INFO     Current min non-exhausted protected class samples 512 (min for early stop 100)\n",
      "2020-05-19 11:50:10,485 root   INFO     Batch run time per generation for instances 512 to 543: 0.07356\n",
      "2020-05-19 11:50:10,486 root   INFO     Current max sampling error 0.019382752490031463 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:50:10,486 root   INFO     Current min non-exhausted protected class samples 544 (min for early stop 100)\n",
      "2020-05-19 11:50:32,851 root   INFO     Batch run time per generation for instances 544 to 575: 0.07073\n",
      "2020-05-19 11:50:32,852 root   INFO     Current max sampling error 0.018835196718032885 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:50:32,853 root   INFO     Current min non-exhausted protected class samples 576 (min for early stop 100)\n",
      "2020-05-19 11:50:55,942 root   INFO     Batch run time per generation for instances 576 to 607: 0.07396\n",
      "2020-05-19 11:50:55,943 root   INFO     Current max sampling error 0.01822825239869026 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:50:55,944 root   INFO     Current min non-exhausted protected class samples 608 (min for early stop 100)\n",
      "2020-05-19 11:51:18,077 root   INFO     Batch run time per generation for instances 608 to 639: 0.07817\n",
      "2020-05-19 11:51:18,078 root   INFO     Current max sampling error 0.017668853226139664 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:51:18,079 root   INFO     Current min non-exhausted protected class samples 640 (min for early stop 100)\n",
      "2020-05-19 11:51:46,980 root   INFO     Batch run time per generation for instances 640 to 671: 0.08325\n",
      "2020-05-19 11:51:46,981 root   INFO     Current max sampling error 0.017219344340366174 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:51:46,982 root   INFO     Current min non-exhausted protected class samples 672 (min for early stop 100)\n",
      "2020-05-19 11:52:14,592 root   INFO     Batch run time per generation for instances 672 to 703: 0.09107\n",
      "2020-05-19 11:52:14,593 root   INFO     Current max sampling error 0.016849627151756107 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:52:14,594 root   INFO     Current min non-exhausted protected class samples 704 (min for early stop 100)\n",
      "2020-05-19 11:52:42,821 root   INFO     Batch run time per generation for instances 704 to 735: 0.08396\n",
      "2020-05-19 11:52:42,823 root   INFO     Current max sampling error 0.01654987556682525 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:52:42,824 root   INFO     Current min non-exhausted protected class samples 736 (min for early stop 100)\n",
      "2020-05-19 11:53:04,291 root   INFO     Batch run time per generation for instances 736 to 767: 0.07128\n",
      "2020-05-19 11:53:04,292 root   INFO     Current max sampling error 0.016204977851017172 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:53:04,293 root   INFO     Current min non-exhausted protected class samples 768 (min for early stop 100)\n",
      "2020-05-19 11:53:24,867 root   INFO     Batch run time per generation for instances 768 to 799: 0.07164\n",
      "2020-05-19 11:53:24,868 root   INFO     Current max sampling error 0.015854172571971345 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:53:24,869 root   INFO     Current min non-exhausted protected class samples 800 (min for early stop 100)\n",
      "2020-05-19 11:53:46,272 root   INFO     Batch run time per generation for instances 800 to 831: 0.07036\n",
      "2020-05-19 11:53:46,273 root   INFO     Current max sampling error 0.015577194578033382 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:53:46,273 root   INFO     Current min non-exhausted protected class samples 832 (min for early stop 100)\n",
      "2020-05-19 11:54:07,637 root   INFO     Batch run time per generation for instances 832 to 863: 0.06910\n",
      "2020-05-19 11:54:07,638 root   INFO     Current max sampling error 0.01521345671266213 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:54:07,639 root   INFO     Current min non-exhausted protected class samples 864 (min for early stop 100)\n",
      "2020-05-19 11:54:31,773 root   INFO     Batch run time per generation for instances 864 to 895: 0.08013\n",
      "2020-05-19 11:54:31,774 root   INFO     Current max sampling error 0.014934199922283157 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:54:31,774 root   INFO     Current min non-exhausted protected class samples 896 (min for early stop 100)\n",
      "2020-05-19 11:54:54,789 root   INFO     Batch run time per generation for instances 896 to 927: 0.07443\n",
      "2020-05-19 11:54:54,790 root   INFO     Current max sampling error 0.014589052446382422 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:54:54,792 root   INFO     Current min non-exhausted protected class samples 928 (min for early stop 100)\n",
      "2020-05-19 11:55:17,195 root   INFO     Batch run time per generation for instances 928 to 959: 0.07129\n",
      "2020-05-19 11:55:17,197 root   INFO     Current max sampling error 0.014489338621649204 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:55:17,198 root   INFO     Current min non-exhausted protected class samples 960 (min for early stop 100)\n",
      "2020-05-19 11:55:39,035 root   INFO     Batch run time per generation for instances 960 to 991: 0.07398\n",
      "2020-05-19 11:55:39,036 root   INFO     Current max sampling error 0.014204817945669423 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:55:39,037 root   INFO     Current min non-exhausted protected class samples 992 (min for early stop 100)\n",
      "2020-05-19 11:55:44,244 root   INFO     Batch run time per generation for instances 992 to 999: 0.06934\n",
      "2020-05-19 11:55:44,245 root   INFO     Current max sampling error 0.014144062895637606 (max for early stop 0.005102040816326531)\n",
      "2020-05-19 11:55:44,246 root   INFO     Current min non-exhausted protected class samples 1000 (min for early stop 100)\n",
      "2020-05-19 11:55:49,968 root   INFO     Estimating sample variance (2001 bags)\n",
      "2020-05-19 11:55:50,674 root   INFO     Robustness score is 0.9407599999999946\n",
      "2020-05-19 11:55:50,674 root   INFO     Model used: logistic_regression\n",
      "2020-05-19 11:55:50,675 root   INFO     CERScore is 1.542001366742597\n",
      "2020-05-19 11:55:50,676 root   INFO     NCERScore is 0.1096038884604268\n",
      "2020-05-19 11:55:50,676 root   INFO     Normalization constant is 14.068856391891119\n",
      "2020-05-19 11:55:50,678 root   INFO     Total run time in seconds: 707.2561123371124\n",
      "2020-05-19 11:55:50,679 root   INFO     Total Samples: 10485\n",
      "2020-05-19 11:55:50,680 root   INFO     Average feature reduction applied to counterfactuals: 0.016\n",
      "2020-05-19 11:55:50,731 root   INFO     Completed robustness report for model logistic_regression\n",
      "2020-05-19 11:55:50,735 root   INFO     Creating ATX report for model: logistic_regression\n",
      "2020-05-19 11:55:50,738 root   INFO     Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "#Run the Scan\n",
    "result = scan.run(write_reports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result is a dictionary keyed on analysis, containing reports keyed on model id (in our case 'local')**\n",
    "\n",
    "**We will be extracting the score information in the form of a DataFrame from this dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>overall fairness</th>\n",
       "      <th>Feature (age)</th>\n",
       "      <th>Group details (&lt;= 25 years)</th>\n",
       "      <th>Group details (&gt; 25 years)</th>\n",
       "      <th>Feature (status)</th>\n",
       "      <th>Group details (female : divorced/separated/married)</th>\n",
       "      <th>Group details (male : divorced/separated)</th>\n",
       "      <th>Group details (male : married/widowed)</th>\n",
       "      <th>Group details (male : single)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression (burden)</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>burden</td>\n",
       "      <td>67.319983</td>\n",
       "      <td>74.077726</td>\n",
       "      <td>0.090659</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>68.387879</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.044144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          context    type  overall fairness  \\\n",
       "logistic_regression (burden)  logistic_regression  burden         67.319983   \n",
       "\n",
       "                              Feature (age)  Group details (<= 25 years)  \\\n",
       "logistic_regression (burden)      74.077726                     0.090659   \n",
       "\n",
       "                              Group details (> 25 years)  Feature (status)  \\\n",
       "logistic_regression (burden)                    0.053191         68.387879   \n",
       "\n",
       "                              Group details (female : divorced/separated/married)  \\\n",
       "logistic_regression (burden)                                           0.088836     \n",
       "\n",
       "                              Group details (male : divorced/separated)  \\\n",
       "logistic_regression (burden)                                      0.105   \n",
       "\n",
       "                              Group details (male : married/widowed)  \\\n",
       "logistic_regression (burden)                                0.035294   \n",
       "\n",
       "                              Group details (male : single)  \n",
       "logistic_regression (burden)                       0.044144  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>robustness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>94.076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 context  robustness\n",
       "logistic_regression  logistic_regression      94.076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>explainability</th>\n",
       "      <th>Num features (1)</th>\n",
       "      <th>Num features (10)</th>\n",
       "      <th>Num features (2)</th>\n",
       "      <th>Num features (3)</th>\n",
       "      <th>Num features (4)</th>\n",
       "      <th>Num features (5)</th>\n",
       "      <th>Num features (6)</th>\n",
       "      <th>Num features (7)</th>\n",
       "      <th>Num features (8)</th>\n",
       "      <th>Num features (9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>94.5625</td>\n",
       "      <td>59.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>8.125</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 context  explainability  Num features (1)  \\\n",
       "logistic_regression  logistic_regression         94.5625           59.0625   \n",
       "\n",
       "                     Num features (10)  Num features (2)  Num features (3)  \\\n",
       "logistic_regression                0.0              32.5             8.125   \n",
       "\n",
       "                     Num features (4)  Num features (5)  Num features (6)  \\\n",
       "logistic_regression            0.3125               0.0               0.0   \n",
       "\n",
       "                     Num features (7)  Num features (8)  Num features (9)  \n",
       "logistic_regression               0.0               0.0               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = construct_scores_dataframe(scores('fairness', result), include_confidence=False)\n",
    "display(df)\n",
    "\n",
    "df = construct_scores_dataframe(scores('robustness', result), include_confidence=False)\n",
    "display(df)\n",
    "\n",
    "df = construct_scores_dataframe(scores('explainability', result), include_confidence=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (3) Creating the exportable scan object\n",
    "**Task 1) Next we'll make modify the scan definition to make it suitable for running against a version of the model deployed as a web service, and export this scan definition as a YAML file. We show how to  deploy the model as a web service and scan it using this scan definition file and the Certifai command line interface in Part 2 of this tutorial.**\n",
    "\n",
    "**The two things that need to be changed are:**\n",
    "- *predict_endpoint*: Since the model will be running in a web service, we need to provide the URL for its intended predict endpoint\n",
    "- *dataset url*: Similarly, since the data will be read from persistent storage rather than an already populated DataFrame, we'll need to modify the data source accordingly. If the URL is a relative file path, it will be interpreted relative to where the scan definition is stored.\n",
    "\n",
    "**Note that we could simply export the definition we have already, and add these fields to the resulting YAML (or have the deploying engineer do so), but it's a bit friendlier if we create placeholders that can be replaced later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.models[0].predict_endpoint = 'http://mymodel/predict'\n",
    "scan.datasets[0].source = CertifaiDatasetSource.csv('somefile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scan object contains the scan definition, which consists of all of the metadata needed to rerun the scan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Viewing the scan definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_schema:\n",
      "  outcome_column: outcome\n",
      "datasets:\n",
      "- dataset_id: evaluation\n",
      "  delimiter: ','\n",
      "  file_type: csv\n",
      "  has_header: true\n",
      "  quote_character: '\"'\n",
      "  url: somefile.csv\n",
      "evaluation:\n",
      "  evaluation_dataset_id: evaluation\n",
      "  evaluation_types:\n",
      "  - fairness\n",
      "  - explainability\n",
      "  - robustness\n",
      "  fairness_grouping_features:\n",
      "  - name: age\n",
      "  - name: status\n",
      "  name: test_user_case\n",
      "  prediction_description: Determine whether a loan should be granted\n",
      "  prediction_favorability: explicit\n",
      "  prediction_values:\n",
      "  - favorable: true\n",
      "    name: Loan granted\n",
      "    value: 1\n",
      "  - favorable: false\n",
      "    name: Loan denied\n",
      "    value: 2\n",
      "model_use_case:\n",
      "  model_use_case_id: test_user_case\n",
      "  name: test_user_case\n",
      "  task_type: binary-classification\n",
      "models:\n",
      "- model_id: logistic_regression\n",
      "  name: logistic_regression\n",
      "  predict_endpoint: http://mymodel/predict\n",
      "  prediction_value_order:\n",
      "  - 1\n",
      "  - 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scan.extract_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Save the Scan Definition locally.**\n",
    "\n",
    "**Save the scan definition to a file. The file path is relative to the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved template to: ./german_credit_definition.yaml\n"
     ]
    }
   ],
   "source": [
    "scan_file=\"./german_credit_definition.yaml\"\n",
    "with open(scan_file, \"w\") as f:\n",
    "    scan.save(f)\n",
    "    print(f\"Saved template to: {scan_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will see how to use this definition to kickstart scans in the CLI in part 2 of this tutorial.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
