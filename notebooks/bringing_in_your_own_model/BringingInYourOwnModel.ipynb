{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a scan programmatically with your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we will be demonstrating how to create a scan in Certifai using your own model. We will show some examples of how to use models and datasets to run scans**\n",
    "\n",
    "**Documentation for Certifai can be found at https://cognitivescale.github.io/cortex-certifai/docs/about**\n",
    "\n",
    "**To begin, we will import the libraries required to run Certifai scans via Jupyter Lab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from copy import copy\n",
    "import yaml\n",
    "\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For multiprocessing to work in a Notebook, we need the encoder to be outside of the notebook. This code imports the encoder in a way that works in hosted notebooks as well as locally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "from utils.cat_encoder import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP (1): Setting up the dataset and model to be scanned\n",
    "\n",
    "**Task 1): Setting up the dataset**\n",
    "\n",
    "**Load the data into a DataFrame for use in both training and later analysing the model. In this example we use the German Credit dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkingstatus</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>status</th>\n",
       "      <th>others</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>otherplans</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>job</th>\n",
       "      <th>liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>... &gt;= 200 DM / salary assignments for at leas...</td>\n",
       "      <td>6</td>\n",
       "      <td>critical account/ other credits existing (not ...</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1343</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>.. &gt;= 7 years</td>\n",
       "      <td>1</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>2</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>... &lt; 0 DM</td>\n",
       "      <td>28</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>4006</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>unskilled - resident</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>2284</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>4 &lt;= ... &lt; 7 years</td>\n",
       "      <td>4</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>1533</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>... &lt; 1 year</td>\n",
       "      <td>4</td>\n",
       "      <td>female : divorced/separated/married</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>stores</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>12</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1101</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : married/widowed</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      checkingstatus  duration  \\\n",
       "0  ... >= 200 DM / salary assignments for at leas...         6   \n",
       "1                                         ... < 0 DM        28   \n",
       "2                                no checking account        24   \n",
       "3                                no checking account        24   \n",
       "4                                no checking account        12   \n",
       "\n",
       "                                             history           purpose  \\\n",
       "0  critical account/ other credits existing (not ...         car (new)   \n",
       "1           existing credits paid back duly till now         car (new)   \n",
       "2           existing credits paid back duly till now  radio/television   \n",
       "3           existing credits paid back duly till now  radio/television   \n",
       "4           existing credits paid back duly till now         car (new)   \n",
       "\n",
       "   amount       savings              employ  installment  \\\n",
       "0    1343  ... < 100 DM       .. >= 7 years            1   \n",
       "1    4006  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "2    2284  ... < 100 DM  4 <= ... < 7 years            4   \n",
       "3    1533  ... < 100 DM        ... < 1 year            4   \n",
       "4    1101  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "\n",
       "                                status         others  ...  \\\n",
       "0                        male : single  others - none  ...   \n",
       "1                        male : single  others - none  ...   \n",
       "2                        male : single  others - none  ...   \n",
       "3  female : divorced/separated/married  others - none  ...   \n",
       "4               male : married/widowed  others - none  ...   \n",
       "\n",
       "                           property         age otherplans housing cards  \\\n",
       "0                       real estate  > 25 years       none     own     2   \n",
       "1  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "2  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "3  car or other, not in attribute 6  > 25 years     stores     own     1   \n",
       "4                       real estate  > 25 years       none     own     2   \n",
       "\n",
       "                           job liable  \\\n",
       "0  skilled employee / official      2   \n",
       "1         unskilled - resident      1   \n",
       "2  skilled employee / official      1   \n",
       "3  skilled employee / official      1   \n",
       "4  skilled employee / official      1   \n",
       "\n",
       "                                          telephone        foreign outcome  \n",
       "0                                      phone - none   foreign - no       1  \n",
       "1                                      phone - none  foreign - yes       2  \n",
       "2  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "3  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "4  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_file = \"datasets/german_credit_eval.csv\"\n",
    "df = pd.read_csv(all_data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2): Set the categorical columns of the dataset up for the encoder (in our case we will encapsulate this in the CatEncoder class, which may be found in the same directory as this notebook). We also note the column that contains the ground truth labels for training in 'label_column' (in this dataset this is 'outcome').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "label_column = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In our example we use a simple logistic classifier from sklearn. This is where you can add your own model. Rather than using the one provided, you can import and set up your model to be used here.**\n",
    "\n",
    "**Note that the predictor must be picklable.  Specifically if the predictor class itself is defined in a notebook rather than an imported module then it *must* be in a different notebook file for Python muti-processing to handle it correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Because the outcome column won't be presented to the model at prediction time we need to drop it from the dataset. We then split into a test and train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[label_column]\n",
    "X = df.drop(label_column, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Set the encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CatEncoder(cat_columns, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Fit the classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic classifier' accuracy is 0.76\n"
     ]
    }
   ],
   "source": [
    "def build_model(data, name, test=None):\n",
    "    if test is None:\n",
    "        test = data\n",
    "        \n",
    "\n",
    "    parameters = {'C': (0.5, 1.0, 2.0), 'solver': ['lbfgs'], 'max_iter': [1000]}\n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(data[0], data[1])\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(test[0], test[1].values)\n",
    "    print(f\"Model '{name}' accuracy is {accuracy}\")\n",
    "    return model\n",
    "\n",
    "logistic_model = build_model((encoder(X_train.values), y_train),\n",
    "                        'Logistic classifier',\n",
    "                        test=(encoder(X_test.values), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Wrap up the model and the encoder so that Certifai sees it as part of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_proxy = CertifaiPredictorWrapper(logistic_model, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Compute model's accuracy with the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier model accuracy on test data is 0.76\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = logistic_model.score(encoder(X_test.values), y_test.values)\n",
    "print(f\"Logistic classifier model accuracy on test data is {logistic_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (2) Create the scan object using the ScanBuilder class\n",
    "\n",
    "**To allow easy working with Certifai from notebooks, or other programmatic use cases, the `ScanBuilder` class abstracts the scan definition and provides an object model to manipulate it.  Building up a definition in this way allows either direct running of the scan in the notebook, or export as a scan definition file, which can be run by the Certifai scanner.**\n",
    "\n",
    "**Task 1) Define the outcomes of the classification task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Create the Certifai scan object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Create the Certifai dataset from the local dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(all_data_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Create the Certifai model from the local model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our local model\n",
    "first_model = CertifaiModel('local',\n",
    "                            local_predictor=logistic_model_proxy)\n",
    "scan.add_model(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Setup an evaluation for fairness, robustness, and explainability on the above dataset using the model**\n",
    "\n",
    "**We can have one or many of the following analysis types:**\n",
    "- fairness\n",
    "- robustness\n",
    "- explainability\n",
    "- explanation\n",
    "- performance\n",
    "\n",
    "**More information on these analyses can be found at our docs: https://cognitivescale.github.io/cortex-certifai/docs/factors/fairness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.add_dataset(eval_dataset)\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.add_evaluation_type('explainability')\n",
    "scan.add_evaluation_type('robustness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Because the dataset contains a ground truth outcome column which the model does not expect to receive as input we need to state that in the dataset schema (since it cannot be inferred from the CSV) so that the scan can be rerun from the definition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Run the scan. \n",
    "    By default this will write the results into individual report files (one per model and evaluation\n",
    "    type) in the 'reports' directory relative to the notebook.  This may be disabled by specifying\n",
    "    `write_reports=False` as below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 15:50:12,086 root   INFO     Validating license...\n",
      "2020-05-11 15:50:12,100 root   INFO     License is valid - expires: n/a\n",
      "2020-05-11 15:50:12,120 root   INFO     Generated unique scan id: 5bfab52f58ec\n",
      "2020-05-11 15:50:12,122 root   INFO     Validating input data...\n",
      "2020-05-11 15:50:12,123 root   INFO     Creating dataset with id: evaluation\n",
      "2020-05-11 15:50:12,149 root   INFO     Inferring dataset features and applying user overrides\n",
      "2020-05-11 15:50:12,152 root   INFO     Reading configs from: /Users/npasricha/.certifai/certifai_config.ini\n",
      "2020-05-11 15:50:12,154 root   INFO     Reading default config (fallback) from: /Users/npasricha/miniconda3/envs/certifai/lib/python3.6/site-packages/certifai/common/utils/default_certifai_config.ini\n",
      "2020-05-11 15:50:12,156 root   INFO     Read config marker: config['default']['marker'] = 0.1\n",
      "2020-05-11 15:50:12,159 root   INFO     Integer-valued feature 'duration' inferred to be numeric (sample cardinality 33)\n",
      "2020-05-11 15:50:12,163 root   INFO     Integer-valued feature 'amount' inferred to be numeric (sample cardinality 921)\n",
      "2020-05-11 15:50:12,164 root   INFO     Integer-valued feature 'installment' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-11 15:50:12,166 root   INFO     Integer-valued feature 'residence' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-11 15:50:12,171 root   INFO     Integer-valued feature 'cards' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-11 15:50:12,174 root   INFO     Integer-valued feature 'liable' inferred to be categorical (sample cardinality 2)\n",
      "2020-05-11 15:50:12,176 root   INFO     Integer-valued feature 'outcome' inferred to be categorical (sample cardinality 2)\n",
      "2020-05-11 15:50:12,179 root   WARNING  Couldn't find column by label as index: `outcome`, in df.columns: `Index(['checkingstatus', 'duration', 'history', 'purpose', 'amount', 'savings',\n",
      "       'employ', 'installment', 'status', 'others', 'residence', 'property',\n",
      "       'age', 'otherplans', 'housing', 'cards', 'job', 'liable', 'telephone',\n",
      "       'foreign'],\n",
      "      dtype='object')`.\n",
      "2020-05-11 15:50:12,181 root   INFO     Inferring dataset features and applying user overrides\n",
      "2020-05-11 15:50:12,184 root   INFO     Integer-valued feature 'duration' inferred to be numeric (sample cardinality 33)\n",
      "2020-05-11 15:50:12,187 root   INFO     Integer-valued feature 'amount' inferred to be numeric (sample cardinality 921)\n",
      "2020-05-11 15:50:12,189 root   INFO     Integer-valued feature 'installment' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-11 15:50:12,191 root   INFO     Integer-valued feature 'residence' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-11 15:50:12,194 root   INFO     Integer-valued feature 'cards' inferred to be categorical (sample cardinality 4)\n",
      "2020-05-11 15:50:12,196 root   INFO     Integer-valued feature 'liable' inferred to be categorical (sample cardinality 2)\n",
      "2020-05-11 15:50:12,203 root   INFO     Input validation complete\n",
      "2020-05-11 15:50:12,203 root   INFO     Beginning to perform evaluations\n",
      "2020-05-11 15:50:12,204 root   INFO     performing evaluation: fairness, for model: local\n",
      "2020-05-11 15:50:12,231 root   INFO     Validating license...\n",
      "2020-05-11 15:50:12,233 root   INFO     License is valid - expires: n/a\n",
      "2020-05-11 15:50:12,235 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.PARTITIONED (analysis = Fairness)\n",
      "2020-05-11 15:50:12,236 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-11 15:50:12,237 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-11 15:50:12,255 root   WARNING  Insufficient examples of some fairness classes to guarantee convergence (smallest class size is for 'male : divorced/separated' with 50 samples)\n",
      "2020-05-11 15:50:12,267 root   INFO     Running analysis variant 'prediction more beneficial'\n",
      "2020-05-11 15:50:13,995 root   INFO     Running with explanation reduction ON\n",
      "2020-05-11 15:50:13,996 root   INFO     Total dataset size is 1000\n",
      "2020-05-11 15:50:33,980 root   INFO     Batch run time per generation for instances 0 to 119: 0.08525\n",
      "2020-05-11 15:50:33,980 root   INFO     Current max sampling error 0.3749999793750012 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:50:33,981 root   INFO     Current min non-exhausted protected class samples 27 (min for early stop 100)\n",
      "2020-05-11 15:50:50,865 root   INFO     Batch run time per generation for instances 120 to 256: 0.07623\n",
      "2020-05-11 15:50:50,866 root   WARNING  Examples of protected class (8, 'male : divorced/separated') exhausted before convergence after 50 samples\n",
      "2020-05-11 15:50:50,867 root   INFO     Current max sampling error 0.31031642438453 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:50:50,868 root   INFO     Current min non-exhausted protected class samples 61 (min for early stop 100)\n",
      "2020-05-11 15:51:07,090 root   INFO     Batch run time per generation for instances 257 to 416: 0.07189\n",
      "2020-05-11 15:51:07,091 root   WARNING  Examples of protected class (8, 'male : married/widowed') exhausted before convergence after 92 samples\n",
      "2020-05-11 15:51:07,092 root   INFO     Current max sampling error 0.2068770298848812 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:51:07,093 root   INFO     Current min non-exhausted protected class samples 128 (min for early stop 100)\n",
      "2020-05-11 15:51:23,650 root   INFO     Batch run time per generation for instances 417 to 507: 0.07216\n",
      "2020-05-11 15:51:23,656 root   INFO     Current max sampling error 0.15953065063372715 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:51:23,657 root   INFO     Current min non-exhausted protected class samples 158 (min for early stop 100)\n",
      "2020-05-11 15:51:39,748 root   INFO     Batch run time per generation for instances 508 to 628: 0.07295\n",
      "2020-05-11 15:51:39,754 root   WARNING  Examples of protected class (12, '<= 25 years') exhausted before convergence after 190 samples\n",
      "2020-05-11 15:51:39,755 root   INFO     Current max sampling error 0.13428744550517044 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:51:39,756 root   INFO     Current min non-exhausted protected class samples 243 (min for early stop 100)\n",
      "2020-05-11 15:51:57,519 root   INFO     Batch run time per generation for instances 629 to 773: 0.07372\n",
      "2020-05-11 15:51:57,520 root   INFO     Current max sampling error 0.12022695360352868 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:51:57,521 root   INFO     Current min non-exhausted protected class samples 305 (min for early stop 100)\n",
      "2020-05-11 15:52:15,951 root   INFO     Batch run time per generation for instances 774 to 982: 0.08498\n",
      "2020-05-11 15:52:15,952 root   WARNING  Examples of protected class (8, 'female : divorced/separated/married') exhausted before convergence after 310 samples\n",
      "2020-05-11 15:52:15,953 root   INFO     Current max sampling error 0.0985571025511247 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:52:15,954 root   INFO     Current min non-exhausted protected class samples 531 (min for early stop 100)\n",
      "2020-05-11 15:52:18,160 root   INFO     Batch run time per generation for instances 983 to 999: 0.08789\n",
      "2020-05-11 15:52:18,161 root   WARNING  Examples of protected class (12, '> 25 years') exhausted before convergence after 810 samples\n",
      "2020-05-11 15:52:18,161 root   WARNING  Examples of protected class (8, 'male : single') exhausted before convergence after 548 samples\n",
      "2020-05-11 15:52:18,162 root   INFO     Early stopping after running 1000 instances\n",
      "2020-05-11 15:52:18,177 root   INFO     Estimating sample variance (2001 bags)\n",
      "2020-05-11 15:52:30,410 root   INFO     Group Burden is [{'feature': 'age', 'groups': [{'label': '<= 25 years', 'value': 0.09065934065934066, 'value_confidence_95_lower': 0.07535885167464115, 'value_confidence_95_upper': 0.10657894736842105, 'values': [0.09065934065934066], 'values_confidence_95_lower': [0.07535885167464115], 'values_confidence_95_upper': [0.10657894736842105], 'values_names': ['burden']}, {'label': '> 25 years', 'value': 0.05319148936170213, 'value_confidence_95_lower': 0.046625766871165646, 'value_confidence_95_upper': 0.0594944512946979, 'values': [0.05319148936170213], 'values_confidence_95_lower': [0.046625766871165646], 'values_confidence_95_upper': [0.0594944512946979], 'values_names': ['burden']}]}, {'feature': 'status', 'groups': [{'label': 'female : divorced/separated/married', 'value': 0.08883647798742138, 'value_confidence_95_lower': 0.07653061224489796, 'value_confidence_95_upper': 0.10096153846153846, 'values': [0.08883647798742138], 'values_confidence_95_lower': [0.07653061224489796], 'values_confidence_95_upper': [0.10096153846153846], 'values_names': ['burden']}, {'label': 'male : divorced/separated', 'value': 0.105, 'value_confidence_95_lower': 0.07407407407407407, 'value_confidence_95_upper': 0.13679245283018868, 'values': [0.105], 'values_confidence_95_lower': [0.07407407407407407], 'values_confidence_95_upper': [0.13679245283018868], 'values_names': ['burden']}, {'label': 'male : married/widowed', 'value': 0.03529411764705882, 'value_confidence_95_lower': 0.020348837209302327, 'value_confidence_95_upper': 0.05, 'values': [0.03529411764705882], 'values_confidence_95_lower': [0.020348837209302327], 'values_confidence_95_upper': [0.05], 'values_names': ['burden']}, {'label': 'male : single', 'value': 0.044144144144144144, 'value_confidence_95_lower': 0.03742802303262956, 'value_confidence_95_upper': 0.05136363636363636, 'values': [0.044144144144144144], 'values_confidence_95_lower': [0.03742802303262956], 'values_confidence_95_upper': [0.05136363636363636], 'values_names': ['burden']}]}]\n",
      "2020-05-11 15:52:30,416 root   INFO     Feature fairnesses are [{'feature': 'age', 'value': 74.07772574151672, 'value_confidence_95_lower': 64.34474349710983, 'value_confidence_95_upper': 84.42549371633751}, {'feature': 'status', 'value': 68.38787882659712, 'value_confidence_95_lower': 58.80694951727081, 'value_confidence_95_upper': 77.8514438311028}]\n",
      "2020-05-11 15:52:30,417 root   INFO     Model used: local\n",
      "2020-05-11 15:52:30,418 root   INFO     CERScore is 1.0570175438596492\n",
      "2020-05-11 15:52:30,418 root   INFO     NCERScore is 0.07723889367830424\n",
      "2020-05-11 15:52:30,419 root   INFO     Normalization constant is 13.685042515783168\n",
      "2020-05-11 15:52:30,420 root   INFO     Total run time in seconds: 125.93060517311096\n",
      "2020-05-11 15:52:30,420 root   INFO     Total Samples: 1838\n",
      "2020-05-11 15:52:30,421 root   INFO     Average feature reduction applied to counterfactuals: 0.0\n",
      "2020-05-11 15:52:30,533 root   INFO     Completed fairness report for model local\n",
      "2020-05-11 15:52:30,537 root   INFO     performing evaluation: explainability, for model: local\n",
      "2020-05-11 15:52:30,564 root   INFO     Validating license...\n",
      "2020-05-11 15:52:30,565 root   INFO     License is valid - expires: n/a\n",
      "2020-05-11 15:52:30,567 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.PARTITIONED (analysis = Explainability)\n",
      "2020-05-11 15:52:30,568 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-11 15:52:30,569 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-11 15:52:30,582 root   INFO     Running analysis variant 'prediction changed'\n",
      "2020-05-11 15:52:32,566 root   INFO     Running with explanation reduction ON\n",
      "2020-05-11 15:52:32,567 root   INFO     Total dataset size is 1000\n",
      "2020-05-11 15:52:56,496 root   INFO     Batch run time per generation for instances 0 to 31: 0.07894\n",
      "2020-05-11 15:52:56,503 root   INFO     Current max sampling error 0.06546639277031954 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:52:56,504 root   INFO     Current min non-exhausted protected class samples 32 (min for early stop 100)\n",
      "2020-05-11 15:53:15,043 root   INFO     Batch run time per generation for instances 32 to 63: 0.06411\n",
      "2020-05-11 15:53:15,044 root   INFO     Current max sampling error 0.05031911907274441 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:53:15,045 root   INFO     Current min non-exhausted protected class samples 64 (min for early stop 100)\n",
      "2020-05-11 15:53:33,828 root   INFO     Batch run time per generation for instances 64 to 95: 0.06586\n",
      "2020-05-11 15:53:33,828 root   INFO     Current max sampling error 0.042420376901320216 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:53:33,829 root   INFO     Current min non-exhausted protected class samples 96 (min for early stop 100)\n",
      "2020-05-11 15:53:54,144 root   INFO     Batch run time per generation for instances 96 to 127: 0.06384\n",
      "2020-05-11 15:53:54,145 root   INFO     Current max sampling error 0.03896660347622054 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:53:54,146 root   INFO     Current min non-exhausted protected class samples 128 (min for early stop 100)\n",
      "2020-05-11 15:54:13,375 root   INFO     Batch run time per generation for instances 128 to 159: 0.06321\n",
      "2020-05-11 15:54:13,376 root   INFO     Current max sampling error 0.035014803086598774 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:54:13,377 root   INFO     Current min non-exhausted protected class samples 160 (min for early stop 100)\n",
      "2020-05-11 15:54:32,278 root   INFO     Batch run time per generation for instances 160 to 191: 0.06403\n",
      "2020-05-11 15:54:32,279 root   INFO     Current max sampling error 0.031137693081705983 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:54:32,279 root   INFO     Current min non-exhausted protected class samples 192 (min for early stop 100)\n",
      "2020-05-11 15:54:52,451 root   INFO     Batch run time per generation for instances 192 to 223: 0.06340\n",
      "2020-05-11 15:54:52,452 root   INFO     Current max sampling error 0.029287437469205934 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:54:52,452 root   INFO     Current min non-exhausted protected class samples 224 (min for early stop 100)\n",
      "2020-05-11 15:55:11,066 root   INFO     Batch run time per generation for instances 224 to 255: 0.06839\n",
      "2020-05-11 15:55:11,067 root   INFO     Current max sampling error 0.027564588088237054 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:55:11,067 root   INFO     Current min non-exhausted protected class samples 256 (min for early stop 100)\n",
      "2020-05-11 15:55:31,720 root   INFO     Batch run time per generation for instances 256 to 287: 0.06835\n",
      "2020-05-11 15:55:31,721 root   INFO     Current max sampling error 0.025846244336746142 (max for early stop 0.025510204081632654)\n",
      "2020-05-11 15:55:31,722 root   INFO     Current min non-exhausted protected class samples 288 (min for early stop 100)\n",
      "2020-05-11 15:55:50,010 root   INFO     Batch run time per generation for instances 288 to 319: 0.06346\n",
      "2020-05-11 15:55:50,011 root   INFO     Protected class (1.0,) now converged after 320 samples\n",
      "2020-05-11 15:55:50,012 root   INFO     Early stopping after running 320 instances\n",
      "2020-05-11 15:55:50,014 root   INFO     Model used: local\n",
      "2020-05-11 15:55:50,015 root   INFO     CERScore is 1.4963297266514808\n",
      "2020-05-11 15:55:50,016 root   INFO     NCERScore is 0.10635759474479545\n",
      "2020-05-11 15:55:50,017 root   INFO     Normalization constant is 14.068856391891119\n",
      "2020-05-11 15:55:50,018 root   INFO     Total run time in seconds: 199.44613909721375\n",
      "2020-05-11 15:55:50,019 root   INFO     Total Samples: 3294\n",
      "2020-05-11 15:55:50,020 root   INFO     Average feature reduction applied to counterfactuals: 0.021875\n",
      "2020-05-11 15:55:50,075 root   INFO     Completed explainability report for model local\n",
      "2020-05-11 15:55:50,079 root   INFO     performing evaluation: robustness, for model: local\n",
      "2020-05-11 15:55:50,106 root   INFO     Validating license...\n",
      "2020-05-11 15:55:50,109 root   INFO     License is valid - expires: n/a\n",
      "2020-05-11 15:55:50,111 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.UNSTRUCTURED (analysis = Robustness)\n",
      "2020-05-11 15:55:50,112 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-11 15:55:50,115 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-11 15:55:50,138 root   INFO     Running analysis variant 'prediction changed'\n",
      "2020-05-11 15:55:52,012 root   INFO     Running with explanation reduction ON\n",
      "2020-05-11 15:55:52,013 root   INFO     Total dataset size is 1000\n",
      "2020-05-11 15:56:14,867 root   INFO     Batch run time per generation for instances 0 to 31: 0.07540\n",
      "2020-05-11 15:56:14,868 root   INFO     Current max sampling error 0.06546639277031954 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:56:14,868 root   INFO     Current min non-exhausted protected class samples 32 (min for early stop 100)\n",
      "2020-05-11 15:56:33,182 root   INFO     Batch run time per generation for instances 32 to 63: 0.06334\n",
      "2020-05-11 15:56:33,185 root   INFO     Current max sampling error 0.05031911907274441 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:56:33,186 root   INFO     Current min non-exhausted protected class samples 64 (min for early stop 100)\n",
      "2020-05-11 15:56:52,657 root   INFO     Batch run time per generation for instances 64 to 95: 0.06828\n",
      "2020-05-11 15:56:52,658 root   INFO     Current max sampling error 0.042426594774731714 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:56:52,658 root   INFO     Current min non-exhausted protected class samples 96 (min for early stop 100)\n",
      "2020-05-11 15:57:13,097 root   INFO     Batch run time per generation for instances 96 to 127: 0.06423\n",
      "2020-05-11 15:57:13,098 root   INFO     Current max sampling error 0.03899078371987135 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:57:13,099 root   INFO     Current min non-exhausted protected class samples 128 (min for early stop 100)\n",
      "2020-05-11 15:57:34,348 root   INFO     Batch run time per generation for instances 128 to 159: 0.06987\n",
      "2020-05-11 15:57:34,349 root   INFO     Current max sampling error 0.03503241401005545 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:57:34,350 root   INFO     Current min non-exhausted protected class samples 160 (min for early stop 100)\n",
      "2020-05-11 15:57:54,486 root   INFO     Batch run time per generation for instances 160 to 191: 0.06821\n",
      "2020-05-11 15:57:54,487 root   INFO     Current max sampling error 0.03125178863464429 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:57:54,487 root   INFO     Current min non-exhausted protected class samples 192 (min for early stop 100)\n",
      "2020-05-11 15:58:16,506 root   INFO     Batch run time per generation for instances 192 to 223: 0.06919\n",
      "2020-05-11 15:58:16,508 root   INFO     Current max sampling error 0.029384028228660534 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:58:16,508 root   INFO     Current min non-exhausted protected class samples 224 (min for early stop 100)\n",
      "2020-05-11 15:58:35,871 root   INFO     Batch run time per generation for instances 224 to 255: 0.07114\n",
      "2020-05-11 15:58:35,872 root   INFO     Current max sampling error 0.0276445435811736 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:58:35,873 root   INFO     Current min non-exhausted protected class samples 256 (min for early stop 100)\n",
      "2020-05-11 15:59:00,226 root   INFO     Batch run time per generation for instances 256 to 287: 0.08060\n",
      "2020-05-11 15:59:00,227 root   INFO     Current max sampling error 0.02591420282092695 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:59:00,227 root   INFO     Current min non-exhausted protected class samples 288 (min for early stop 100)\n",
      "2020-05-11 15:59:21,383 root   INFO     Batch run time per generation for instances 288 to 319: 0.07338\n",
      "2020-05-11 15:59:21,385 root   INFO     Current max sampling error 0.024621342221024915 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:59:21,386 root   INFO     Current min non-exhausted protected class samples 320 (min for early stop 100)\n",
      "2020-05-11 15:59:44,934 root   INFO     Batch run time per generation for instances 320 to 351: 0.07265\n",
      "2020-05-11 15:59:44,935 root   INFO     Current max sampling error 0.023707513830576427 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 15:59:44,937 root   INFO     Current min non-exhausted protected class samples 352 (min for early stop 100)\n",
      "2020-05-11 16:00:07,881 root   INFO     Batch run time per generation for instances 352 to 383: 0.07350\n",
      "2020-05-11 16:00:07,882 root   INFO     Current max sampling error 0.02294794940631691 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:00:07,882 root   INFO     Current min non-exhausted protected class samples 384 (min for early stop 100)\n",
      "2020-05-11 16:00:27,575 root   INFO     Batch run time per generation for instances 384 to 415: 0.06717\n",
      "2020-05-11 16:00:27,576 root   INFO     Current max sampling error 0.022245367638674435 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:00:27,577 root   INFO     Current min non-exhausted protected class samples 416 (min for early stop 100)\n",
      "2020-05-11 16:00:47,153 root   INFO     Batch run time per generation for instances 416 to 447: 0.06632\n",
      "2020-05-11 16:00:47,154 root   INFO     Current max sampling error 0.021226350581498507 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:00:47,155 root   INFO     Current min non-exhausted protected class samples 448 (min for early stop 100)\n",
      "2020-05-11 16:01:08,804 root   INFO     Batch run time per generation for instances 448 to 479: 0.07728\n",
      "2020-05-11 16:01:08,805 root   INFO     Current max sampling error 0.02072906437878101 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:01:08,807 root   INFO     Current min non-exhausted protected class samples 480 (min for early stop 100)\n",
      "2020-05-11 16:01:30,572 root   INFO     Batch run time per generation for instances 480 to 511: 0.07017\n",
      "2020-05-11 16:01:30,573 root   INFO     Current max sampling error 0.019979091643995712 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:01:30,574 root   INFO     Current min non-exhausted protected class samples 512 (min for early stop 100)\n",
      "2020-05-11 16:01:51,017 root   INFO     Batch run time per generation for instances 512 to 543: 0.06699\n",
      "2020-05-11 16:01:51,018 root   INFO     Current max sampling error 0.019382752490031463 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:01:51,019 root   INFO     Current min non-exhausted protected class samples 544 (min for early stop 100)\n",
      "2020-05-11 16:02:11,570 root   INFO     Batch run time per generation for instances 544 to 575: 0.06499\n",
      "2020-05-11 16:02:11,571 root   INFO     Current max sampling error 0.018835196718032885 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:02:11,572 root   INFO     Current min non-exhausted protected class samples 576 (min for early stop 100)\n",
      "2020-05-11 16:02:31,945 root   INFO     Batch run time per generation for instances 576 to 607: 0.06525\n",
      "2020-05-11 16:02:31,946 root   INFO     Current max sampling error 0.01822825239869026 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:02:31,947 root   INFO     Current min non-exhausted protected class samples 608 (min for early stop 100)\n",
      "2020-05-11 16:02:51,221 root   INFO     Batch run time per generation for instances 608 to 639: 0.06807\n",
      "2020-05-11 16:02:51,222 root   INFO     Current max sampling error 0.017668853226139664 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:02:51,223 root   INFO     Current min non-exhausted protected class samples 640 (min for early stop 100)\n",
      "2020-05-11 16:03:13,314 root   INFO     Batch run time per generation for instances 640 to 671: 0.06363\n",
      "2020-05-11 16:03:13,315 root   INFO     Current max sampling error 0.017219344340366174 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:03:13,316 root   INFO     Current min non-exhausted protected class samples 672 (min for early stop 100)\n",
      "2020-05-11 16:03:32,907 root   INFO     Batch run time per generation for instances 672 to 703: 0.06460\n",
      "2020-05-11 16:03:32,908 root   INFO     Current max sampling error 0.016849627151756107 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:03:32,908 root   INFO     Current min non-exhausted protected class samples 704 (min for early stop 100)\n",
      "2020-05-11 16:03:54,253 root   INFO     Batch run time per generation for instances 704 to 735: 0.06347\n",
      "2020-05-11 16:03:54,255 root   INFO     Current max sampling error 0.01654987556682525 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:03:54,255 root   INFO     Current min non-exhausted protected class samples 736 (min for early stop 100)\n",
      "2020-05-11 16:04:13,872 root   INFO     Batch run time per generation for instances 736 to 767: 0.06512\n",
      "2020-05-11 16:04:13,873 root   INFO     Current max sampling error 0.016204977851017172 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:04:13,874 root   INFO     Current min non-exhausted protected class samples 768 (min for early stop 100)\n",
      "2020-05-11 16:04:33,223 root   INFO     Batch run time per generation for instances 768 to 799: 0.06738\n",
      "2020-05-11 16:04:33,224 root   INFO     Current max sampling error 0.015854172571971345 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:04:33,225 root   INFO     Current min non-exhausted protected class samples 800 (min for early stop 100)\n",
      "2020-05-11 16:04:53,658 root   INFO     Batch run time per generation for instances 800 to 831: 0.06718\n",
      "2020-05-11 16:04:53,659 root   INFO     Current max sampling error 0.015577194578033382 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:04:53,660 root   INFO     Current min non-exhausted protected class samples 832 (min for early stop 100)\n",
      "2020-05-11 16:05:13,116 root   INFO     Batch run time per generation for instances 832 to 863: 0.06292\n",
      "2020-05-11 16:05:13,117 root   INFO     Current max sampling error 0.01521345671266213 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:05:13,118 root   INFO     Current min non-exhausted protected class samples 864 (min for early stop 100)\n",
      "2020-05-11 16:05:32,518 root   INFO     Batch run time per generation for instances 864 to 895: 0.06440\n",
      "2020-05-11 16:05:32,518 root   INFO     Current max sampling error 0.014934199922283157 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:05:32,519 root   INFO     Current min non-exhausted protected class samples 896 (min for early stop 100)\n",
      "2020-05-11 16:05:53,120 root   INFO     Batch run time per generation for instances 896 to 927: 0.06662\n",
      "2020-05-11 16:05:53,121 root   INFO     Current max sampling error 0.014589052446382422 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:05:53,122 root   INFO     Current min non-exhausted protected class samples 928 (min for early stop 100)\n",
      "2020-05-11 16:06:13,708 root   INFO     Batch run time per generation for instances 928 to 959: 0.06550\n",
      "2020-05-11 16:06:13,709 root   INFO     Current max sampling error 0.014489338621649204 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:06:13,709 root   INFO     Current min non-exhausted protected class samples 960 (min for early stop 100)\n",
      "2020-05-11 16:06:33,250 root   INFO     Batch run time per generation for instances 960 to 991: 0.06620\n",
      "2020-05-11 16:06:33,253 root   INFO     Current max sampling error 0.014204817945669423 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:06:33,254 root   INFO     Current min non-exhausted protected class samples 992 (min for early stop 100)\n",
      "2020-05-11 16:06:38,398 root   INFO     Batch run time per generation for instances 992 to 999: 0.06843\n",
      "2020-05-11 16:06:38,399 root   INFO     Current max sampling error 0.014144062895637606 (max for early stop 0.005102040816326531)\n",
      "2020-05-11 16:06:38,400 root   INFO     Current min non-exhausted protected class samples 1000 (min for early stop 100)\n",
      "2020-05-11 16:06:43,548 root   INFO     Estimating sample variance (2001 bags)\n",
      "2020-05-11 16:06:44,247 root   INFO     Robustness score is 0.9407599999999946\n",
      "2020-05-11 16:06:44,248 root   INFO     Model used: local\n",
      "2020-05-11 16:06:44,249 root   INFO     CERScore is 1.542001366742597\n",
      "2020-05-11 16:06:44,249 root   INFO     NCERScore is 0.1096038884604268\n",
      "2020-05-11 16:06:44,250 root   INFO     Normalization constant is 14.068856391891119\n",
      "2020-05-11 16:06:44,251 root   INFO     Total run time in seconds: 648.2969250679016\n",
      "2020-05-11 16:06:44,252 root   INFO     Total Samples: 10485\n",
      "2020-05-11 16:06:44,252 root   INFO     Average feature reduction applied to counterfactuals: 0.016\n",
      "2020-05-11 16:06:44,282 root   INFO     Completed robustness report for model local\n",
      "2020-05-11 16:06:44,310 root   INFO     Creating ATX report for model: local\n",
      "2020-05-11 16:06:44,328 root   INFO     Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "#Run the Scan\n",
    "result = scan.run(write_reports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result is a dictionary keyed on analysis, containing reports keyed on model id (in our case 'local')**\n",
    "\n",
    "**We will be extracting the score information in the form of a DataFrame from this dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = construct_scores_dataframe(scores('fairness', result), include_confidence=False)\n",
    "display(df)\n",
    "\n",
    "df = construct_scores_dataframe(scores('robustness', result), include_confidence=False)\n",
    "display(df)\n",
    "\n",
    "df = construct_scores_dataframe(scores('explainability', result), include_confidence=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (3) Creating the exportable scan object\n",
    "**Task 1) Next we'll make modify the scan definition to make it suitable for running against a version of the model deployed as a web service, and export this scan definition as a YAML file. We show how to  deploy the model as a web service and scan it using this scan definition file and the Certifai command line interface in Part 2 of this tutorial.**\n",
    "\n",
    "**The two things that need to be changed are:**\n",
    "- *predict_endpoint*: Since the model will be running in a web service, we need to provide the URL for its intended predict endpoint\n",
    "- *dataset url*: Similarly, since the data will be read from persistent storage rather than an already populated DataFrame, we'll need to modify the data source accordingly. If the URL is a relative file path, it will be interpreted relative to where the scan definition is stored.\n",
    "\n",
    "**Note that we could simply export the definition we have already, and add these fields to the resulting YAML (or have the deploying engineer do so), but it's a bit friendlier if we create placeholders that can be replaced later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.models[0].predict_endpoint = 'http://mymodel/predict'\n",
    "scan.datasets[0].source = CertifaiDatasetSource.csv('somefile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scan object contains the scan definition, which consists of all of the metadata needed to rerun the scan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Viewing the scan definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan.extract_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Save the Scan Definition locally.**\n",
    "\n",
    "**Save the scan definition to a file. The file path is relative to the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_file=\"./my_scan_definition.yaml\"\n",
    "with open(scan_file, \"w\") as f:\n",
    "    scan.save(f)\n",
    "    print(f\"Saved template to: {scan_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will see how to use this definition to kickstart scans in the CLI in part 2 of this tutorial.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
