{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022. Cognitive Scale Inc. All rights reserved.Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/master/LICENSE.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data for Data Statistics and Drift Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate Certifai's `data_statistics` evaluation type, we synthetically insert distributional shifts (i.e. drift), unexpected values, and missing values (i.e. NaN) into the UCI Adult Income dataset (48842 data rows, 13 features, https://archive.ics.uci.edu/ml/datasets/Adult). In this example scenario, we will create a model to predict whether a person makes over 50K a year, and then monitor the data and predictions over various (monitored) datasets to analyze changes in data statistics and drift.\n",
    "\n",
    "To mimic drift, we process the data over the monitored datasets in a few ways: <br>\n",
    "(1) for categorical variables, we swap categorical values, <br>\n",
    "(2) for numerical variables, we inject Gaussian noise, and <br>\n",
    "(3) for predictions, we swap class labels in classification tasks or inject Gaussian noise into predicted values in regression problems.\n",
    "\n",
    "By compounding the distributional shifts across the monitored datasets, we can generate a drift in the features and predictions over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Data Processing:\n",
    "(1) Set the Reference Dataset, <br>\n",
    "(2) Create a Prediction Model from the Reference Dataset,  <br>\n",
    "(3) Gather the Monitored Datasets, and <br>\n",
    "(4) Inject Data Drift and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:00.424119Z",
     "iopub.status.busy": "2023-01-05T19:12:00.423804Z",
     "iopub.status.idle": "2023-01-05T19:12:01.130079Z",
     "shell.execute_reply": "2023-01-05T19:12:01.129138Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from certifai.common.utils.encoding import CatEncoder\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:01.133382Z",
     "iopub.status.busy": "2023-01-05T19:12:01.133173Z",
     "iopub.status.idle": "2023-01-05T19:12:01.136424Z",
     "shell.execute_reply": "2023-01-05T19:12:01.135890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup the data folders\n",
    "DATASET_DIR = './data/adult'\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Set the Reference Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a sample of 6000 observations (~12%) of the UCI Adult Income Dataset as the \"reference dataset\". The drift statistics will be calculated with this as a baseline.\n",
    "\n",
    "Pre-processing notes:\n",
    "- `fnlwgt` is a generated feature (created by the census bureau) aimed to allocate similar weights to people with similar demographic characteristics (\"final weight\"). Literature has shown that this feature has no predictive power and is generally removed since it's not part of the collected data.\n",
    "\n",
    "- `education-num` encodes the same information as education so we remove it to prevent correlation effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:01.139572Z",
     "iopub.status.busy": "2023-01-05T19:12:01.139385Z",
     "iopub.status.idle": "2023-01-05T19:12:01.280592Z",
     "shell.execute_reply": "2023-01-05T19:12:01.279638Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_file = f\"../datasets/adult_income_eval.csv\"\n",
    "\n",
    "training_idx = 6000\n",
    "label_column = 'income'\n",
    "\n",
    "all_data = pd.read_csv(all_data_file)\n",
    "all_data.drop(['fnlwgt', 'educational-num'], axis=1, inplace=True)\n",
    "\n",
    "reference_data = deepcopy(all_data[:training_idx])\n",
    "\n",
    "cat_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race',\n",
    "       'gender', 'native-country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Create a Prediction Model with the Reference Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a Logistic Regression model using the reference dataset to classify the income level (1: >= 50k, 0: < 50k). The model predictions for each dataset will be recorded and used in Certifai to calculate prediction statistics and track prediction drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:01.284492Z",
     "iopub.status.busy": "2023-01-05T19:12:01.284270Z",
     "iopub.status.idle": "2023-01-05T19:12:01.909987Z",
     "shell.execute_reply": "2023-01-05T19:12:01.909381Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic classifier' accuracy is 0.8491666666666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>workclass_Private</td>\n",
       "      <td>education_11th</td>\n",
       "      <td>marital-status_Never-married</td>\n",
       "      <td>occupation_Machine-op-inspct</td>\n",
       "      <td>relationship_Own-child</td>\n",
       "      <td>race_Black</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>workclass_Private</td>\n",
       "      <td>education_HS-grad</td>\n",
       "      <td>marital-status_Married-civ-spouse</td>\n",
       "      <td>occupation_Farming-fishing</td>\n",
       "      <td>relationship_Husband</td>\n",
       "      <td>race_White</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>workclass_Local-gov</td>\n",
       "      <td>education_Assoc-acdm</td>\n",
       "      <td>marital-status_Married-civ-spouse</td>\n",
       "      <td>occupation_Protective-serv</td>\n",
       "      <td>relationship_Husband</td>\n",
       "      <td>race_White</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>workclass_Private</td>\n",
       "      <td>education_HS-grad</td>\n",
       "      <td>marital-status_Married-civ-spouse</td>\n",
       "      <td>occupation_Exec-managerial</td>\n",
       "      <td>relationship_Husband</td>\n",
       "      <td>race_White</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>native-country_Cuba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>workclass_Private</td>\n",
       "      <td>education_Some-college</td>\n",
       "      <td>marital-status_Married-civ-spouse</td>\n",
       "      <td>occupation_Machine-op-inspct</td>\n",
       "      <td>relationship_Husband</td>\n",
       "      <td>race_Black</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age            workclass               education  \\\n",
       "0   25    workclass_Private          education_11th   \n",
       "1   38    workclass_Private       education_HS-grad   \n",
       "2   28  workclass_Local-gov    education_Assoc-acdm   \n",
       "3   58    workclass_Private       education_HS-grad   \n",
       "4   44    workclass_Private  education_Some-college   \n",
       "\n",
       "                      marital-status                    occupation  \\\n",
       "0       marital-status_Never-married  occupation_Machine-op-inspct   \n",
       "1  marital-status_Married-civ-spouse    occupation_Farming-fishing   \n",
       "2  marital-status_Married-civ-spouse    occupation_Protective-serv   \n",
       "3  marital-status_Married-civ-spouse    occupation_Exec-managerial   \n",
       "4  marital-status_Married-civ-spouse  occupation_Machine-op-inspct   \n",
       "\n",
       "             relationship        race       gender  capital-gain  \\\n",
       "0  relationship_Own-child  race_Black  gender_Male             0   \n",
       "1    relationship_Husband  race_White  gender_Male             0   \n",
       "2    relationship_Husband  race_White  gender_Male             0   \n",
       "3    relationship_Husband  race_White  gender_Male             0   \n",
       "4    relationship_Husband  race_Black  gender_Male          7688   \n",
       "\n",
       "   capital-loss  hours-per-week                native-country  income  \\\n",
       "0             0              40  native-country_United-States       0   \n",
       "1             0              50  native-country_United-States       0   \n",
       "2             0              40  native-country_United-States       1   \n",
       "3             0              24           native-country_Cuba       0   \n",
       "4             0              40  native-country_United-States       1   \n",
       "\n",
       "   predicted  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = reference_data[label_column]\n",
    "X = reference_data.drop(label_column, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "encoder = CatEncoder(cat_columns, X, normalize=True)\n",
    "\n",
    "def build_model(data, name, test=None):\n",
    "    if test is None:\n",
    "        test = data\n",
    "        \n",
    "    parameters = {'C': (0.5, 1.0, 2.0), 'solver': ['lbfgs'], 'max_iter': [1000]}\n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(data[0], data[1])\n",
    "   \n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(test[0], test[1].values)\n",
    "    print(f\"Model '{name}' accuracy is {accuracy}\")\n",
    "    return model\n",
    "\n",
    "logistic_model = build_model((encoder(X_train.values), y_train),\n",
    "                           'Logistic classifier',\n",
    "                           test=(encoder(X_test.values), y_test))\n",
    "\n",
    "# Generate a prediction label for the data\n",
    "reference_data['predicted'] = logistic_model.predict(encoder(X.values))\n",
    "reference_data.to_csv(f\"{DATASET_DIR}/adult_reference_dataset.csv\", sep=',', index=False)\n",
    "\n",
    "display(reference_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Gather the Monitored Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We break up the remainder of the UCI Adult Income Dataset into separate data blocks - these blocks will be called the \"monitored datasets\". These monitored datasets will behave as separate data uploads into the Certifai platform for tracking and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:01.943767Z",
     "iopub.status.busy": "2023-01-05T19:12:01.943481Z",
     "iopub.status.idle": "2023-01-05T19:12:02.161434Z",
     "shell.execute_reply": "2023-01-05T19:12:02.160815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate data into blocks\n",
    "monitored_df = deepcopy(all_data[training_idx:])\n",
    "monitor_size = 3000\n",
    "monitored_data = {}\n",
    "for block in np.arange(1, 1+monitored_df.shape[0]//monitor_size):\n",
    "    monitored_data[block-1] = monitored_df[(block-1)*monitor_size:block*monitor_size]\n",
    "    \n",
    "    # Generate a prediction using the model created from the reference dataset\n",
    "    X = monitored_data[block-1]\n",
    "    prediction = logistic_model.predict(encoder(X.drop(label_column, axis=1).values))\n",
    "    monitored_data[block-1].insert(monitored_df.shape[1], \"predicted\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:02.164589Z",
     "iopub.status.busy": "2023-01-05T19:12:02.164415Z",
     "iopub.status.idle": "2023-01-05T19:12:02.167678Z",
     "shell.execute_reply": "2023-01-05T19:12:02.167127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of monitored datasets: 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of monitored datasets: {len(monitored_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:02.170669Z",
     "iopub.status.busy": "2023-01-05T19:12:02.170495Z",
     "iopub.status.idle": "2023-01-05T19:12:02.180330Z",
     "shell.execute_reply": "2023-01-05T19:12:02.179747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>37</td>\n",
       "      <td>workclass_Self-emp-not-inc</td>\n",
       "      <td>education_Some-college</td>\n",
       "      <td>marital-status_Divorced</td>\n",
       "      <td>occupation_Craft-repair</td>\n",
       "      <td>relationship_Not-in-family</td>\n",
       "      <td>race_White</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>48</td>\n",
       "      <td>workclass_Private</td>\n",
       "      <td>education_Bachelors</td>\n",
       "      <td>marital-status_Never-married</td>\n",
       "      <td>occupation_Sales</td>\n",
       "      <td>relationship_Other-relative</td>\n",
       "      <td>race_White</td>\n",
       "      <td>gender_Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>67</td>\n",
       "      <td>workclass_Private</td>\n",
       "      <td>education_HS-grad</td>\n",
       "      <td>marital-status_Divorced</td>\n",
       "      <td>occupation_Priv-house-serv</td>\n",
       "      <td>relationship_Unmarried</td>\n",
       "      <td>race_Black</td>\n",
       "      <td>gender_Female</td>\n",
       "      <td>1848</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>72</td>\n",
       "      <td>workclass_Self-emp-not-inc</td>\n",
       "      <td>education_Some-college</td>\n",
       "      <td>marital-status_Married-civ-spouse</td>\n",
       "      <td>occupation_Other-service</td>\n",
       "      <td>relationship_Husband</td>\n",
       "      <td>race_White</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>31</td>\n",
       "      <td>workclass_Local-gov</td>\n",
       "      <td>education_Some-college</td>\n",
       "      <td>marital-status_Never-married</td>\n",
       "      <td>occupation_Protective-serv</td>\n",
       "      <td>relationship_Not-in-family</td>\n",
       "      <td>race_Black</td>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age                   workclass               education  \\\n",
       "6000   37  workclass_Self-emp-not-inc  education_Some-college   \n",
       "6001   48           workclass_Private     education_Bachelors   \n",
       "6002   67           workclass_Private       education_HS-grad   \n",
       "6003   72  workclass_Self-emp-not-inc  education_Some-college   \n",
       "6004   31         workclass_Local-gov  education_Some-college   \n",
       "\n",
       "                         marital-status                  occupation  \\\n",
       "6000            marital-status_Divorced     occupation_Craft-repair   \n",
       "6001       marital-status_Never-married            occupation_Sales   \n",
       "6002            marital-status_Divorced  occupation_Priv-house-serv   \n",
       "6003  marital-status_Married-civ-spouse    occupation_Other-service   \n",
       "6004       marital-status_Never-married  occupation_Protective-serv   \n",
       "\n",
       "                     relationship        race         gender  capital-gain  \\\n",
       "6000   relationship_Not-in-family  race_White    gender_Male             0   \n",
       "6001  relationship_Other-relative  race_White  gender_Female             0   \n",
       "6002       relationship_Unmarried  race_Black  gender_Female          1848   \n",
       "6003         relationship_Husband  race_White    gender_Male             0   \n",
       "6004   relationship_Not-in-family  race_Black    gender_Male             0   \n",
       "\n",
       "      capital-loss  hours-per-week                native-country  income  \\\n",
       "6000             0              50  native-country_United-States       0   \n",
       "6001             0              38  native-country_United-States       1   \n",
       "6002             0              99  native-country_United-States       0   \n",
       "6003             0              40  native-country_United-States       0   \n",
       "6004             0              40  native-country_United-States       0   \n",
       "\n",
       "      predicted  \n",
       "6000          0  \n",
       "6001          0  \n",
       "6002          0  \n",
       "6003          0  \n",
       "6004          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitored_data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Inject Data Drift and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We synthetically generate datasets to demonstrate Certifai's `data_statistics` evaluation type. These synthetic datasets will allow us to verify Certifai's analysis tools and to keep track of which features have \"drifted\". We process the data for analysis in two ways:\n",
    "\n",
    "(1) We randomly sample rows to negate with NaN or insert with an unexpected value. If we randomly replace values and the dataset is large, it is likely that `num_cells_missing == num_rows_missing`, and these graphs will look identical. To ensure these graphs look different (to showcase the analysis), we duplicate some of the replacement rows. This duplication means `num_cells_missing != num_rows_missing`. \n",
    "\n",
    "(2) At each dataset upload, we gradually inject more noise into the numerical feature `hours-per-week` and two categorical features `workclass` and `education`. Each monitored dataset will act as a new upload of data over time. By progressively increasing noise into the above features, we artificially shift the data distributions and produce a drift in the feature. Similarly, we inject drift into the prediction label to test Certifai's ability to detect prediction label drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:02.183926Z",
     "iopub.status.busy": "2023-01-05T19:12:02.183680Z",
     "iopub.status.idle": "2023-01-05T19:12:02.192297Z",
     "shell.execute_reply": "2023-01-05T19:12:02.191711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data processing functions\n",
    "def randomly_sample_indices(data, p=0.5):\n",
    "    # Randomly sample rows to negate with NaN\n",
    "    rows = np.random.choice(range(data.shape[0]), int(p*data.shape[0]))\n",
    "    duplicate_rows = int(len(rows)*random.uniform(0.35, 0.45))\n",
    "    rows[:duplicate_rows] = rows[-duplicate_rows:]\n",
    "    \n",
    "    # Randomly sample columns, ignoring the `predicted` and `income` columns\n",
    "    cols = np.random.choice(range(data.shape[1]-2), size=len(rows), replace=True)\n",
    "    return rows, cols\n",
    "\n",
    "\n",
    "def inject_missing_values(input_data, p=.25):    \n",
    "    rows, cols = randomly_sample_indices(input_data, p)\n",
    "    x = input_data.values\n",
    "    x[rows, cols] = np.nan\n",
    "    return pd.DataFrame(x, index=input_data.index, columns=input_data.columns)\n",
    "\n",
    "\n",
    "def inject_unexpected_value(input_data, categorical_names, p=0.25):\n",
    "    rows, _ = randomly_sample_indices(input_data, p)\n",
    "        \n",
    "    # Only insert into categoricals (sans `occupation` due to high cardinality)\n",
    "    col_indices = [input_data.columns.get_loc(c) for c in categorical_names if c !='occupation']\n",
    "    # Assign random weighting to avoid uniform insertion\n",
    "    weights = np.random.randint(0, 200, size=len(col_indices))\n",
    "    weights = weights/float(np.sum(weights))\n",
    "    np.random.shuffle(weights)\n",
    "    \n",
    "    cols = np.random.choice(col_indices, size=len(rows), p=weights, replace=True)\n",
    "\n",
    "    x = input_data.values\n",
    "    x[rows, cols] = [input_data.columns[idx]+'_unexpected_group' for idx in cols] \n",
    "    return pd.DataFrame(x, index=input_data.index, columns=input_data.columns)\n",
    "\n",
    "\n",
    "def inject_numeric_drift(input_data, fraction, col_idx):\n",
    "    # we operate on a copy of the data\n",
    "    output = np.copy(input_data)\n",
    "    \n",
    "    for col in col_idx:\n",
    "        stddevs = np.std(input_data[:,col])\n",
    "        scales = random.uniform(0.5, 3)\n",
    "\n",
    "        for index, row in enumerate(input_data):\n",
    "            if random.random() < fraction:\n",
    "                noise = np.random.normal(0, scales * stddevs)\n",
    "                sign = random.choice((-1, 1))\n",
    "                \n",
    "                new_value = int(input_data[index, col] + sign*noise)\n",
    "\n",
    "                output[index, col] = max((new_value, min(input_data[:,col])))\n",
    "                output[index, col] = min((output[index, col], max(input_data[:,col])))                 \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T19:12:02.195394Z",
     "iopub.status.busy": "2023-01-05T19:12:02.195183Z",
     "iopub.status.idle": "2023-01-05T19:12:03.203856Z",
     "shell.execute_reply": "2023-01-05T19:12:03.203078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inject drift - 1 % of feature corrupted\n",
      "Inject drift - 3 % of feature corrupted\n",
      "Inject drift - 5 % of feature corrupted\n",
      "Inject drift - 7 % of feature corrupted\n",
      "Inject drift - 8 % of feature corrupted\n",
      "Inject drift - 10 % of feature corrupted\n",
      "Inject drift - 12 % of feature corrupted\n",
      "Inject drift - 14 % of feature corrupted\n",
      "Inject drift - 16 % of feature corrupted\n",
      "Inject drift - 18 % of feature corrupted\n",
      "Inject drift - 19 % of feature corrupted\n",
      "Inject drift - 21 % of feature corrupted\n",
      "Inject drift - 23 % of feature corrupted\n",
      "Inject drift - 25 % of feature corrupted\n"
     ]
    }
   ],
   "source": [
    "# Process monitored data\n",
    "drift_variables = ['hours-per-week', 'workclass', 'education']\n",
    "switch_to = [0, 'workclass_Federal-gov', 'education_Doctorate']\n",
    "\n",
    "# Create noise vector for drift\n",
    "pcts = np.linspace(.01, .25, len(monitored_data)) \n",
    "\n",
    "drift_over_time, threshold, pvalues, corrected_alpha = [], [], [], []\n",
    "\n",
    "for pct_idx, pct in enumerate(pcts):  \n",
    "    print(\"Inject drift - {} % of feature corrupted\".format(int(100*np.round(pct,2))))\n",
    "    adult_valid_corrupted = monitored_data[pct_idx]\n",
    "    \n",
    "    # Insert drift into the features\n",
    "    for feature_idx, drift_feature in enumerate(drift_variables):\n",
    "        data_idx = reference_data.columns.get_loc(drift_feature)\n",
    "\n",
    "        if drift_feature in cat_columns:\n",
    "            # Categorical features\n",
    "            sample_idx = adult_valid_corrupted.sample(frac=pct/10).index\n",
    "            adult_valid_corrupted.loc[sample_idx, drift_feature] = switch_to[feature_idx]\n",
    "            \n",
    "        else:\n",
    "            # Numeric features\n",
    "            output = inject_numeric_drift(adult_valid_corrupted.values, pct, [data_idx])\n",
    "            adult_valid_corrupted = pd.DataFrame(output, columns=monitored_data[0].columns)\n",
    "        \n",
    "    # Randomly insert missing values (NaN)\n",
    "    nan_prob = np.random.uniform(5, 10)/100\n",
    "    adult_valid_corrupted = inject_missing_values(adult_valid_corrupted, p=nan_prob)\n",
    "\n",
    "    # Randomly insert an unexpected value\n",
    "    unexpected_prob = np.random.uniform(5, 10)/100\n",
    "    adult_valid_corrupted = inject_unexpected_value(adult_valid_corrupted, cat_columns, p=unexpected_prob)\n",
    "\n",
    "    # Insert drift into the prediction\n",
    "    sample_idx = adult_valid_corrupted.sample(frac=pct/10).index\n",
    "    adult_valid_corrupted.loc[sample_idx, 'predicted'] = 1\n",
    "\n",
    "    # Write the data to the dataset directory\n",
    "    pct_idx_str = \"0\"+str(pct_idx) if pct_idx < 10 else str(pct_idx)\n",
    "    \n",
    "    adult_valid_corrupted.to_csv(f\"{DATASET_DIR}/adult_monitored_dataset_{pct_idx_str}.csv\", sep=',',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
