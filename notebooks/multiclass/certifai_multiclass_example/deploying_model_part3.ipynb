{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying model as a service\n",
    "\n",
    "- For the sake of this tutorial we will be deploying the previously built model (in part3 of the example) to Azure Cloud using Azure Cloud Instance (ACI)\n",
    "- Most of the steps are common for almost all could service providers\n",
    "- Important thing to note is the scoring script (score.py) which defines `request/response` schema needed for Certifai  scan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the section below we will:\n",
    "\n",
    "1. Configure Azure workspace\n",
    "2. Register model (built in part3 of the example) to the workspace\n",
    "3. Create a prediction environment in the remote Azure workspace (created above) and\n",
    "4. Deploy model (predict) as web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the \n",
    "[configuration-notebook](https://github.com/Azure/MachineLearningNotebooks/blob/c520bd1d4130d9a01ee46e0937459e2de95d15ec/configuration.ipynb) to create an Azure workspace. Creating remote environments/dependencies will be covered in the notebook\n",
    "\n",
    "**PleaseNote**: to step through this notebook, make sure you have necessary dependencies installed locally\n",
    "\n",
    "- python>=3.6.2,<3.7\n",
    "- scikit-learn>0.23.1\n",
    "- numpy=1.19.1\n",
    "- pandas\n",
    "- azureml-sdk=1.12.0 (pip install azureml-sdk==1.12.0)\n",
    "- matplotlib\n",
    "- jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Initialize Azure workspace\n",
    "\n",
    "- Follow the instructions listed here [creating and managing azure-ml workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace) to create an azure-ml workspace\n",
    "\n",
    "**Once you have the workspace created easiest way to run through remaining steps is to download the `config.json` to the current directory and replace the exisiting config.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a [Workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace%28class%29?view=azure-ml-py) object from the persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deps test model for model serialization/de-serialization\n",
    "# model was built with scikit-learn 0.23.2 \n",
    "\n",
    "import sklearn as sklearn_version_test\n",
    "assert sklearn_version_test.__version__ >= '0.23.1', 'scikit-learn version mismatch, `pip install scikit-learn>=0.23.1` to install right sklearn version for this notebook'\n",
    "assert np.__version__                   >= '1.16.2' , 'numpy version mismatch, `pip install numpy>=1.16.2` to install right numpy version for this notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models/german_credit_multiclass.joblib\n",
      "Pipeline(steps=[('full_pipeline',\n",
      "                 Pipeline(steps=[('scaler', StandardScaler())])),\n",
      "                ('model',\n",
      "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
      "                              param_grid={'C': (0.5, 1.0, 2.0),\n",
      "                                          'max_iter': [1000],\n",
      "                                          'solver': ['lbfgs']}))])\n"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "model_path = 'models/german_credit_multiclass.joblib'\n",
    "print(f'loading {model_path}')\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f'model `{model_path}` not found. Looks like model has not been trained or file location is wrong')\n",
    "    raise Exception(str(e))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model to created  workspace\n",
    "\n",
    "- Register a file or folder as a model by calling [Model.register()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-).\n",
    "\n",
    "- In addition to the content of the model file itself (model + scaler object), our registered model will also store model metadata like model description, tags, etc. -- that will be useful when managing and deploying models in our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model german_credit_target_encoded_multiclass\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "target_en_multiclass_german_credit = Model.register(model_path=model_path,\n",
    "                       model_name='german_credit_target_encoded_multiclass',\n",
    "                       tags={'area': \"banking credit risk\", 'type': \"multi-class\"},\n",
    "                       description=\"Logistic Classifier model to predict credit loan approved/denied/further Inspection\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom prediction environment inside azure-ml workspace\n",
    "\n",
    "If we want control over how our model is run, if it uses another framework, or if it has special runtime requirements, we can instead specify our own environment and scoring method. Custom environments can be used for any model we want to deploy.\n",
    "\n",
    "Specify the model's runtime environment by creating an [Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment%28class%29?view=azure-ml-py) object and providing the [CondaDependencies](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py) needed by the model\n",
    "\n",
    "In this example we will create a conda environment for our german credit model from file **myenv.yml** and register it to our workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: project_environment\n",
      "dependencies:\n",
      "  - python=3.6.2\n",
      "  - scikit-learn>=0.23.1\n",
      "  - numpy>=1.16.2\n",
      "  - joblib\n",
      "  - pip:\n",
      "    - azureml-defaults\n",
      "    - inference-schema[numpy-support]\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\", 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200723.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"target-en-multiclass\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                \"scikit-learn>=0.23.1\",\n",
       "                \"numpy>=1.16.2\",\n",
       "                \"joblib\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"inference-schema[numpy-support]\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"azureml_b9777714200670935b10e1478480a3a7\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"5\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "environment = Environment(\"target-en-multiclass\")\n",
    "environment.python.conda_dependencies = CondaDependencies(\"myenv.yml\")\n",
    "environment.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certifai model invoke request/response schema\n",
    "\n",
    "Make a note of the request/response schema in `score.py`\n",
    "\n",
    "- Certifai invokes model with the json schema:\n",
    "\n",
    "```\n",
    "{\n",
    "\t\"payload\": {\n",
    "\t\t\"instances\": [\n",
    "\t\t\t[6, 107, 88, 0, 0, 36.8, 0.727, 31],\n",
    "\t\t\t[5, 100, 80, 0, 0, 31.9, 0.61, 33]\n",
    "\t\t]\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n",
    "**where individual list of values correspond to a `row` in the dataset**\n",
    "\n",
    "- Certifai expects model responses with the json schema: \n",
    "\n",
    "```\n",
    "{\n",
    "\t\"payload\": {\n",
    "\t\t\"predictions\": [1, 0]\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n",
    "**where `predictions` correspond to an ordered list of model predict responses**\n",
    "\n",
    "**Important**: Certifai needs batch-predictions enabled for serving models in-order to be performant. It invokes model  predicts with batches of size 4K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Inference Configuration and deploy webservice\n",
    "\n",
    "**Inference Configuration** will contain:\n",
    "\n",
    "1. Scoring script\n",
    "2. Environment (created above)\n",
    "\n",
    "We create the scoring script, called **score.py**. The web service call uses this script to show how to use the model.\n",
    "\n",
    "We include below two required functions in the scoring script:\n",
    "\n",
    "1. The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "\n",
    "2. The `run(data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are also supported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import json\r\n",
      "import numpy as np\r\n",
      "import joblib\r\n",
      "import traceback\r\n",
      "\r\n",
      "\r\n",
      "def init():\r\n",
      "\tglobal model\r\n",
      "\t# AZUREML_MODEL_DIR is an environment variable created during deployment.\r\n",
      "\t# It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\r\n",
      "\t# For multiple models, it points to the folder containing all deployed models (./azureml-models)\r\n",
      "\tmodel_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'german_credit_multiclass.joblib')\r\n",
      "\t# deserialize the model_obj file back into a sklearn model and scaler object\r\n",
      "\tmodel  = joblib.load(model_path)\r\n",
      "\tprint(model)\r\n",
      "\r\n",
      "\r\n",
      "def run(data):\r\n",
      "\ttry: \r\n",
      "\t\t# certifai invokes model with the json schema -> {\"payload\": {\"instances\": [ [6,107,88,0,0,36.8,0.727,31], [5,100,80,0,0,31.9,0.61,33] ]}}\r\n",
      "\t\tdata  = json.loads(data).get('payload', {}).get('instances', [])\r\n",
      "\t\tdata  = np.array(data, dtype=object)\r\n",
      "\t\tdata  = data if data.ndim == 2 else np.reshape(data, (1, -1))\r\n",
      "\t\tresult = model.predict(data)\r\n",
      "\t\t# you can return any datatype as long as it is JSON-serializable\r\n",
      "\t\t# certifai expects model response with the json schema -> {\"payload\": {\"predictions\": [1,0]} }\r\n",
      "\r\n",
      "\t\treturn {\"payload\":{ \"predictions\": result.tolist()} }\r\n",
      "\texcept Exception as e:\r\n",
      "\t\terror = str(e)\r\n",
      "\t\tprint(traceback.format_exc())\r\n",
      "\t\treturn error\r\n"
     ]
    }
   ],
   "source": [
    "!cat scripts/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the registered model in the custom environment by providing an [InferenceConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py) object to [Model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config--deployment-config-none--deployment-target-none-). In this case we are also using the [AciWebservice.deploy_configuration()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none--) method to generate a custom deploy configuration\n",
    "        \n",
    "**Note**: This step can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "inference_config= InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=environment,source_directory=\"scripts\")\n",
    "\n",
    "service_name = 'te-multiclass-gc-service'\n",
    "aci_deployment_config = AciWebservice.deploy_configuration(auth_enabled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running....\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, service_name, [target_en_multiclass_german_credit],inference_config=inference_config,\n",
    "                       deployment_config=aci_deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the webservice\n",
    "\n",
    "- create the data instances to test with\n",
    "- invoke the service endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "base_path = '../..'\n",
    "all_data_file = f\"{base_path}/datasets/german_credit_eval_multiclass_encoded.csv\"\n",
    "df = pd.read_csv(all_data_file)\n",
    "\n",
    "X_test = df.drop('outcome',axis=1).values\n",
    "\n",
    "sample_input = json.dumps({\n",
    "\"payload\": {\n",
    "    \"instances\": \n",
    "        X_test[:10].tolist()\n",
    "}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "0:00:02.433177\n",
      "{'payload': {'predictions': [1, 2, 1, 1, 1, 1, 1, 1, 1, 1]}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "response = requests.post(\n",
    "    service.scoring_uri, data=sample_input, headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_scan_definition_file = 'target_encoded_gcredit_multiclass_scan_def.yaml'\n",
    "import yaml\n",
    "\n",
    "with open(local_scan_definition_file) as file:\n",
    "    scan_def = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update scan definition yaml\n",
    "\n",
    "- update the model `predict-endpoint` with the scoring uri of the deployed web service\n",
    "- add the auth header deatils (if auth enabled in service)\n",
    "- save the scan definition yaml for remote scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the predict-endpoint with scoring uri\n",
    "scan_def['models'][0]['predict_endpoint'] = service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if web-service auth is enabled un-comment the below code snippet'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add header details\n",
    "scan_def['model_headers'] = {}\n",
    "scan_def['model_headers']['default'] = [{'name': 'Content-Type', 'value':'application/json'},\n",
    "                                        {'name': 'accept',        'value':'application/json'} ]\n",
    "\n",
    "'''if web-service auth is enabled un-comment the below code snippet'''\n",
    "\n",
    "\n",
    "# scan_def['model_headers']['defined'] = [{'model_id': 'german_credit_multiclass',\n",
    "#                                          'name': 'Authorization', \n",
    "#                                          'value':'Bearer <INSERT_TOKEN_HERE>'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save yaml to disk\n",
    "with open(local_scan_definition_file, 'w') as file:\n",
    "    yaml.dump(scan_def, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
