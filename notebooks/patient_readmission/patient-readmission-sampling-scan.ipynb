{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8293d592-9696-44c7-94e9-ee1c1ec869f0",
   "metadata": {
    "_uuid": "90d890b7e4ff4dbbb27e2b59e50e942c7bb0078c"
   },
   "source": [
    "Copyright (c) 2020. Cognitive Scale Inc. All rights reserved.\n",
    "Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/7998b8a481fccd467463deb1fc46d19622079b0e/LICENSE.md)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This is the fifth notebook in this example of how to scan models using Certifai. If you have not already done so, please run the [first notebook](patient-readmission-train.ipynb) to train the models to be explained and the [second notebook](patient-readmission-explain-scan.ipynb) to create the `explain-scan-def.yaml` scan definition. **This notebook requires at least Certifai 1.3.13.**\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Create a Certifai scan object with the information Certifai needs to explain a model\n",
    "2. Run explanation scans using counterfactual search\n",
    "3. View the results in the Console\n",
    "\n",
    "Counterfactual search is an alternative approach for finding counterfactuals, where, Certifai searches the evaluation dataset for counterfactuals instead of generating counterfactuals via its genetic algorithm (GA). Unlike a traditional explanation scan, counterfactual search can be run whether or not there is access to model predictions. When Certifai has access to the model it is able to simplify the counterfactuals found in the dataset to remove unnecessary feature changes. When there is no access to the model the counterfactuals are exactly in the evaluation dataset.\n",
    "\n",
    "In this notebook we will run two explanations scan using counterfactual search, one with access to the model and one without access to the model. See the [sixth notebook](patient-readmission-sampling-results.ipynb) for how to work with the results of the explanations scan in a notebook and for a comparison between the counterfactuals from each scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equivalent-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel,\n",
    "                                      CertifaiDataset, CertifaiDatasetSource, CertifaiGroupingFeature,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue,\n",
    "                                      CertifaiFeatureDataType, CertifaiFeatureSchema, CertifaiDataSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f6e1d-f545-4ca8-8be9-05e37ab148c5",
   "metadata": {
    "_uuid": "a4490db86a8bb5bdc7bc81d17da9f0a3b690b90c"
   },
   "source": [
    "# Loading the Certifai Scan object\n",
    "\n",
    "In this section, we load the previously defined scan definition to use as a starting point. This is a convenience that avoids us having to recreate information about the prediction task, datasets and feature schema. \n",
    "\n",
    "Load the scan definition from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd03de5-7406-4992-bfe7-8b77c0e21313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 19:06:31,912 root   WARNING  The model 'logit' was locally defined and doesn't have a valid 'predict_endpoint'. Before running a scan with this model, you should deploy the model and update the 'logit' models metadata in the scan definition.\n",
      "2021-10-12 19:06:31,914 root   WARNING  The model 'mlp' was locally defined and doesn't have a valid 'predict_endpoint'. Before running a scan with this model, you should deploy the model and update the 'mlp' models metadata in the scan definition.\n"
     ]
    }
   ],
   "source": [
    "scan = CertifaiScanBuilder.from_file('explain-scan-def.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797d6e0-8183-43bf-9fd1-835d3b921b3f",
   "metadata": {},
   "source": [
    "For this analysis we will only use a single model. Because we're running with local models in the notebook, we need to reload the model and reassociate it with the scan. If the models were running externally, we would instead update the scan definition with the correct predict_endpoint URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e17955-c3ca-45b0-82aa-b21f8ab569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing models\n",
    "for model_name in ['logit', 'mlp']:\n",
    "    scan.remove_model(model_name)\n",
    "\n",
    "# include the logitstic regression model\n",
    "with open('readmission_logit.pkl', 'rb') as f:\n",
    "    saved = pickle.load(f)\n",
    "    logit_model = saved.get('model')\n",
    "    model = CertifaiPredictorWrapper(logit_model)\n",
    "    scan.add_model(CertifaiModel('logit', local_predictor=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802fd1a-cfde-4f8f-9d6a-4a2002193732",
   "metadata": {},
   "source": [
    "### Running with model access\n",
    "\n",
    "Below we run the scan and save the results in the `reports` folder. The `sampling` kwarg specifies the explanation scan should be run using Counterfactual Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25bbd293-9250-476c-8ae0-46061b81f607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scan with model_use_case_id: 'readmission' and scan_id: '56c3cf74279e'\n",
      "[--------------------] 2021-10-12 19:06:36.293999 - 0 of 1  (0.0% complete) - Running sampling explanation evaluation for model: logit\n",
      "[####################] 2021-10-12 19:08:47.069785 - 1 of 1  (100.0% complete) - Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "results = scan.run_explain(write_reports=True, sampling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b84770-b5b1-423a-9016-12f8de085d59",
   "metadata": {},
   "source": [
    "### Preparing the scan to run without model access\n",
    "\n",
    "To perform the scan without model access we will include the model predictions for each dataset as an extra column within the dataset. This is similar to having historical predictions for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a2291e-85f0-4654-bfa9-94533cb43ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the predicted outcome column\n",
    "predicted_label = 'logit_predictions'\n",
    "scan.dataset_schema.predicted_outcome_feature_name = predicted_label\n",
    "\n",
    "def add_predicted_outcome(df, model):\n",
    "    X = df.drop('readmitted', axis=1)\n",
    "    predictions = model.predict(X)\n",
    "    df['logit_predictions'] = predictions\n",
    "    return df\n",
    "    \n",
    "\n",
    "# insert the model predictions in the evaluation dataset and update the scan definition\n",
    "evaluation_df = add_predicted_outcome(pd.read_csv('diabetic_data_processed.csv'), logit_model)\n",
    "eval_dataset = CertifaiDataset('evaluation', CertifaiDatasetSource.dataframe(evaluation_df))\n",
    "scan.remove_dataset('evaluation')\n",
    "scan.add_dataset(eval_dataset)\n",
    "scan.evaluation_dataset_id = 'evaluation'\n",
    "\n",
    "# insert the model predictions in the explanation dataset and update the scan definition\n",
    "explanation_df = add_predicted_outcome(pd.read_csv('diabetic_data_explain.csv'), logit_model)\n",
    "explan_dataset = CertifaiDataset('explanation', CertifaiDatasetSource.dataframe(explanation_df))\n",
    "scan.remove_dataset('explanation')\n",
    "scan.add_dataset(explan_dataset)\n",
    "scan.explanation_dataset_id = 'explanation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b16d1-c3c9-4dc7-9aac-b4a05fee1fbc",
   "metadata": {},
   "source": [
    "Specify in that the scan does not have model access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c265474b-1f47-4fd0-bf1e-b87a4a30f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.no_model_access = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fedb43-e239-470a-b2dd-3cd42fb989eb",
   "metadata": {},
   "source": [
    "Remove the underlying model from the previous scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2943893f-5fcc-43bf-8773-5d67696b72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.remove_model('logit')\n",
    "scan.add_model(CertifaiModel('logit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d3b45-6a30-43f3-80d5-7e8b774a1618",
   "metadata": {},
   "source": [
    "### Running without model access\n",
    "\n",
    "Below we run the scan and save the results in the `reports` folder. The `sampling` kwarg specifies the explanation scan should be run using Counterfactual Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe003c2d-4df9-4cbf-9d24-e33a40b94ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------] 2021-10-12 19:08:51.417783 - 0 of 1  (0.0% complete) - Starting scan with model_use_case_id: 'readmission' and scan_id: '9bdb2bc8dfd5'\n",
      "[--------------------] 2021-10-12 19:08:51.417963 - 0 of 1  (0.0% complete) - Running sampling explanation evaluation for model: logit\n",
      "[####################] 2021-10-12 19:11:07.835351 - 1 of 1  (100.0% complete) - Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "results = scan.run_explain(write_reports=True, sampling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6a517-bb98-441f-860c-d71930dc6c22",
   "metadata": {},
   "source": [
    "# View the Results\n",
    "\n",
    "The results can be viewed in the Certifai console using the CLI command `certifai console`, run from this folder. \n",
    "Go to `http://localhost:8000` in your browser. \n",
    "\n",
    "The results can also be analyzed in the same notebook; or analyzed later in a separate notebook. See the [sixth notebook](patient-readmission-sampling-results.ipynb) for how to load and work with the results of the explanations scan in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabc181-81de-4572-b625-62b5bac8e6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
