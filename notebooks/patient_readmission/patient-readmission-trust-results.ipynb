{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90d890b7e4ff4dbbb27e2b59e50e942c7bb0078c"
   },
   "source": [
    "Copyright (c) 2020. Cognitive Scale Inc. All rights reserved.\n",
    "Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/7998b8a481fccd467463deb1fc46d19622079b0e/LICENSE.md)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This fifth notebook shows you how to explore the trust score results in a notebook. If you have not already done so, please run the [fourth notebook](patient-readmission-trust-scan.ipynb) to scan the models for their trust scores.\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load the previously saved trust score reports\n",
    "2. Convert the results into a dataframe and display them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "fba09007b76132d605daa699b39a5fc92ff87ee1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from certifai.scanner.report_reader import ScanReportReader\n",
    "from certifai.scanner.report_utils import (\n",
    "    scores, construct_scores_dataframe, construct_feature_scores_dataframe, construct_overall_scores_dataframe,\n",
    "    construct_group_scores_dataframe)\n",
    "from certifai.scanner.builder import ExplanationType\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4490db86a8bb5bdc7bc81d17da9f0a3b690b90c"
   },
   "source": [
    "# Loading the Trust Score Reports\n",
    "\n",
    "To load the reports, we need to know the use case ID ('readmission') and the scan ID.\n",
    "\n",
    "List the available use cases, and the scans within the 'readmission' use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date                                      evals       scan id\n",
      "0  20201102T134851  explainability, fairness, atx, robustness  eafa5614d892\n",
      "1  20201102T131236                                explanation  c0e07952e6d6\n",
      "2  20201102T103533                                explanation  df7a42f2ab84\n",
      "3  20201102T102839                                explanation  b6de685a2712\n",
      "4  20201016T132038                                explanation  5683ba38b998\n",
      "5  20201011T151543  atx, fairness, robustness, explainability  4b13c55a4131\n",
      "6  20201011T141903                                explanation  7a2e8b64cbd6\n"
     ]
    }
   ],
   "source": [
    "reader = ScanReportReader(\"reports\")\n",
    "reader.list_usecases()\n",
    "scans = reader.list_scans('readmission')\n",
    "data=[[s['date'], ', '.join(s['reportTypes']), s['id']] for s in scans]\n",
    "df = pd.DataFrame(data, columns=['date', 'evals', 'scan id']).sort_values(by=['date'], ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the latest trust score scan and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_scan = df[df['evals'].str.contains('fairness') & df['evals'].str.contains('robustness')].iloc[0]\n",
    "results = reader.load_scan('readmission', latest_scan['scan id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the results\n",
    "\n",
    "In this section we'll construct dataframes containing the score results and display them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the overall fairness results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>eval type</th>\n",
       "      <th>score type</th>\n",
       "      <th>score</th>\n",
       "      <th>score lower bound</th>\n",
       "      <th>score upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>fairness</td>\n",
       "      <td>burden</td>\n",
       "      <td>71.720752</td>\n",
       "      <td>67.045924</td>\n",
       "      <td>75.873632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logit</td>\n",
       "      <td>fairness</td>\n",
       "      <td>burden</td>\n",
       "      <td>59.551743</td>\n",
       "      <td>53.758901</td>\n",
       "      <td>65.337007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  context eval type score type      score  score lower bound  \\\n",
       "0     mlp  fairness     burden  71.720752          67.045924   \n",
       "1   logit  fairness     burden  59.551743          53.758901   \n",
       "\n",
       "   score upper bound  \n",
       "0          75.873632  \n",
       "1          65.337007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fairness_scores = list(scores('fairness', results))\n",
    "display(construct_overall_scores_dataframe(fairness_scores, include_confidence=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the fairness scores by feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>eval type</th>\n",
       "      <th>score type</th>\n",
       "      <th>age</th>\n",
       "      <th>age lower bound</th>\n",
       "      <th>age upper bound</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender lower bound</th>\n",
       "      <th>gender upper bound</th>\n",
       "      <th>race</th>\n",
       "      <th>race lower bound</th>\n",
       "      <th>race upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>fairness</td>\n",
       "      <td>burden</td>\n",
       "      <td>75.494891</td>\n",
       "      <td>70.844715</td>\n",
       "      <td>80.032798</td>\n",
       "      <td>94.906289</td>\n",
       "      <td>87.700702</td>\n",
       "      <td>99.487169</td>\n",
       "      <td>71.953967</td>\n",
       "      <td>67.045924</td>\n",
       "      <td>76.684155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logit</td>\n",
       "      <td>fairness</td>\n",
       "      <td>burden</td>\n",
       "      <td>59.686611</td>\n",
       "      <td>53.875415</td>\n",
       "      <td>66.078304</td>\n",
       "      <td>84.501607</td>\n",
       "      <td>73.826148</td>\n",
       "      <td>94.716060</td>\n",
       "      <td>65.890092</td>\n",
       "      <td>59.128323</td>\n",
       "      <td>72.863878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  context eval type score type        age  age lower bound  age upper bound  \\\n",
       "0     mlp  fairness     burden  75.494891        70.844715        80.032798   \n",
       "1   logit  fairness     burden  59.686611        53.875415        66.078304   \n",
       "\n",
       "      gender  gender lower bound  gender upper bound       race  \\\n",
       "0  94.906289           87.700702           99.487169  71.953967   \n",
       "1  84.501607           73.826148           94.716060  65.890092   \n",
       "\n",
       "   race lower bound  race upper bound  \n",
       "0         67.045924         76.684155  \n",
       "1         59.128323         72.863878  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(construct_feature_scores_dataframe(fairness_scores, include_confidence=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the detailed fairness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>eval type</th>\n",
       "      <th>score type</th>\n",
       "      <th>value type</th>\n",
       "      <th>age - 15</th>\n",
       "      <th>age - 15 lower bound</th>\n",
       "      <th>age - 15 upper bound</th>\n",
       "      <th>age - 25</th>\n",
       "      <th>age - 25 lower bound</th>\n",
       "      <th>age - 25 upper bound</th>\n",
       "      <th>...</th>\n",
       "      <th>race - Caucasian upper bound</th>\n",
       "      <th>race - Hispanic</th>\n",
       "      <th>race - Hispanic lower bound</th>\n",
       "      <th>race - Hispanic upper bound</th>\n",
       "      <th>race - Other</th>\n",
       "      <th>race - Other lower bound</th>\n",
       "      <th>race - Other upper bound</th>\n",
       "      <th>race - nan</th>\n",
       "      <th>race - nan lower bound</th>\n",
       "      <th>race - nan upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>fairness</td>\n",
       "      <td>burden</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.056508</td>\n",
       "      <td>0.044298</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.132073</td>\n",
       "      <td>0.100531</td>\n",
       "      <td>0.167759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093498</td>\n",
       "      <td>0.080362</td>\n",
       "      <td>0.062368</td>\n",
       "      <td>0.099629</td>\n",
       "      <td>0.064237</td>\n",
       "      <td>0.048607</td>\n",
       "      <td>0.082366</td>\n",
       "      <td>0.017340</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.024469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logit</td>\n",
       "      <td>fairness</td>\n",
       "      <td>burden</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>0.218283</td>\n",
       "      <td>0.152212</td>\n",
       "      <td>0.288154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114462</td>\n",
       "      <td>0.075701</td>\n",
       "      <td>0.051036</td>\n",
       "      <td>0.107286</td>\n",
       "      <td>0.054516</td>\n",
       "      <td>0.032154</td>\n",
       "      <td>0.085820</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.027991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  context eval type score type value type  age - 15  age - 15 lower bound  \\\n",
       "0     mlp  fairness     burden     burden  0.056508              0.044298   \n",
       "1   logit  fairness     burden     burden  0.031334              0.018616   \n",
       "\n",
       "   age - 15 upper bound  age - 25  age - 25 lower bound  age - 25 upper bound  \\\n",
       "0              0.069952  0.132073              0.100531              0.167759   \n",
       "1              0.049608  0.218283              0.152212              0.288154   \n",
       "\n",
       "   ...  race - Caucasian upper bound  race - Hispanic  \\\n",
       "0  ...                      0.093498         0.080362   \n",
       "1  ...                      0.114462         0.075701   \n",
       "\n",
       "   race - Hispanic lower bound  race - Hispanic upper bound  race - Other  \\\n",
       "0                     0.062368                     0.099629      0.064237   \n",
       "1                     0.051036                     0.107286      0.054516   \n",
       "\n",
       "   race - Other lower bound  race - Other upper bound  race - nan  \\\n",
       "0                  0.048607                  0.082366    0.017340   \n",
       "1                  0.032154                  0.085820    0.017773   \n",
       "\n",
       "   race - nan lower bound  race - nan upper bound  \n",
       "0                0.011066                0.024469  \n",
       "1                0.009156                0.027991  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(construct_group_scores_dataframe(fairness_scores, include_confidence=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of visualizing the fairness results in a chart, see the [fairness metrics notebook](https://github.com/CognitiveScale/cortex-certifai-examples/blob/master/notebooks/fairness_metrics/FairnessMetrics.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the robustness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>robustness</th>\n",
       "      <th>robustness lower bound</th>\n",
       "      <th>robustness upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>mlp</td>\n",
       "      <td>70.003655</td>\n",
       "      <td>65.077138</td>\n",
       "      <td>74.713251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>logit</td>\n",
       "      <td>80.816004</td>\n",
       "      <td>76.619526</td>\n",
       "      <td>84.575458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      context  robustness  robustness lower bound  robustness upper bound\n",
       "mlp       mlp   70.003655               65.077138               74.713251\n",
       "logit   logit   80.816004               76.619526               84.575458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = construct_scores_dataframe(scores('robustness', results), include_confidence=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the explainability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>explainability</th>\n",
       "      <th>Num features (1)</th>\n",
       "      <th>Num features (10)</th>\n",
       "      <th>Num features (2)</th>\n",
       "      <th>Num features (3)</th>\n",
       "      <th>Num features (4)</th>\n",
       "      <th>Num features (5)</th>\n",
       "      <th>Num features (6)</th>\n",
       "      <th>Num features (7)</th>\n",
       "      <th>Num features (8)</th>\n",
       "      <th>Num features (9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>mlp</td>\n",
       "      <td>97.265625</td>\n",
       "      <td>75.78125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.4375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>logit</td>\n",
       "      <td>97.617188</td>\n",
       "      <td>77.34375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8750</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      context  explainability  Num features (1)  Num features (10)  \\\n",
       "mlp       mlp       97.265625          75.78125                0.0   \n",
       "logit   logit       97.617188          77.34375                0.0   \n",
       "\n",
       "       Num features (2)  Num features (3)  Num features (4)  Num features (5)  \\\n",
       "mlp             23.4375           0.00000           0.78125               0.0   \n",
       "logit           21.8750           0.78125           0.00000               0.0   \n",
       "\n",
       "       Num features (6)  Num features (7)  Num features (8)  Num features (9)  \n",
       "mlp                 0.0               0.0               0.0               0.0  \n",
       "logit               0.0               0.0               0.0               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = construct_scores_dataframe(scores('explainability', results), include_confidence=False)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
