{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020. Cognitive Scale Inc. All rights reserved.\n",
    "Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/7998b8a481fccd467463deb1fc46d19622079b0e/LICENSE.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Running Cortex Certifai Scan on Sklearn model built and deployed on AWS Sagemaker using Certifai Model Connectors\n",
    "\n",
    "\n",
    "In this tutorial we will create sklearn models to classify german credit loan risk (predict whether loan will be granted or not). Models are built using Scikit-learn with [Sagemaker](https://sagemaker.readthedocs.io/en/stable/using_sklearn.html) by utilizing the pre-built container. Cortex Certifai provides first class support for various machine learning platforms including aws-sagemaker. We will then use [Cortex Certifai Toolkit](https://www.cognitivescale.com/download-certifai/) to launch fairness evaluation on the hosted models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "This notebook was created and tested on an ml.m4.xlarge sagemaker notebook instance. However you can also run it locally by making sure you have the [aws profile](https://docs.aws.amazon.com/cli/latest/reference/configure/) configured and following dependencies installed on your system\n",
    "\n",
    "\n",
    "- python>=3.6.2,<=3.7\n",
    "- scikit-learn==0.23.1\n",
    "- numpy==1.18.1\n",
    "- pandas\n",
    "- sagemaker==1.58.2\n",
    "- boto3 >= 1.0.0,< 2.0.0\n",
    "- ipython\n",
    "- matplotlib\n",
    "- jupyter\n",
    "- [optional for configuring aws profile] awscli==1.18.61\n",
    "- wget (when running locally on mac/windows)\n",
    "- certifai_toolkit>=1.12.14\n",
    "\n",
    "> **Please note**: this tutorial assumes you have downloaded the [Cortex Certifai Toolkit](https://www.cognitivescale.com/download-certifai/) and uploaded it to your `S3` bucket which will be later used to install certifai packages.\n",
    "> Also make sure you have configured aws with right roles and region for using S3 bucket and sagemaker utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, lets create our Sagemaker session and role and create a S3 prefix to use for the notebook example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [optional for local uage] sagemaker iam role guide setting up permissions (roles) for running this notebook locally\n",
    "- follow the [sagemaker-iam-role-documentation](https://docs.aws.amazon.com/glue/latest/dg/create-an-iam-role-sagemaker-notebook.html) for creating an `iam-role`\n",
    "\n",
    "> this notebook was built using iam-role `AmazonSageMakerFullAccess`\n",
    "\n",
    "make sure `~/.aws/configure` looks like below\n",
    "\n",
    "\n",
    "```\n",
    "[default]\n",
    "region = <aws-region>\n",
    "output = <YAML>\n",
    "role_arn = <aws_iam_role>\n",
    "source_profile = default\n",
    "```\n",
    "and `~/.aws/credentials` has the necessary access and secret access keys\n",
    "\n",
    "```\n",
    "[default]\n",
    "aws_access_key_id = <access_key_id>\n",
    "aws_secret_access_key = <secret_access_key>\n",
    "```\n",
    "\n",
    "**PleaseNote**:  Once you have the execution role setup (using iam-role guide from above), you must enable `Trust Policy` which specifies who is allowed to assume the associated role. If this is missing you might get an **error \n",
    "user <user1\\> unable to  STS AssumeRole**. Refer to [trust-policy-iam-role](https://aws.amazon.com/blogs/security/how-to-use-a-single-iam-user-to-easily-access-all-your-accounts-by-using-the-aws-cli/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the AssumeRole operation: User: arn:aws:iam::610527985415:user/bjesudasan is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::610527985415:user/bjesudasan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-072c557efd51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Get a SageMaker-compatible role used by this Notebook Instance.(set role in ~/.aws/config when running locally)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_execution_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mget_execution_role\u001b[0;34m(sagemaker_session)\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m         \u001b[0msagemaker_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3316\u001b[0;31m     \u001b[0marn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_caller_identity_arn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\":role/\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mget_caller_identity_arn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2912\u001b[0m             \u001b[0;34m\"sts\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m             \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_region_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m             \u001b[0mendpoint_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msts_regional_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_region_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m         ).get_caller_identity()[\"Arn\"]\n\u001b[1;32m   2916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             http, parsed_response = self._make_request(\n\u001b[0;32m--> 663\u001b[0;31m                 operation_model, request_dict, request_context)\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         self.meta.events.emit(\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             self.meta.events.emit(\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    100\u001b[0m         logger.debug(\"Making request for %s with params: %s\",\n\u001b[1;32m    101\u001b[0m                      operation_model, request_dict)\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mattempts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         success_response, exception = self._get_response(\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36mcreate_request\u001b[0;34m(self, params, operation_model)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 op_name=operation_model.name)\n\u001b[1;32m    115\u001b[0m             self._event_emitter.emit(event_name, request=request,\n\u001b[0;32m--> 116\u001b[0;31m                                      operation_name=operation_model.name)\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mprepared_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprepared_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0maliased_event_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_event_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maliased_event_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                  \u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36m_emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers_to_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event %s: calling handler %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_on_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/signers.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(self, operation_name, request, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# this method is invoked to sign the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Don't call this method directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     def sign(self, operation_name, request, region_name=None,\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/signers.py\u001b[0m in \u001b[0;36msign\u001b[0;34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signing_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigning_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signing_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_auth_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnknownSignatureVersionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msigning_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'standard'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/signers.py\u001b[0m in \u001b[0;36mget_auth_instance\u001b[0;34m(self, signing_name, region_name, signature_version, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mfrozen_credentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_credentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mfrozen_credentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_credentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frozen_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'credentials'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozen_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREQUIRES_REGION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/credentials.py\u001b[0m in \u001b[0;36mget_frozen_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frozen_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/credentials.py\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 is_mandatory_refresh = self.refresh_needed(\n\u001b[1;32m    506\u001b[0m                     self._mandatory_refresh_timeout)\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protected_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_mandatory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_mandatory_refresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/credentials.py\u001b[0m in \u001b[0;36m_protected_refresh\u001b[0;34m(self, is_mandatory)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# the self._refresh_lock.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh_using\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mperiod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mandatory'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_mandatory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'advisory'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/credentials.py\u001b[0m in \u001b[0;36mfetch_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cached_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_cached_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/credentials.py\u001b[0m in \u001b[0;36m_get_cached_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/credentials.py\u001b[0m in \u001b[0;36m_get_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assume_role_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massume_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_assume_role_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/certifai-sagemaker-model-env/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the AssumeRole operation: User: arn:aws:iam::610527985415:user/bjesudasan is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::610527985415:user/bjesudasan"
     ]
    }
   ],
   "source": [
    "# S3 prefix\n",
    "prefix = 'german-credit-certifai'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.(set role in ~/.aws/config when running locally)\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download german credit dataset from UCI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on macOS wget can be installed via homebrew `brew install wget`\n",
    "- on windows download wget from [here](http://gnuwin32.sourceforge.net/packages/wget.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data -O german_credit.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert downloaded raw dataset to encoded csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_data import make_decoded_data\n",
    "!mkdir -p ./data\n",
    "make_decoded_data(\"data/german_credit-decoded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Test to confirm correct version of scikit-learn and numpy are installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sklearn_version_test\n",
    "import numpy as numpy_version_test\n",
    "assert sklearn_version_test.__version__ == '0.23.1', 'scikit-learn version mismatch, `!pip install scikit-learn==0.22.1` paste this command in a cell to install right sklearn version for this notebook'\n",
    "assert numpy_version_test.__version__   == '1.18.1', 'numpy version mismatch, `!pip install numpy==1.18.1` paste this command in a cell to install right numpy version for this notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the encoded dataset to S3 for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Scikit-learn script to train with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker can run a scikit-learn script using the SKLearn estimator. When executed on SageMaker a number of environment variables are available to access properties of the training environment, such as:\n",
    "\n",
    "- SM_MODEL_DIR: A string representing the path to the directory to write model artifacts to. Any artifacts saved in this folder are uploaded to S3 for model hosting after the training job completes.\n",
    "-  SM_OUTPUT_DIR: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, 'train' and 'test', were used in the call to the SKLearn estimator's fit() method, the following environment variables will be set, following the format SM_CHANNEL_[channel_name]:\n",
    "\n",
    "    SM_CHANNEL_TRAIN: A string representing the path to the directory containing data in the 'train' channel\n",
    "    SM_CHANNEL_TEST: Same as above, but for the 'test' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to script as arguments and can be retrieved with an argparse.ArgumentParser instance. For example, the script that we will run in this notebook is the below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create encoder for the encoding categorical features\n",
    "\n",
    "Note all extra modules and files must be in a directory to be uploaded to sagemaker. We create a directory name `source_dir` and add our files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile source_dir/cat_encoder.py\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class CatEncoder:\n",
    "    def __init__(self, cat_columns, data, normalize: bool=True):\n",
    "        self.cat_indexes = [data.columns.get_loc(name) for name in cat_columns]\n",
    "        self.num_indexes = [idx for idx in range(len(data.columns)) if idx not in self.cat_indexes]\n",
    "        self.encoder = preprocessing.OneHotEncoder()\n",
    "        self.encoder.fit(data[cat_columns])\n",
    "        self.num_columns = list(data.columns[self.num_indexes])\n",
    "        self.cat_columns = cat_columns\n",
    "        cat_transformed_names = self.encoder.get_feature_names(input_features=self.cat_columns)\n",
    "        self._transformed_column_names =  self.num_columns + list(cat_transformed_names)\n",
    "        if normalize:\n",
    "            self.normalizer = StandardScaler()\n",
    "            self.normalizer.fit(data.iloc[:, self.num_indexes])\n",
    "        else:\n",
    "            self.normalizer = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        numeric = x[:, self.num_indexes]\n",
    "        if self.normalizer is not None:\n",
    "            numeric = self.normalizer.transform(numeric)\n",
    "        categorical = self.encoder.transform(x[:, self.cat_indexes]).toarray()\n",
    "        return np.concatenate((numeric, categorical), axis=1)\n",
    "\n",
    "    @property\n",
    "    def transformed_features(self):\n",
    "        return self._transformed_column_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create requirements.txt file for any training/inference specific python packages/versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile source_dir/requirements.txt\n",
    "scikit-learn==0.22.1\n",
    "numpy==1.18.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create logistic model training and inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile source_dir/logistic_script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "from cat_encoder import CatEncoder\n",
    "import json\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    print(f'listing model dir {os.listdir(model_dir)}' )\n",
    "    clf = joblib.load(os.path.join(model_dir,'german_credit_logit.joblib'))\n",
    "    print(clf)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"An input_fn that loads a json bytes string. \n",
    "    Certifai invokes model with the json schema -> {\"payload\": {\"instances\": [ [6,107,88,0,0,36.8,0.727,31], [5,100,80,0,0,31.9,0.61,33] ]}}\n",
    "    \"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        input_data  = json.loads(request_body).get('payload', {}).get('instances', [])\n",
    "        data  = np.array(input_data, dtype=object)\n",
    "        data  = data if data.ndim == 2 else np.reshape(data, (1, -1))\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(f'content type {request_content_type} not supported')\n",
    "\n",
    "def predict_fn(input_data, clf):\n",
    "    \"\"\"certifai expects model response with json\n",
    "    schema -> {\"payload\": {\"predictions\": [1,0]} }\n",
    "    \"\"\"\n",
    "    model = clf.get('model')\n",
    "    encoder = clf.get('encoder')\n",
    "    try:\n",
    "        prediction = model.predict(encoder(input_data))\n",
    "        print(prediction)\n",
    "        return {\"payload\":{ \"predictions\": prediction.tolist()} }\n",
    "    except Exception as e:\n",
    "        return {\"payload\":{ \"error\": str(e)}}\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--train-file', type=str, default='german_credit-decoded.csv')\n",
    "    \n",
    "    # hyperparams for training\n",
    "    parser.add_argument('--max_iter', type=list,  default=[1000])\n",
    "    parser.add_argument('--solver',   type=list,  default= ['lbfgs'])\n",
    "    parser.add_argument('--C',        type=tuple, default=(0.5, 1.0, 2.0))\n",
    "\n",
    "    args, _ = parser.parse_known_args()    \n",
    "    \n",
    "    print('reading data')\n",
    "    df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "    label_column = 'outcome'\n",
    "    y = df[label_column]\n",
    "    X = df.drop(label_column, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # apply categorical encoder to data     \n",
    "    encoder = CatEncoder(cat_columns, X)\n",
    "    \n",
    "    parameters = {'C':args.C, 'solver':args.solver, 'max_iter':args.max_iter}\n",
    "    \n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(encoder(X_train.values), y_train)\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(encoder(X_test.values), y_test)\n",
    "    print(f\"Model accuracy is {accuracy}\")\n",
    "  \n",
    "    # create artifact object with model and encoder\n",
    "    model_path = os.path.join(args.model_dir, 'german_credit_logit')\n",
    "    model_path = f'{model_path}.joblib'\n",
    "    model_obj = {\n",
    "        \"model\":model,\n",
    "        \"encoder\":encoder\n",
    "    }\n",
    "    joblib.dump(value=model_obj, filename=model_path)\n",
    "    print(f'model {model_obj} saved on disk as {model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training logistic model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python source_dir/logistic_script.py --model-dir ./ \\\n",
    "                   --train ./data \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SageMaker Scikit Estimator for logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run our Scikit-learn training script on SageMaker, we construct a sagemaker.sklearn.estimator.sklearn estimator, which accepts several constructor arguments:\n",
    "\n",
    "-    entry_point: The path to the Python script SageMaker runs for training and prediction.\n",
    "-    role: Role ARN\n",
    "-    train_instance_type (optional): The type of SageMaker instances for training. Note: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "-    sagemaker_session (optional): The session used to train on Sagemaker.\n",
    "-    hyperparameters (optional): A dictionary passed to the train function as hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_logistic = SKLearn(\n",
    "    entry_point='logistic_script.py',\n",
    "    framework_version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir='source_dir',\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SKLearn logistic model Estimator on german credit encoded data uploaded to S3\n",
    "Training is very simple, just call fit on the Estimator. This will start a SageMaker Training job that will download the data for us, invoke our scikit-learn code (in the provided script file inside the source_dir), and save any model artifacts that the script creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_logistic.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly create svm model training and inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile source_dir/svm_script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "from cat_encoder import CatEncoder\n",
    "import json\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    print(f'listing model dir {os.listdir(model_dir)}' )\n",
    "    clf = joblib.load(os.path.join(model_dir,'german_credit_svm.joblib'))\n",
    "    print(clf)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"An input_fn that loads a json bytes string\"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        input_data  = json.loads(request_body).get('payload', {}).get('instances', [])\n",
    "        data  = np.array(input_data, dtype=object)\n",
    "        data  = data if data.ndim == 2 else np.reshape(data, (1, -1))\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(f'content type {request_content_type} not supported')\n",
    "\n",
    "def predict_fn(input_data, clf):\n",
    "    model = clf.get('model')\n",
    "    encoder = clf.get('encoder')\n",
    "    try:\n",
    "        prediction = model.predict(encoder(input_data))\n",
    "        print(prediction)\n",
    "        return {\"payload\":{ \"predictions\": prediction.tolist()} }\n",
    "    except Exception as e:\n",
    "        return {\"payload\":{ \"error\": str(e)}}\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--train-file', type=str, default='german_credit-decoded.csv')\n",
    "    \n",
    "    # hyperparams for training\n",
    "    parser.add_argument('--kernel', type=list,  default= ['linear', 'rbf', 'poly'])\n",
    "    parser.add_argument('--gamma',  type=list,  default= ['auto'])\n",
    "    parser.add_argument('--C',      type=list,  default= [0.1, .5, 1, 2, 4, 10])\n",
    "\n",
    "    args, _ = parser.parse_known_args()    \n",
    "    \n",
    "    print('reading data')\n",
    "    df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "    label_column = 'outcome'\n",
    "    y = df[label_column]\n",
    "    X = df.drop(label_column, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # apply categorical encoder to data     \n",
    "    encoder = CatEncoder(cat_columns, X)\n",
    "        \n",
    "    parameters={'kernel':args.kernel, 'C':args.C, 'gamma':args.gamma}\n",
    "    m = svm.SVC()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(encoder(X_train.values), y_train)\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(encoder(X_test.values), y_test)\n",
    "    print(f\"Model accuracy is {accuracy}\")\n",
    "  \n",
    "    # create artifact object with model and encoder\n",
    "    model_path = os.path.join(args.model_dir, 'german_credit_svm')\n",
    "    model_path = f'{model_path}.joblib'\n",
    "    model_obj = {\n",
    "        \"model\":model,\n",
    "        \"encoder\":encoder\n",
    "    }\n",
    "    joblib.dump(value=model_obj, filename=model_path)\n",
    "    print(f'model {model_obj} saved on disk as {model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training svm model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python source_dir/svm_script.py --model-dir ./ \\\n",
    "                   --train ./data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly create SageMaker Scikit Estimator for svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_svm = SKLearn(\n",
    "    entry_point='svm_script.py',\n",
    "    framework_version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir='source_dir',\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SKLearn svm model Estimator on german credit encoded data uploaded to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained model to make inference requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the models\n",
    "\n",
    "**Note:** this might take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_logistic = sklearn_logistic.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_svm      = sklearn_svm.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "idata = json.dumps({\"payload\":{\n",
    "    \"instances\":[\n",
    "            \"... < 0 DM\",\n",
    "            6,\n",
    "            \"critical account/ other credits existing (not at this bank)\",\n",
    "            \"radio/television\",\n",
    "            1169,\n",
    "            \"unknown/ no savings account\",\n",
    "            \".. >= 7 years\",\n",
    "            4,\n",
    "            \"male : single\",\n",
    "            \"others - none\",\n",
    "            4,\n",
    "            \"real estate\",\n",
    "            \"> 25 years\",\n",
    "            \"none\",\n",
    "            \"own\",\n",
    "            2,\n",
    "            \"skilled employee / official\",\n",
    "            1,\n",
    "            \"phone - yes, registered under the customers name\",\n",
    "            \"foreign - yes\"\n",
    "        ]}})\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "from botocore.exceptions import HTTPClientError\n",
    "client=boto3.client('sagemaker-runtime')\n",
    "try:\n",
    "    resp = client.invoke_endpoint(EndpointName=predictor_logistic.endpoint,Body=idata)\n",
    "    print(json.loads(resp['Body'].read()))\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cortex Certifai Toolkit path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [optional] update the `certifai_toolkit_path` to a local file path where the downloaded toolkit from S3 bucket will be saved\n",
    "- this will be used in the next cell to install cortex certifai python packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download toolkit from S3 bucket to current environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "home = expanduser('~')\n",
    "certifai_toolkit = 'certifai_toolkit.zip'\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file('certifai-testing', certifai_toolkit, certifai_toolkit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unzip and extract cortex_certifai_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf certifai_toolkit\n",
    "!unzip -q -d certifai_toolkit $certifai_toolkit\n",
    "!cat certifai_toolkit/version.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required certifai packages (optional packages are left for user to install)¶\n",
    "\n",
    "initiating a Cortex Certifai scan requires following python packages to be installed in the current local environment. We will be using `cortex-certifai-connectors` package which provided first class support for sagemaker models\n",
    "\n",
    "required-packages\n",
    "\n",
    "-    cortex-certifai-scanner\n",
    "-    cortex-certifai-engine\n",
    "-    cortex-certifai-common\n",
    "-    cortex-certifai-connectors\n",
    "\n",
    "optional-packages\n",
    "\n",
    "-   cortex-certifai-client\n",
    "-   cortex-certifai-console\n",
    "\n",
    "**NOTE:** Make sure to install `cortex-certifai-engine` package for correct python version, by default it will install for `$certifai_toolkitpackages/python3.6` in the cell below. python 3.6/7/8 are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find certifai_toolkit/packages/all       -type f ! -name \"*console-*\" | xargs -I % sh -c 'pip install % ' ;\n",
    "!find certifai_toolkit/packages/python3.6 -type f   -name \"*engine-*\"                      | xargs -I % sh -c 'pip install % ' ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cortex Certifai python-package to launch a scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue,\n",
    "                                      CertifaiModelConnector, CertifaiModelMetric)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### define cortex certifai task type\n",
    "\n",
    "-    CertifaiTaskOutcomes : cortex certifai supports classification as well as regression models. here we have an example of binary-classification (e.g. predict whether loan should be granted or not)\n",
    "-    CertifaiOutcomeValue : define the different outcomes possible from the model predictions. here we have a model that predicts either 1(loan granted) or 2(loan denied)\n",
    "\n",
    "Note: Please refer to [Certifai Api Docs](https://cognitivescale.github.io/cortex-certifai/certifai-api-ref/certifai.scanner.builder.html) for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "all_data_file = f\"{base_path}/data/german_credit-decoded.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')\n",
    "\n",
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### add logistic and svm models sagemaker models deployed above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the SageMaker model\n",
    "sagemaker_connector = CertifaiModelConnector('sagemaker', 'certifai.connectors.sagemaker', 'SageMakerModel')\n",
    "first_model = CertifaiModel('logit_sagemaker',\n",
    "                            predict_endpoint=predictor_logistic.endpoint,\n",
    "                            connector=sagemaker_connector)\n",
    "scan.add_model(first_model)\n",
    "second_model = CertifaiModel('svm_sagemaker',\n",
    "                            predict_endpoint=predictor_svm.endpoint,\n",
    "                            connector=sagemaker_connector)\n",
    "scan.add_model(second_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### add the evaluation dataset to scan object\n",
    "\n",
    "-    evaluation dataset dataset to be used by cortex certifai to evaluate the model against\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(all_data_file))\n",
    "scan.add_dataset(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating model fairness\n",
    "\n",
    "-   add fairness as evaluation type to scan object\n",
    "-   create an evaluation_dataset_id to refer to added evaluation datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup an evaluation for fairness on the above dataset using the model\n",
    "# We'll look at disparity between groups defined by marital status and age\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset contains a ground truth outcome column which the model does not\n",
    "# expect to receive as input we need to state that in the dataset schema (since it cannot\n",
    "# be inferred from the CSV)\n",
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scan.\n",
    "# By default this will write the results into individual report files (one per model and evaluation\n",
    "# type) in the 'reports' directory relative to the Jupyter root.  This may be disabled by specifying\n",
    "# `write_reports=False` as below\n",
    "# The result is a dictionary of dictionaries of reports.  The top level dict key is the evaluation type\n",
    "# and the second level key is model id.\n",
    "# Reports saved as JSON (which `write_reports=True` will do) may be visualized in the console app\n",
    "result = scan.run(write_reports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Analayze Fairness Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is a dictionary keyed on analysis, containing reports keyed on model id\n",
    "# The console app is the recommended way to view these, by saving the results to file\n",
    "# (see previous cell), but programmatic analysis of the result here is also possible\n",
    "df = construct_scores_dataframe(scores('fairness', result), include_confidence=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### fairness by model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many scores also come with 95% confidence bounds, which we omitted above for the sake of brevity, but\n",
    "# we can include those also.  In the example here we include the confidence bounds but only display the scores\n",
    "# to a reduced level of detail to keep a smallish table for display purposes\n",
    "df = construct_scores_dataframe(scores('fairness', result, max_depth=1))\n",
    "display(df)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Let's chart the fairness measure by feature for each model together with its confidence bounds for\n",
    "# easier visual comparison:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['Feature (status)', 'Feature (age)']\n",
    "feature_scores = df[features]\n",
    "feature_lower_bounds = df[[f + ' lower bound' for f in features]]\n",
    "feature_upper_bounds = df[[f + ' upper bound' for f in features]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,4])\n",
    "ax.set_title('Feature fairness by model', fontsize=20)\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:pink']\n",
    "width = 0.4\n",
    "\n",
    "ax.set_xticks(np.arange(len(features))+width)\n",
    "ax.set_xticklabels(features)\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    central_values = list(feature_scores.iloc[idx])\n",
    "    lower_bounds = list(feature_lower_bounds.iloc[idx])\n",
    "    upper_bounds = list(feature_upper_bounds.iloc[idx])\n",
    "    lower_errors = [central_values[i] - lower_bounds[i] for i in range(len(central_values))]\n",
    "    upper_errors = [upper_bounds[i] - central_values[i] for i in range(len(central_values))]\n",
    "\n",
    "    ax.bar([width/2+idx*width+f_idx for f_idx in range(len(features))],\n",
    "            central_values,\n",
    "            width,\n",
    "            yerr=[lower_errors, upper_errors],\n",
    "            color=colors[idx],\n",
    "            label=df.index[idx],\n",
    "            capsize=10)\n",
    "\n",
    "fig.legend(fontsize=14, bbox_to_anchor=(1.1,.6))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.8) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint cleanup\n",
    "\n",
    "delete the containers created after evaluation is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm.delete_endpoint()\n",
    "sklearn_logistic.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
