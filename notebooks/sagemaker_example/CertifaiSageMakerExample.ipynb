{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Running Cortex Certifai Scan on Sklearn model built and deployed on AWS Sagemaker using Certifai Model Connectors\n",
    "\n",
    "\n",
    "In this tutorial we will create sklearn models to classify german credit loan risk (predict whether loan will be granted or not). Models are built using Scikit-learn with [Sagemaker](https://sagemaker.readthedocs.io/en/stable/using_sklearn.html) by utilizing the pre-built container. Cortex Certifai provides first class support for various machine learning platforms including aws-sagemaker. We will then use [Cortex Certifai Toolkit](https://www.cognitivescale.com/download-certifai/) to launch fairness evaluation on the hosted models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "This notebook was created and tested on an ml.m4.xlarge sagemaker notebook instance. However you can also run it locally by making sure you have the [aws profile](https://docs.aws.amazon.com/cli/latest/reference/configure/) configured and following dependencies installed on your system\n",
    "\n",
    "\n",
    "- python>=3.6.2,<=3.7\n",
    "- scikit-learn==0.22.1\n",
    "- numpy==1.18.1\n",
    "- pandas\n",
    "- sagemaker==1.58.2\n",
    "- ipython\n",
    "- matplotlib\n",
    "- jupyter\n",
    "- [optional for configuring aws profile] awscli==1.18.61\n",
    "- wget (when running locally on mac/windows)\n",
    "\n",
    "\n",
    "> **Please note**: this tutorial assumes you have downloaded the [Cortex Certifai Toolkit](https://www.cognitivescale.com/download-certifai/) and uploaded it to your `S3` bucket which will be later used to install certifai packages.\n",
    "> Also make sure you have configured aws with right roles and region for using S3 bucket and sagemaker utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, lets create our Sagemaker session and role, and create a S3 prefix to use for the notebook example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sagemaker iam role guide\n",
    "- follow the [sagemaker-iam-role-documentation](https://docs.aws.amazon.com/glue/latest/dg/create-an-iam-role-sagemaker-notebook.html) for creating an `iam-role`\n",
    "\n",
    "> this notebook was built using iam-role `AmazonSageMakerFullAccess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'german-credit-certifai'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.(set role in ~/.aws/config when running locally)\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download german credit dataset from UCI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on macOS wget can be installed via homebrew `brew install wget`\n",
    "- on windows download wget from [here](http://gnuwin32.sourceforge.net/packages/wget.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-21 23:16:56--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 79793 (78K) [application/x-httpd-php]\n",
      "Saving to: ‘german_credit.csv’\n",
      "\n",
      "german_credit.csv   100%[===================>]  77.92K   150KB/s    in 0.5s    \n",
      "\n",
      "2020-05-21 23:16:58 (150 KB/s) - ‘german_credit.csv’ saved [79793/79793]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data -O german_credit.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert downloaded raw dataset to encoded csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving decoded data as data/german_credit-decoded.csv\n"
     ]
    }
   ],
   "source": [
    "from decode_data import make_decoded_data\n",
    "!mkdir -p ./data\n",
    "make_decoded_data(\"data/german_credit-decoded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Test to confirm correct version of scikit-learn and numpy are installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sklearn_version_test\n",
    "import numpy as numpy_version_test\n",
    "assert sklearn_version_test.__version__ == '0.22.1', 'scikit-learn version mismatch, `!pip install scikit-learn==0.22.1` paste this command in a cell to install right sklearn version for this notebook'\n",
    "assert numpy_version_test.__version__   == '1.18.1', 'numpy version mismatch, `!pip install numpy==1.18.1` paste this command in a cell to install right numpy version for this notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the encoded dataset to S3 for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Scikit-learn script to train with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker can run a scikit-learn script using the SKLearn estimator. When executed on SageMaker a number of environment variables are available to access properties of the training environment, such as:\n",
    "\n",
    "- SM_MODEL_DIR: A string representing the path to the directory to write model artifacts to. Any artifacts saved in this folder are uploaded to S3 for model hosting after the training job completes.\n",
    "-  SM_OUTPUT_DIR: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, 'train' and 'test', were used in the call to the SKLearn estimator's fit() method, the following environment variables will be set, following the format SM_CHANNEL_[channel_name]:\n",
    "\n",
    "    SM_CHANNEL_TRAIN: A string representing the path to the directory containing data in the 'train' channel\n",
    "    SM_CHANNEL_TEST: Same as above, but for the 'test' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to script as arguments and can be retrieved with an argparse.ArgumentParser instance. For example, the script that we will run in this notebook is the below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create encoder for the encoding categorical features\n",
    "\n",
    "Note all extra modules and files must be in a directory to be uploaded to sagemaker. We create a directory name `source_dir` and add our files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/cat_encoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/cat_encoder.py\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class CatEncoder:\n",
    "    def __init__(self, cat_columns, data, normalize: bool=True):\n",
    "        self.cat_indexes = [data.columns.get_loc(name) for name in cat_columns]\n",
    "        self.num_indexes = [idx for idx in range(len(data.columns)) if idx not in self.cat_indexes]\n",
    "        self.encoder = preprocessing.OneHotEncoder()\n",
    "        self.encoder.fit(data[cat_columns])\n",
    "        self.num_columns = list(data.columns[self.num_indexes])\n",
    "        self.cat_columns = cat_columns\n",
    "        cat_transformed_names = self.encoder.get_feature_names(input_features=self.cat_columns)\n",
    "        self._transformed_column_names =  self.num_columns + list(cat_transformed_names)\n",
    "        if normalize:\n",
    "            self.normalizer = StandardScaler()\n",
    "            self.normalizer.fit(data.iloc[:, self.num_indexes])\n",
    "        else:\n",
    "            self.normalizer = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        numeric = x[:, self.num_indexes]\n",
    "        if self.normalizer is not None:\n",
    "            numeric = self.normalizer.transform(numeric)\n",
    "        categorical = self.encoder.transform(x[:, self.cat_indexes]).toarray()\n",
    "        return np.concatenate((numeric, categorical), axis=1)\n",
    "\n",
    "    @property\n",
    "    def transformed_features(self):\n",
    "        return self._transformed_column_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create requirements.txt file for any training/inference specific python packages/versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/requirements.txt\n",
    "scikit-learn==0.22.1\n",
    "numpy==1.18.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create logistic model training and inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/logistic_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/logistic_script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "from cat_encoder import CatEncoder\n",
    "import json\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    print(f'listing model dir {os.listdir(model_dir)}' )\n",
    "    clf = joblib.load(os.path.join(model_dir,'german_credit_logit.joblib'))\n",
    "    print(clf)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"An input_fn that loads a json bytes string. \n",
    "    Certifai invokes model with the json schema -> {\"payload\": {\"instances\": [ [6,107,88,0,0,36.8,0.727,31], [5,100,80,0,0,31.9,0.61,33] ]}}\n",
    "    \"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        input_data  = json.loads(request_body).get('payload', {}).get('instances', [])\n",
    "        data  = np.array(input_data, dtype=object)\n",
    "        data  = data if data.ndim == 2 else np.reshape(data, (1, -1))\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(f'content type {request_content_type} not supported')\n",
    "\n",
    "def predict_fn(input_data, clf):\n",
    "    \"\"\"certifai expects model response with json\n",
    "    schema -> {\"payload\": {\"predictions\": [1,0]} }\n",
    "    \"\"\"\n",
    "    model = clf.get('model')\n",
    "    encoder = clf.get('encoder')\n",
    "    try:\n",
    "        prediction = model.predict(encoder(input_data))\n",
    "        print(prediction)\n",
    "        return {\"payload\":{ \"predictions\": prediction.tolist()} }\n",
    "    except Exception as e:\n",
    "        return {\"payload\":{ \"error\": str(e)}}\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--train-file', type=str, default='german_credit-decoded.csv')\n",
    "    \n",
    "    # hyperparams for training\n",
    "    parser.add_argument('--max_iter', type=list,  default=[1000])\n",
    "    parser.add_argument('--solver',   type=list,  default= ['lbfgs'])\n",
    "    parser.add_argument('--C',        type=tuple, default=(0.5, 1.0, 2.0))\n",
    "\n",
    "    args, _ = parser.parse_known_args()    \n",
    "    \n",
    "    print('reading data')\n",
    "    df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "    label_column = 'outcome'\n",
    "    y = df[label_column]\n",
    "    X = df.drop(label_column, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # apply categorical encoder to data     \n",
    "    encoder = CatEncoder(cat_columns, X)\n",
    "    \n",
    "    parameters = {'C':args.C, 'solver':args.solver, 'max_iter':args.max_iter}\n",
    "    \n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(encoder(X_train.values), y_train)\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(encoder(X_test.values), y_test)\n",
    "    print(f\"Model accuracy is {accuracy}\")\n",
    "  \n",
    "    # create artifact object with model and encoder\n",
    "    model_path = os.path.join(args.model_dir, 'german_credit_logit')\n",
    "    model_path = f'{model_path}.joblib'\n",
    "    model_obj = {\n",
    "        \"model\":model,\n",
    "        \"encoder\":encoder\n",
    "    }\n",
    "    joblib.dump(value=model_obj, filename=model_path)\n",
    "    print(f'model {model_obj} saved on disk as {model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training logistic model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "extracting arguments\n",
      "reading data\n",
      "Model accuracy is 0.765\n",
      "model {'model': GridSearchCV(cv=3, error_score=nan,\n",
      "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                          fit_intercept=True,\n",
      "                                          intercept_scaling=1, l1_ratio=None,\n",
      "                                          max_iter=100, multi_class='auto',\n",
      "                                          n_jobs=None, penalty='l2',\n",
      "                                          random_state=None, solver='lbfgs',\n",
      "                                          tol=0.0001, verbose=0,\n",
      "                                          warm_start=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'C': (0.5, 1.0, 2.0), 'max_iter': [1000],\n",
      "                         'solver': ['lbfgs']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0), 'encoder': <cat_encoder.CatEncoder object at 0x7fcbd059ba90>} saved on disk as ./german_credit_logit.joblib\n"
     ]
    }
   ],
   "source": [
    "! python source_dir/logistic_script.py --model-dir ./ \\\n",
    "                   --train ./data \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SageMaker Scikit Estimator for logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run our Scikit-learn training script on SageMaker, we construct a sagemaker.sklearn.estimator.sklearn estimator, which accepts several constructor arguments:\n",
    "\n",
    "-    entry_point: The path to the Python script SageMaker runs for training and prediction.\n",
    "-    role: Role ARN\n",
    "-    train_instance_type (optional): The type of SageMaker instances for training. Note: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "-    sagemaker_session (optional): The session used to train on Sagemaker.\n",
    "-    hyperparameters (optional): A dictionary passed to the train function as hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_logistic = SKLearn(\n",
    "    entry_point='logistic_script.py',\n",
    "    source_dir='source_dir',\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SKLearn logistic model Estimator on german credit encoded data uploaded to S3\n",
    "Training is very simple, just call fit on the Estimator. This will start a SageMaker Training job that will download the data for us, invoke our scikit-learn code (in the provided script file inside the source_dir), and save any model artifacts that the script creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_logistic.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly create svm model training and inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/svm_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/svm_script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "from cat_encoder import CatEncoder\n",
    "import json\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    print(f'listing model dir {os.listdir(model_dir)}' )\n",
    "    clf = joblib.load(os.path.join(model_dir,'german_credit_svm.joblib'))\n",
    "    print(clf)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"An input_fn that loads a json bytes string\"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        input_data  = json.loads(request_body).get('payload', {}).get('instances', [])\n",
    "        data  = np.array(input_data, dtype=object)\n",
    "        data  = data if data.ndim == 2 else np.reshape(data, (1, -1))\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(f'content type {request_content_type} not supported')\n",
    "\n",
    "def predict_fn(input_data, clf):\n",
    "    model = clf.get('model')\n",
    "    encoder = clf.get('encoder')\n",
    "    try:\n",
    "        prediction = model.predict(encoder(input_data))\n",
    "        print(prediction)\n",
    "        return {\"payload\":{ \"predictions\": prediction.tolist()} }\n",
    "    except Exception as e:\n",
    "        return {\"payload\":{ \"error\": str(e)}}\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--train-file', type=str, default='german_credit-decoded.csv')\n",
    "    \n",
    "    # hyperparams for training\n",
    "    parser.add_argument('--kernel', type=list,  default= ['linear', 'rbf', 'poly'])\n",
    "    parser.add_argument('--gamma',  type=list,  default= ['auto'])\n",
    "    parser.add_argument('--C',      type=list,  default= [0.1, .5, 1, 2, 4, 10])\n",
    "\n",
    "    args, _ = parser.parse_known_args()    \n",
    "    \n",
    "    print('reading data')\n",
    "    df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "    label_column = 'outcome'\n",
    "    y = df[label_column]\n",
    "    X = df.drop(label_column, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # apply categorical encoder to data     \n",
    "    encoder = CatEncoder(cat_columns, X)\n",
    "        \n",
    "    parameters={'kernel':args.kernel, 'C':args.C, 'gamma':args.gamma}\n",
    "    m = svm.SVC()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(encoder(X_train.values), y_train)\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(encoder(X_test.values), y_test)\n",
    "    print(f\"Model accuracy is {accuracy}\")\n",
    "  \n",
    "    # create artifact object with model and encoder\n",
    "    model_path = os.path.join(args.model_dir, 'german_credit_svm')\n",
    "    model_path = f'{model_path}.joblib'\n",
    "    model_obj = {\n",
    "        \"model\":model,\n",
    "        \"encoder\":encoder\n",
    "    }\n",
    "    joblib.dump(value=model_obj, filename=model_path)\n",
    "    print(f'model {model_obj} saved on disk as {model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training svm model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "extracting arguments\n",
      "reading data\n",
      "Model accuracy is 0.75\n",
      "model {'model': GridSearchCV(cv=3, error_score=nan,\n",
      "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
      "                           class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'C': [0.1, 0.5, 1, 2, 4, 10], 'gamma': ['auto'],\n",
      "                         'kernel': ['linear', 'rbf', 'poly']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0), 'encoder': <cat_encoder.CatEncoder object at 0x7fcaf182a7d0>} saved on disk as ./german_credit_svm.joblib\n"
     ]
    }
   ],
   "source": [
    "! python source_dir/svm_script.py --model-dir ./ \\\n",
    "                   --train ./data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly create SageMaker Scikit Estimator for svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_svm = SKLearn(\n",
    "    entry_point='svm_script.py',\n",
    "    source_dir='source_dir',\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SKLearn svm model Estimator on german credit encoded data uploaded to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained model to make inference requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor_logistic = sklearn_logistic.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_svm      = sklearn_svm.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'payload': {'predictions': [1]}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "idata = json.dumps({\"payload\":{\n",
    "    \"instances\":[\n",
    "            \"... < 0 DM\",\n",
    "            6,\n",
    "            \"critical account/ other credits existing (not at this bank)\",\n",
    "            \"radio/television\",\n",
    "            1169,\n",
    "            \"unknown/ no savings account\",\n",
    "            \".. >= 7 years\",\n",
    "            4,\n",
    "            \"male : single\",\n",
    "            \"others - none\",\n",
    "            4,\n",
    "            \"real estate\",\n",
    "            \"> 25 years\",\n",
    "            \"none\",\n",
    "            \"own\",\n",
    "            2,\n",
    "            \"skilled employee / official\",\n",
    "            1,\n",
    "            \"phone - yes, registered under the customers name\",\n",
    "            \"foreign - yes\"\n",
    "        ]}})\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "from botocore.exceptions import HTTPClientError\n",
    "client=boto3.client('sagemaker-runtime')\n",
    "try:\n",
    "    resp = client.invoke_endpoint(EndpointName=predictor_logistic.endpoint,Body=idata)\n",
    "    print(json.loads(resp['Body'].read()))\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cortex Certifai Toolkit path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- update the certifai_toolkit_path to point your downloaded toolkit from S3 bucket\n",
    "- this will be used later to install cortex certifai python packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download toolkit from S3 bucket to current environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "home = expanduser('~')\n",
    "certifai_toolkit = 'certifai_toolkit.zip'\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file('S3_BUCKET_NAME', 'S3_OBJECT_NAME', certifai_toolkit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unzip and extract cortex_certifai_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certifai Version: 1.2.14\r\n",
      "Scanner build: 1.2.14-115-g96dc7f43\r\n",
      "Console build: 1.2.14-81-gca71bec\r\n",
      "Reference Models build: 1.2.14-1-gae546f6\r\n"
     ]
    }
   ],
   "source": [
    "!unzip -q -d certifai_toolkit $certifai_toolkit\n",
    "!cat certifai_toolkit/version.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required certifai packages (optional packages are left for user to install)¶\n",
    "\n",
    "initiating a Cortex Certifai scan requires following python packages to be installed in the current local environment. We will be using `cortex-certifai-connectors` package which provided first class support for sagemaker models\n",
    "\n",
    "required-packages\n",
    "\n",
    "-    cortex-certifai-scanner\n",
    "-    cortex-certifai-engine\n",
    "-    cortex-certifai-common\n",
    "-    cortex-certifai-connectors\n",
    "\n",
    "optional-packages\n",
    "\n",
    "-   cortex-certifai-client\n",
    "-   cortex-certifai-console\n",
    "\n",
    "Download certifai toolkit and follow instructions in the Readme.md to install the python-packages in the current environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find certifai_toolkit/packages/all       -type f ! -name \"*console-*\" | xargs -I % sh -c 'pip install % ' ;\n",
    "!find certifai_toolkit/packages/python3.6 -type f   -name \"*engine-*\"                      | xargs -I % sh -c 'pip install % ' ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cortex Certifai python-package to launch a scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue,\n",
    "                                      CertifaiModelConnector, CertifaiModelMetric)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### define cortex certifai task type\n",
    "\n",
    "-    CertifaiTaskOutcomes : cortex certifai supports classification as well as regression models. here we have an example of binary-classification (e.g. predict whether loan should be granted or not)\n",
    "-    CertifaiOutcomeValue : define the different outcomes possible from the model predictions. here we have a model that predicts either 1(loan granted) or 2(loan denied)\n",
    "\n",
    "Note: Please refer to [Certifai Api Docs](https://cognitivescale.github.io/cortex-certifai/certifai-api-ref/certifai.scanner.builder.html) for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "all_data_file = f\"{base_path}/data/german_credit-decoded.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')\n",
    "\n",
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### add logistic and svm models sagemaker models deployed above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the SageMaker model\n",
    "sagemaker_connector = CertifaiModelConnector('sagemaker', 'certifai.connectors.sagemaker', 'SageMakerModel')\n",
    "first_model = CertifaiModel('logit_sagemaker',\n",
    "                            predict_endpoint=predictor_logistic.endpoint,\n",
    "                            connector=sagemaker_connector)\n",
    "scan.add_model(first_model)\n",
    "second_model = CertifaiModel('svm_sagemaker',\n",
    "                            predict_endpoint=predictor_svm.endpoint,\n",
    "                            connector=sagemaker_connector)\n",
    "scan.add_model(second_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### add the evaluation dataset to scan object\n",
    "\n",
    "-    evaluation dataset dataset to be used by cortex certifai to evaluate the model against\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(all_data_file))\n",
    "scan.add_dataset(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating model fairness\n",
    "\n",
    "-   add fairness as evaluation type to scan object\n",
    "-   create an evaluation_dataset_id to refer to added evaluation datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup an evaluation for fairness on the above dataset using the model\n",
    "# We'll look at disparity between groups defined by marital status and age\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset contains a ground truth outcome column which the model does not\n",
    "# expect to receive as input we need to state that in the dataset schema (since it cannot\n",
    "# be inferred from the CSV)\n",
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scan.\n",
    "# By default this will write the results into individual report files (one per model and evaluation\n",
    "# type) in the 'reports' directory relative to the Jupyter root.  This may be disabled by specifying\n",
    "# `write_reports=False` as below\n",
    "# The result is a dictionary of dictionaries of reports.  The top level dict key is the evaluation type\n",
    "# and the second level key is model id.\n",
    "# Reports saved as JSON (which `write_reports=True` will do) may be visualized in the console app\n",
    "result = scan.run(write_reports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Analayze Fairness Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is a dictionary keyed on analysis, containing reports keyed on model id\n",
    "# The console app is the recommended way to view these, by saving the results to file\n",
    "# (see previous cell), but programmatic analysis of the result here is also possible\n",
    "print(type(result['fairness']['SVM']['fairness']['secondary_scores']))\n",
    "df = construct_scores_dataframe(scores('fairness', result), include_confidence=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### fairness by model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many scores also come with 95% confidence bounds, which we omitted above for the sake of brevity, but\n",
    "# we can include those also.  In the example here we include the confidence bounds but only display the scores\n",
    "# to a reduced level of detail to keep a smallish table for display purposes\n",
    "df = construct_scores_dataframe(scores('fairness', result, max_depth=1))\n",
    "display(df)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Let's chart the fairness measure by feature for each model together with its confidence bounds for\n",
    "# easier visual comparison:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['Feature (status)', 'Feature (age)']\n",
    "feature_scores = df[features]\n",
    "feature_lower_bounds = df[[f + ' lower bound' for f in features]]\n",
    "feature_upper_bounds = df[[f + ' upper bound' for f in features]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,4])\n",
    "ax.set_title('Feature fairness by model', fontsize=20)\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:pink']\n",
    "width = 0.4\n",
    "\n",
    "ax.set_xticks(np.arange(len(features))+width)\n",
    "ax.set_xticklabels(features)\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    central_values = list(feature_scores.iloc[idx])\n",
    "    lower_bounds = list(feature_lower_bounds.iloc[idx])\n",
    "    upper_bounds = list(feature_upper_bounds.iloc[idx])\n",
    "    lower_errors = [central_values[i] - lower_bounds[i] for i in range(len(central_values))]\n",
    "    upper_errors = [upper_bounds[i] - central_values[i] for i in range(len(central_values))]\n",
    "\n",
    "    ax.bar([width/2+idx*width+f_idx for f_idx in range(len(features))],\n",
    "            central_values,\n",
    "            width,\n",
    "            yerr=[lower_errors, upper_errors],\n",
    "            color=colors[idx],\n",
    "            label=df.index[idx],\n",
    "            capsize=10)\n",
    "\n",
    "fig.legend(fontsize=14, bbox_to_anchor=(1.1,.6))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.8) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint cleanup\n",
    "\n",
    "delete the containers created after evaluation is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm.delete_endpoint()\n",
    "sklearn_logistic.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
