{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the scanner within a notebook from a definition file\n",
    "\n",
    "In this notebook we will show how to run a scan from an existing scan template definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from certifai.scanner.builder import CertifaiScanBuilder, CertifaiPredictorWrapper\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special import - \n",
    "# for multiprocessing to work in a Notebook,  pickled classes must be in a separate package or notebook\n",
    "# hence, the encoder class has to be somewhere other than the current notebook\n",
    "# from ipynb.fs.defs.cat_encoder import CatEncoder # <- doesn't work on Azure Notebooks\n",
    "# %run cat_encoder.py # <- doesn't work because code doesn't remain external\n",
    "\n",
    "# Azure Notebooks workaround - \n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from cat_encoder import CatEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example will use a simple logistic classifier on the German Credit dataset\n",
    "defs_path = '../definitions'\n",
    "scan_def = f\"{defs_path}/german_credit_scanner_definition.yaml\"\n",
    "all_data_file = f\"../datasets/german_credit_eval.csv\"\n",
    "\n",
    "df = pd.read_csv(all_data_file)\n",
    "\n",
    "cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "label_column = 'outcome'\n",
    "\n",
    "# Separate outcome\n",
    "y = df[label_column]\n",
    "X = df.drop(label_column, axis=1)\n",
    "\n",
    "# Note - to support python multi-processing in the context of a notebook the encoder MUST\n",
    "# be in a separate file, which is why `CatEncoder` is defined outside of this notebook\n",
    "encoder = CatEncoder(cat_columns, X)\n",
    "\n",
    "# Fit a classification model (note - no train/test split here currently as I'm just using the same data as\n",
    "# the scan will)\n",
    "model = LogisticRegression(random_state=0, solver=\"lbfgs\", max_iter=1000)\n",
    "model.fit(encoder(X.values), y)\n",
    "\n",
    "# Assess on the test set\n",
    "accuracy = model.score(encoder(X.values), y.values)\n",
    "print(f\"Model accuracy on all data is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the model up for use by Certifai as a local model\n",
    "model_proxy = CertifaiPredictorWrapper(model, encoder=encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scan with the local model injected\n",
    "# First load the scan template\n",
    "scan = CertifaiScanBuilder.from_file(scan_def)\n",
    "# Adjust the 'logit' model to use the local predictor\n",
    "for m in scan.models:\n",
    "    if m.id == 'logit':\n",
    "        print(\"Adding local predictor for logit model\")\n",
    "        m.local_predictor = model_proxy\n",
    "\n",
    "# For simplicity restrict the output to just the `logit` model (since we only overrode that one) and\n",
    "# the reports to just the fairness report.  Paths in the scan template are interpreted relative to\n",
    "# the directory containing the template, but since we're providing a template object directly rather\n",
    "# than sourcing from the file, we need to provide a `base_path` which relative paths in the template\n",
    "# will be with respect to.\n",
    "result = scan.run(model_id='logit',\n",
    "                  report='fairness',\n",
    "                  base_path=defs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default running a scan will write the results into individual report files (one per model and evaluation\n",
    "# type) in the output directory specified by the template (relative to the `base_path`).  This may be disabled by specifying\n",
    "# `write_reports=False` in the `run` call above, or forced to a different output directory by specifying\n",
    "# `output=<override path>`\n",
    "#\n",
    "# The result is a dictionary of dictionaries of reports.  The top level dict key is the evaluation type\n",
    "# and the second level key is model id.\n",
    "# Reports saved as JSON (which `write_reports=True` will do) may be visualized in the console app\n",
    "#\n",
    "# Note - saved reports are one model and evaluation type per report file - that is to say that each second level\n",
    "# entry in the nested dictionary produced by a scan will be saved as a separate file\n",
    "\n",
    "# We can also take a look at our results in the notebook directly (for example if we want to perform a bespoke analysis\n",
    "# not directly supported by the console UI)\n",
    "all_scores = next(scores('fairness', result))\n",
    "\n",
    "# Plot the burdens for each protected group - first assess the feature and class structure based on the scores\n",
    "# from a representative sample (the first model)\n",
    "# Fairness scores have sub-scores for each feature, and within each of those sub-scores for each group\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_scores = all_scores.children\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,4])\n",
    "ax.set_title('Group burdens by feature', fontsize=20)\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:pink']\n",
    "max_groups = 5\n",
    "width = 0.75/max_groups\n",
    "spacing = 0.8/max_groups\n",
    "\n",
    "ticks = []\n",
    "ticklabels = []\n",
    "\n",
    "for f_idx, f in enumerate(feature_scores): \n",
    "    feature_group_scores = f.children\n",
    "    burdens = [b.value for b in feature_group_scores]\n",
    "    x = [f_idx + g_idx*spacing - ((len(burdens)-1)/2)*spacing for g_idx in range(len(burdens))]\n",
    "    ticks.extend(x)\n",
    "    ticklabels.extend([b.name for b in feature_group_scores])\n",
    "    ax.bar(x,\n",
    "           burdens,\n",
    "           width=width,\n",
    "           color=colors[f_idx],\n",
    "           label=f.name)\n",
    "\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(ticklabels, rotation='vertical')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect fairness would imply equality of burdens between groups within each feature (so the heights of all bars\n",
    "of any given color in the above plot would be equal).  Disparity indicates greater burden for one protected group\n",
    "over another, and a plot such as the above allows us to see where the greater burden falls.  Looking at age for example, we can see that younger applicants have over twice the burden of older applicants, meaning there is a bias\n",
    "against youth in the model.  Note that any such analysis is always with respect to the distribution of input data, so\n",
    "it is possible that this model would not exhibit this bias with a different correlation structure against age.  For this reason it is very important that we always anlayse datasets that are representative of the data on which the model will actually be predicting in deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
