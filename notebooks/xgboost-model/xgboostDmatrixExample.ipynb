{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Cortex Certifai fairness evaluation on xgboost model to predict adult income\n",
    "\n",
    "- Description: Each dataset row represents the attribute values for de-identified individual. The models predict the income bracket of the person as <=50K or >=50K\n",
    "- Dataset Source: UCI [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/census+income)\n",
    "- In the example below we show how to create an xgboost model and evaluate fairness using Cortex Certifai\n",
    "- Example can be worked locally by installing the dependencies listed below\n",
    "- dependencies\n",
    "    - python>=3.6.2,<=3.7\n",
    "    - scikit-learn=0.20.3\n",
    "    - xgboost (`conda install -c conda-forge xgboost`)\n",
    "    - numpy=1.16.2\n",
    "    - pandas\n",
    "    - ipython\n",
    "    - matplotlib\n",
    "    - jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neccessary imports\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special import - \n",
    "# for multiprocessing to work in a Notebook,  pickled classes must be in a separate package or notebook\n",
    "# hence, the model encoder(s),decoder class has to be somewhere other than the current notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('.')))\n",
    "from cat_encoder import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "df = pd.read_csv('adult_income-prepped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate outcome\n",
    "label_column = 'income'\n",
    "y = df[label_column]\n",
    "X_raw = df.drop(label_column, axis=1)\n",
    "\n",
    "# remove some additional non helpful columns\n",
    "rm=[\"fnlwgt\", \"capital-loss\"]\n",
    "dropped_indexes_list = [i for i,col in enumerate(X_raw.columns.to_list()) if col in rm]\n",
    "final_list=X_raw.columns.to_list()\n",
    "for i in rm:   \n",
    "    final_list.remove(i)\n",
    "X = X_raw[final_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test set from the cleaned dataframe(after removing non-useful columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder for categorical columns\n",
    "from cat_encoder import CatEncoder\n",
    "cat_columns = [\n",
    "   'workclass', \n",
    "   'education', \n",
    "   'marital-status', \n",
    "   'occupation', \n",
    "   'relationship',\n",
    "   'race',\n",
    "   'gender',\n",
    "   'native-country'\n",
    "           ]\n",
    "encoder = CatEncoder(cat_columns, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set hyperparams and start model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparams for training xgboost model\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode training data to be used to for model training \n",
    "data_dmatrix = xgb.DMatrix(data=encoder(X_train.values),label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the xgboost model\n",
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcuate model accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8493192752584706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy on test-set. using 0.46 as threshold for scoring\n",
    "threshold = 0.46\n",
    "dtest = xgb.DMatrix(encoder(X_test.values))\n",
    "preds = xg_reg.predict(dtest)\n",
    "best_preds = map(lambda x: int(x > threshold), preds)\n",
    "acc = accuracy_score(y_test, list(best_preds))\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cortex certifai updates required before initiating scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrapping model to create xgboost.Dmatrix obj from numpy arrays for certifai predicts\n",
    "\n",
    "- cortex certifai invokes model (black-box) predicts using numpy-arrays from evaluation dataset provided\n",
    "- since xgboost model requires Dmatrix obj for prediction we create a `TransformedPredict` wrapper class\n",
    "- `TransformedPredict` wrapper creates Dmatrix object before returning calling wrapped model's (here xgboost) predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting override_model_predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile override_model_predict.py\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "class TransformedPredict:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    def predict(self,arr):\n",
    "        dtest = xgb.DMatrix(data=arr)\n",
    "        return self.model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft scoring models additionally need to provide a decoder callable to get outcomes\n",
    "\n",
    "- soft scoring models like xgboost return scores (e.g. probability) that needs to be passed through a threshold filter to get final outcomes\n",
    "- just as we did above to create a threshold to filter binary outcomes for calculating accuracy metrics, we create a `Decoder` class with overridden `__call__` method to add decoding rules for xgboost model scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting decoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile decoder.py\n",
    "import numpy as np\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self,threshold):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        if not isinstance(x, np.ndarray):\n",
    "             x = np.array(x)\n",
    "        return (x > self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to verify model predicts with new wrapper model class == model predicts from raw model\n",
    "from decoder import Decoder\n",
    "from override_model_predict import TransformedPredict\n",
    "decoder = Decoder(threshold)\n",
    "transformed_model = TransformedPredict(xg_reg)\n",
    "assert (decoder(transformed_model.predict(encoder(X_test.values))) == \n",
    "        decoder(xg_reg.predict(xgb.DMatrix(encoder(X_test.values))))).all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using cortex certifai scan api's to set up model scanning\n",
    "\n",
    "- before running below section make sure you have necessary packages for cortex certifai installed\n",
    "- copy the toolkit path to `certifai_toolkit_path` variable and run the below cell to install the required packages to initiate a certifai model scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "certifai_toolkit_path = 'path_to_certifai_toolkit'\n",
    "!find $certifai_toolkit_path/packages/all       -type f ! -name \"*console-*\" ! -name \"*client-*\" | xargs -I % sh -c 'pip install % ' ;\n",
    "!find $certifai_toolkit_path/packages/python3.6 -type f   -name \"*engine-*\"                      | xargs -I % sh -c 'pip install % ' ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.13'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check version of certifai installed\n",
    "from certifai.scanner.version import  get_version\n",
    "get_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for building certifai scan\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a CertifaiPredictiorWrapper object from transformed model created above\n",
    "\n",
    "- this predictiorWrapper object will be used by certifai to perform model predicts as constructor to CertifaiModel\n",
    "- run the assert test below to confirm predictions from raw model and certifaiWrapped model are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_certifai_wrapped_model = CertifaiPredictorWrapper(transformed_model,encoder=encoder,decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to assert wrapped certifai model predicts == raw model predicts\n",
    "assert (xbg_certifai_wrapped_model.model.predict(X_test.values) == \n",
    "        decoder(xg_reg.predict(xgb.DMatrix(encoder(X_test.values))))).all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a certifai evaluation dataset\n",
    "\n",
    "- earlier we modified our dataset to drop certain non useful columns\n",
    "- and we ran our encoder on the cleaned dataset\n",
    "- we will pass the cleaned dataframe (with the removed columns) to certifai for evaluation\n",
    "- this is needed since the dropped columns are non-encoded and are essentially not required by model for predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned dataframe `X_raw[final_list]` or X\n",
    "dataframe_certifai = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-27 17:10:56,860 root   INFO     Validating license...\n",
      "2020-05-27 17:10:56,861 root   INFO     License is valid - expires: n/a\n",
      "2020-05-27 17:10:56,882 root   INFO     Generated unique scan id: 3ff9bc936ff6\n",
      "2020-05-27 17:10:56,884 root   INFO     Validating input data...\n",
      "2020-05-27 17:10:56,885 root   INFO     Creating dataset with id: evaluation\n",
      "2020-05-27 17:10:56,887 root   WARNING  Couldn't find column by label as index: `income`, in df.columns: `Index(['age', 'workclass', 'education', 'educational-num', 'marital-status',\n",
      "       'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n",
      "       'hours-per-week', 'native-country'],\n",
      "      dtype='object')`.\n",
      "2020-05-27 17:10:56,888 root   INFO     Inferring dataset features and applying user overrides\n",
      "2020-05-27 17:10:56,889 root   INFO     Reading configs from: /Users/akumar/.certifai/certifai_config.ini\n",
      "2020-05-27 17:10:56,892 root   INFO     Reading default config (fallback) from: /Users/akumar/miniconda/envs/visa3.7/lib/python3.7/site-packages/certifai/common/utils/default_certifai_config.ini\n",
      "2020-05-27 17:10:56,906 root   INFO     Read config marker: config['default']['marker'] = 0.1\n",
      "2020-05-27 17:10:56,912 root   INFO     Integer-valued feature 'age' inferred to be numeric (sample cardinality 74)\n",
      "2020-05-27 17:10:56,989 root   INFO     Integer-valued feature 'educational-num' inferred to be numeric (sample cardinality 16)\n",
      "2020-05-27 17:10:57,120 root   INFO     Integer-valued feature 'capital-gain' inferred to be numeric (sample cardinality 123)\n",
      "2020-05-27 17:10:57,124 root   INFO     Integer-valued feature 'hours-per-week' inferred to be numeric (sample cardinality 96)\n",
      "2020-05-27 17:10:57,152 root   WARNING  Couldn't find column by label as index: `income`, in df.columns: `Index(['age', 'workclass', 'education', 'educational-num', 'marital-status',\n",
      "       'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n",
      "       'hours-per-week', 'native-country'],\n",
      "      dtype='object')`.\n",
      "2020-05-27 17:10:57,153 root   WARNING  Couldn't find column by label as index: `income`, in df.columns: `Index(['age', 'workclass', 'education', 'educational-num', 'marital-status',\n",
      "       'occupation', 'relationship', 'race', 'gender', 'capital-gain',\n",
      "       'hours-per-week', 'native-country'],\n",
      "      dtype='object')`.\n",
      "2020-05-27 17:10:57,154 root   INFO     Inferring dataset features and applying user overrides\n",
      "2020-05-27 17:10:57,160 root   INFO     Integer-valued feature 'age' inferred to be numeric (sample cardinality 74)\n",
      "2020-05-27 17:10:57,231 root   INFO     Integer-valued feature 'educational-num' inferred to be numeric (sample cardinality 16)\n",
      "2020-05-27 17:10:57,371 root   INFO     Integer-valued feature 'capital-gain' inferred to be numeric (sample cardinality 123)\n",
      "2020-05-27 17:10:57,374 root   INFO     Integer-valued feature 'hours-per-week' inferred to be numeric (sample cardinality 96)\n",
      "2020-05-27 17:10:57,662 root   INFO     Input validation complete\n",
      "2020-05-27 17:10:57,663 root   INFO     Beginning to perform evaluations\n",
      "2020-05-27 17:10:57,664 root   INFO     performing evaluation: fairness, for model: XGB\n",
      "2020-05-27 17:10:57,702 root   INFO     Validating license...\n",
      "2020-05-27 17:10:57,705 root   INFO     License is valid - expires: n/a\n",
      "2020-05-27 17:10:57,707 root   INFO     Running counterfactual analysis for multiclass classification with class structure ClassStructure.PARTITIONED (analysis = Fairness)\n",
      "2020-05-27 17:10:57,709 root   INFO     Hyper-params for experiment: {'tournsize': 3, 'population': 4000, 'indpb': 0.05, 'CXPB': 0.5, 'MUTPB': 0.2, 'generation': 180, 'evolution': 100, 'N_CYCLES': 1, 'early_stopping_delta': 0.0001, 'early_stopping_epochs': 3, 'percent_class_seeding': 5, 'sampling_Z': 1.96, 'sampling_boundary': 0.01, 'sampling_min_n': 100, '2pt_orig_weight': 0.025, 'shrinkage_weight': 0.5, 'annealing_weight': 0.45, 'annealing_rate': 1.25, 'elitism': 0.04, 'dimensional_normalization': True, 'num_counterfactuals': 1}\n",
      "2020-05-27 17:10:57,712 root   INFO     Running without scaler, using identity scaler.\n",
      "2020-05-27 17:11:04,019 root   INFO     Running analysis variant 'prediction more beneficial'\n",
      "2020-05-27 17:11:06,188 root   INFO     Running with explanation reduction ON\n",
      "2020-05-27 17:11:06,189 root   INFO     Total dataset size is 48842\n",
      "2020-05-27 17:11:38,157 root   INFO     Batch run time per generation for instances 0 to 35: 0.06961\n",
      "2020-05-27 17:11:38,158 root   INFO     Current max sampling error 0.3911745762970556 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:11:38,158 root   INFO     Current min non-exhausted protected class samples 6 (min for early stop 100)\n",
      "2020-05-27 17:12:08,012 root   INFO     Batch run time per generation for instances 36 to 72: 0.06630\n",
      "2020-05-27 17:12:08,012 root   INFO     Current max sampling error 0.24290664859038796 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:12:08,013 root   INFO     Current min non-exhausted protected class samples 12 (min for early stop 100)\n",
      "2020-05-27 17:12:39,046 root   INFO     Batch run time per generation for instances 73 to 107: 0.06892\n",
      "2020-05-27 17:12:39,047 root   INFO     Current max sampling error 0.20394316903551682 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:12:39,048 root   INFO     Current min non-exhausted protected class samples 18 (min for early stop 100)\n",
      "2020-05-27 17:13:10,302 root   INFO     Batch run time per generation for instances 108 to 145: 0.06956\n",
      "2020-05-27 17:13:10,303 root   INFO     Current max sampling error 0.20192164172416358 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:13:10,304 root   INFO     Current min non-exhausted protected class samples 25 (min for early stop 100)\n",
      "2020-05-27 17:13:42,965 root   INFO     Batch run time per generation for instances 146 to 183: 0.06916\n",
      "2020-05-27 17:13:42,966 root   INFO     Current max sampling error 0.1596455801972877 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:13:42,967 root   INFO     Current min non-exhausted protected class samples 31 (min for early stop 100)\n",
      "2020-05-27 17:14:17,048 root   INFO     Batch run time per generation for instances 184 to 216: 0.07519\n",
      "2020-05-27 17:14:17,049 root   INFO     Current max sampling error 0.13904764876234305 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:14:17,050 root   INFO     Current min non-exhausted protected class samples 37 (min for early stop 100)\n",
      "2020-05-27 17:14:54,184 root   INFO     Batch run time per generation for instances 217 to 252: 0.08103\n",
      "2020-05-27 17:14:54,185 root   INFO     Current max sampling error 0.1322938905495505 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:14:54,186 root   INFO     Current min non-exhausted protected class samples 43 (min for early stop 100)\n",
      "2020-05-27 17:15:30,797 root   INFO     Batch run time per generation for instances 253 to 291: 0.08372\n",
      "2020-05-27 17:15:30,798 root   INFO     Current max sampling error 0.12623922029480683 (max for early stop 0.005102040816326531)\n",
      "2020-05-27 17:15:30,799 root   INFO     Current min non-exhausted protected class samples 50 (min for early stop 100)\n"
     ]
    }
   ],
   "source": [
    "# Create the scan object from scratch using the ScanBuilder class\n",
    "\n",
    "# First define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='income > 50K', favorable=True),\n",
    "        CertifaiOutcomeValue(0, name='income < 50K')\n",
    "    ]),\n",
    "    prediction_description='Determine whether income greater than 50K or less')\n",
    "\n",
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)\n",
    "\n",
    "# Add our local models\n",
    "first_model = CertifaiModel('XGB',\n",
    "                            local_predictor=xbg_certifai_wrapped_model)\n",
    "scan.add_model(first_model)\n",
    "\n",
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.dataframe(dataframe_certifai))\n",
    "scan.add_dataset(eval_dataset)\n",
    "\n",
    "# Setup an evaluation for fairness on the above dataset using the model\n",
    "# We'll look at disparity between groups defined by marital status and age\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('race'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('gender'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.evaluation_dataset_id = 'evaluation'\n",
    "\n",
    "# Because the dataset contains a ground truth outcome column which the model does not\n",
    "# expect to receive as input we need to state that in the dataset schema (since it cannot\n",
    "# be inferred from the CSV)\n",
    "scan.dataset_schema.outcome_feature_name = 'income'\n",
    "\n",
    "# Run the scan.\n",
    "# By default this will write the results into individual report files (one per model and evaluation\n",
    "# type) in the 'reports' directory relative to the Jupyter root.  This may be disabled by specifying\n",
    "# `write_reports=False` as below\n",
    "# The result is a dictionary of dictionaries of reports.  The top level dict key is the evaluation type\n",
    "# and the second level key is model id.\n",
    "# Reports saved as JSON (which `write_reports=True` will do) may be visualized in the console app\n",
    "result = scan.run(write_reports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
