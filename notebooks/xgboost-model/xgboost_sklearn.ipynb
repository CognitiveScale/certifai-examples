{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020. Cognitive Scale Inc. All rights reserved.\n",
    "Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/7998b8a481fccd467463deb1fc46d19622079b0e/LICENSE.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Cortex Certifai fairness evaluation on xgboost model to predict adult income\n",
    "\n",
    "- Description: Each dataset row represents the attribute values for de-identified individual. The models predict the income bracket of the person as <=50K or >=50K\n",
    "- Dataset Source: UCI [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/census+income)\n",
    "- This example uses an XGBoostClassifier\n",
    "- Example can be worked locally by installing the dependencies listed below\n",
    "- dependencies\n",
    "    - installed Certifai toolkit\n",
    "    - xgboost (`conda install -c conda-forge xgboost`)\n",
    "    - ipython\n",
    "    - matplotlib\n",
    "    - jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# imports for building certifai scan\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe\n",
    "from certifai.common.utils.encoding import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "df = pd.read_csv('adult_income-prepped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate outcome\n",
    "label_column = 'income'\n",
    "y = df[label_column]\n",
    "X_raw = df.drop(label_column, axis=1)\n",
    "\n",
    "# remove some additional non helpful columns\n",
    "# X = X_raw.drop([\"fnlwgt\", \"capital-loss\"], axis=1)\n",
    "rm=[\"fnlwgt\", \"capital-loss\"]\n",
    "dropped_indexes_list = [i for i,col in enumerate(X_raw.columns.to_list()) if col in rm]\n",
    "final_list=X_raw.columns.to_list()\n",
    "for i in rm:   \n",
    "    final_list.remove(i)\n",
    "X = X_raw[final_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test set from the cleaned dataframe(after removing non-useful columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder for categorical columns\n",
    "cat_columns = [\n",
    "   'workclass', \n",
    "   'education', \n",
    "   'marital-status', \n",
    "   'occupation', \n",
    "   'relationship',\n",
    "   'race',\n",
    "   'gender',\n",
    "   'native-country'\n",
    "           ]\n",
    "encoder = CatEncoder(cat_columns, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set hyperparams and start model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode training data to be used to for model training \n",
    "encoded_X_train = encoder(X_train.values)\n",
    "encoded_X_test = encoder(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the xgboost model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(encoded_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcuate model accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8687685535878801"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy on test-set.\n",
    "acc = xgb.score(encoded_X_test, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using cortex certifai scan api's to set up model scanning\n",
    "\n",
    "- before running below section make sure you have necessary packages for cortex certifai installed\n",
    "- copy the toolkit path to `certifai_toolkit_path` variable and run the below cell to install the required packages to initiate a certifai model scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.8'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check version of certifai installed\n",
    "from certifai.scanner.version import  get_version\n",
    "get_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scans with hard predict\n",
    "\n",
    "Setup a scan definition that does not use soft output. Run a preflight and explanations scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_wrapped_model = CertifaiPredictorWrapper(xgb,encoder=encoder)\n",
    "# test to assert wrapped certifai model predicts == raw model predicts\n",
    "assert (xgb_wrapped_model.model.predict(X_test.values) == \n",
    "        \n",
    "        xgb.predict(encoded_X_test)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Preflight Scan\n",
      "[--------------------] 2021-04-19 14:19:28.068847 - 0 of 3 checks (0.0% complete) - Running model nondeterminism preflight check for model XGB\n",
      "[######--------------] 2021-04-19 14:19:28.110753 - 1 of 3 checks (33.33% complete) - Running scan time estimate preflight check for model XGB\n",
      "[#############-------] 2021-04-19 14:20:58.970944 - 2 of 3 checks (66.67% complete) - Running unknown outcome class preflight check for model XGB\n",
      "[####################] 2021-04-19 14:20:58.977491 - 3 of 3 checks (100.0% complete) - Finished all preflight checks for model XGB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'XGB': {'warnings': [],\n",
       "  'messages': ['Passed model non determinism check',\n",
       "   'Expected time for explanation analysis is 17 seconds',\n",
       "   'Model XGB passed time estimation check',\n",
       "   'Passed unknown outcome classes check'],\n",
       "  'errors': []}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scan object from scratch using the ScanBuilder class\n",
    "\n",
    "# First define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='income > 50K', favorable=True),\n",
    "        CertifaiOutcomeValue(0, name='income < 50K')\n",
    "    ]),\n",
    "    prediction_description='Determine whether income greater than 50K or less')\n",
    "\n",
    "scan = CertifaiScanBuilder.create('test_use_case',\n",
    "                                  prediction_task=task)\n",
    "\n",
    "# Add our local models\n",
    "first_model = CertifaiModel('XGB',\n",
    "                            local_predictor=xgb_wrapped_model)\n",
    "scan.add_model(first_model)\n",
    "\n",
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.dataframe(X))\n",
    "scan.add_dataset(eval_dataset)\n",
    "\n",
    "explan_dataset = CertifaiDataset('explanation',\n",
    "                               CertifaiDatasetSource.dataframe(X[:10]))\n",
    "scan.add_dataset(explan_dataset)\n",
    "\n",
    "\n",
    "# Setup an explanation scan\n",
    "scan.add_evaluation_type('explanation')\n",
    "scan.evaluation_dataset_id = 'evaluation'\n",
    "scan.explanation_dataset_id = 'explanation'\n",
    "\n",
    "# Because the dataset contains a ground truth outcome column which the model does not\n",
    "# expect to receive as input we need to state that in the dataset schema (since it cannot\n",
    "# be inferred from the CSV)\n",
    "scan.dataset_schema.outcome_feature_name = 'income'\n",
    "\n",
    "# Run the scan.\n",
    "# By default this will write the results into individual report files (one per model and evaluation\n",
    "# type) in the 'reports' directory relative to the Jupyter root.  This may be disabled by specifying\n",
    "# `write_reports=False` as below\n",
    "# The result is a dictionary of dictionaries of reports.  The top level dict key is the evaluation type\n",
    "# and the second level key is model id.\n",
    "# Reports saved as JSON (which `write_reports=True` will do) may be visualized in the console app\n",
    "scan.run_preflight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scan with model_use_case_id: 'test_use_case' and scan_id: '39e1da7675b5', total estimated time is 1 minutes\n",
      "[--------------------] 2021-04-19 14:20:59.144896 - 0 of 1 reports (0.0% complete) - Running explanation evaluation for model: XGB, estimated time is 17 seconds\n",
      "[####################] 2021-04-19 14:21:10.651839 - 1 of 1 reports (100.0% complete) - Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "result=scan.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run scans using soft output\n",
    "\n",
    "Modify the scan definition to run a scan using soft output. We'll do a preflight test, and then explanations including Shap, which requires soft output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up wrapper with soft outputs\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from sklearn_soft_wrapper import SkLearnSoftWrapper\n",
    "xgb_soft_wrapped_model = CertifaiPredictorWrapper(SkLearnSoftWrapper(xgb),\n",
    "                                    soft_predictions=True,\n",
    "                                    encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------] 2021-04-19 14:21:10.811406 - 0 of 3 checks (0.0% complete) - Starting Preflight Scan\n",
      "[--------------------] 2021-04-19 14:21:10.811527 - 0 of 3 checks (0.0% complete) - Running model nondeterminism preflight check for model SoftXGB\n",
      "[######--------------] 2021-04-19 14:21:10.855993 - 1 of 3 checks (33.33% complete) - Running scan time estimate preflight check for model SoftXGB\n",
      "[#############-------] 2021-04-19 14:22:32.730645 - 2 of 3 checks (66.67% complete) - Running unknown outcome class preflight check for model SoftXGB\n",
      "[####################] 2021-04-19 14:22:32.737630 - 3 of 3 checks (100.0% complete) - Finished all preflight checks for model SoftXGB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SoftXGB': {'warnings': [],\n",
       "  'messages': ['Passed model non determinism check',\n",
       "   'Expected time for explanation analysis is 16 seconds',\n",
       "   'Model SoftXGB passed time estimation check',\n",
       "   'Passed unknown outcome classes check'],\n",
       "  'errors': []}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan2 = CertifaiScanBuilder.create('test_use_case',\n",
    "                                  prediction_task=task)\n",
    "\n",
    "scan2.add_model(CertifaiModel('SoftXGB',\n",
    "                            local_predictor=xgb_soft_wrapped_model))\n",
    "scan2.add_dataset(eval_dataset)\n",
    "scan2.add_dataset(explan_dataset)\n",
    "scan2.add_evaluation_type('explanation')\n",
    "scan2.evaluation_dataset_id = 'evaluation'\n",
    "scan2.explanation_dataset_id = 'explanation'\n",
    "\n",
    "# Add Shap to explanations\n",
    "scan2.add_explanation_type('shap')\n",
    "scan2.run_preflight()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------] 2021-04-19 14:22:32.890377 - 0 of 1 reports (0.0% complete) - Starting scan with model_use_case_id: 'test_use_case' and scan_id: '46e887c03ae5', total estimated time is 1 minutes\n",
      "[--------------------] 2021-04-19 14:22:32.890530 - 0 of 1 reports (0.0% complete) - Running explanation evaluation for model: SoftXGB, estimated time is 16 seconds\n",
      "[####################] 2021-04-19 14:22:50.017508 - 1 of 1 reports (100.0% complete) - Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "result = scan2.run(write_reports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98465240e-01, 1.53476745e-03],\n",
       "       [8.64778340e-01, 1.35221660e-01],\n",
       "       [4.46438372e-01, 5.53561628e-01],\n",
       "       [7.61495471e-01, 2.38504559e-01],\n",
       "       [6.94274902e-04, 9.99305725e-01],\n",
       "       [7.51609027e-01, 2.48390958e-01],\n",
       "       [9.99894857e-01, 1.05137420e-04],\n",
       "       [9.95557725e-01, 4.44229366e-03],\n",
       "       [9.98467922e-01, 1.53206184e-03],\n",
       "       [2.37099528e-02, 9.76290047e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_soft_wrapped_model.model.soft_predict(X[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
