{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020. Cognitive Scale Inc. All rights reserved.\n",
    "Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/7998b8a481fccd467463deb1fc46d19622079b0e/LICENSE.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a scan programmatically with your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we will be demonstrating how to create a scan in Certifai using your own model. We will show some examples of how to use models and datasets to run scans**\n",
    "\n",
    "**Documentation for Certifai can be found at https://cognitivescale.github.io/cortex-certifai/docs/about**\n",
    "\n",
    "**To begin, we will import the libraries required to run Certifai scans via Jupyter Lab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:39.859798Z",
     "iopub.status.busy": "2023-01-09T18:01:39.859458Z",
     "iopub.status.idle": "2023-01-09T18:01:43.520269Z",
     "shell.execute_reply": "2023-01-09T18:01:43.519492Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from copy import copy\n",
    "import yaml\n",
    "\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For multiprocessing to work in a Notebook, we need the encoder to be outside of the notebook. This code imports the encoder from the common library in a way that works in hosted notebooks as well as locally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.523763Z",
     "iopub.status.busy": "2023-01-09T18:01:43.523534Z",
     "iopub.status.idle": "2023-01-09T18:01:43.526736Z",
     "shell.execute_reply": "2023-01-09T18:01:43.526144Z"
    }
   },
   "outputs": [],
   "source": [
    "from certifai.common.utils.encoding import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP (1): Setting up the dataset and model to be scanned\n",
    "\n",
    "**Task 1): Setting up the dataset**\n",
    "\n",
    "**Load the data into a DataFrame for use in both training and later analysing the model. In this example we use the German Credit dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.530426Z",
     "iopub.status.busy": "2023-01-09T18:01:43.529867Z",
     "iopub.status.idle": "2023-01-09T18:01:43.560804Z",
     "shell.execute_reply": "2023-01-09T18:01:43.560140Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkingstatus</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>status</th>\n",
       "      <th>others</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>otherplans</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>job</th>\n",
       "      <th>liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>... &gt;= 200 DM / salary assignments for at leas...</td>\n",
       "      <td>6</td>\n",
       "      <td>critical account/ other credits existing (not ...</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1343</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>.. &gt;= 7 years</td>\n",
       "      <td>1</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>2</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>... &lt; 0 DM</td>\n",
       "      <td>28</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>4006</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>unskilled - resident</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>2284</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>4 &lt;= ... &lt; 7 years</td>\n",
       "      <td>4</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>1533</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>... &lt; 1 year</td>\n",
       "      <td>4</td>\n",
       "      <td>female : divorced/separated/married</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>stores</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>12</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1101</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : married/widowed</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      checkingstatus  duration  \\\n",
       "0  ... >= 200 DM / salary assignments for at leas...         6   \n",
       "1                                         ... < 0 DM        28   \n",
       "2                                no checking account        24   \n",
       "3                                no checking account        24   \n",
       "4                                no checking account        12   \n",
       "\n",
       "                                             history           purpose  \\\n",
       "0  critical account/ other credits existing (not ...         car (new)   \n",
       "1           existing credits paid back duly till now         car (new)   \n",
       "2           existing credits paid back duly till now  radio/television   \n",
       "3           existing credits paid back duly till now  radio/television   \n",
       "4           existing credits paid back duly till now         car (new)   \n",
       "\n",
       "   amount       savings              employ  installment  \\\n",
       "0    1343  ... < 100 DM       .. >= 7 years            1   \n",
       "1    4006  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "2    2284  ... < 100 DM  4 <= ... < 7 years            4   \n",
       "3    1533  ... < 100 DM        ... < 1 year            4   \n",
       "4    1101  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "\n",
       "                                status         others  ...  \\\n",
       "0                        male : single  others - none  ...   \n",
       "1                        male : single  others - none  ...   \n",
       "2                        male : single  others - none  ...   \n",
       "3  female : divorced/separated/married  others - none  ...   \n",
       "4               male : married/widowed  others - none  ...   \n",
       "\n",
       "                           property         age otherplans housing cards  \\\n",
       "0                       real estate  > 25 years       none     own     2   \n",
       "1  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "2  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "3  car or other, not in attribute 6  > 25 years     stores     own     1   \n",
       "4                       real estate  > 25 years       none     own     2   \n",
       "\n",
       "                           job liable  \\\n",
       "0  skilled employee / official      2   \n",
       "1         unskilled - resident      1   \n",
       "2  skilled employee / official      1   \n",
       "3  skilled employee / official      1   \n",
       "4  skilled employee / official      1   \n",
       "\n",
       "                                          telephone        foreign outcome  \n",
       "0                                      phone - none   foreign - no       1  \n",
       "1                                      phone - none  foreign - yes       2  \n",
       "2  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "3  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "4  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_file = \"datasets/german_credit_eval.csv\"\n",
    "df = pd.read_csv(all_data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2): Set the categorical columns of the dataset up for the encoder (in our case we will encapsulate this in the CatEncoder class, which may be found in the same directory as this notebook). We also note the column that contains the ground truth labels for training in 'label_column' (in this dataset this is 'outcome').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.596854Z",
     "iopub.status.busy": "2023-01-09T18:01:43.596357Z",
     "iopub.status.idle": "2023-01-09T18:01:43.600625Z",
     "shell.execute_reply": "2023-01-09T18:01:43.600029Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "label_column = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In our example we use a simple logistic classifier from sklearn. This is where you can add your own model. Rather than using the one provided, you can import and set up your model to be used here.**\n",
    "\n",
    "**Note that the predictor must be picklable.  Specifically if the predictor class itself is defined in a notebook rather than an imported module then it *must* be in a different notebook file for Python muti-processing to handle it correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Because the outcome column won't be presented to the model at prediction time we need to drop it from the dataset. We then split into a test and train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.603864Z",
     "iopub.status.busy": "2023-01-09T18:01:43.603504Z",
     "iopub.status.idle": "2023-01-09T18:01:43.608927Z",
     "shell.execute_reply": "2023-01-09T18:01:43.608399Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[label_column]\n",
    "X = df.drop(label_column, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Set the encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.612288Z",
     "iopub.status.busy": "2023-01-09T18:01:43.612083Z",
     "iopub.status.idle": "2023-01-09T18:01:43.619686Z",
     "shell.execute_reply": "2023-01-09T18:01:43.619113Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = CatEncoder(cat_columns, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Fit the classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.622876Z",
     "iopub.status.busy": "2023-01-09T18:01:43.622672Z",
     "iopub.status.idle": "2023-01-09T18:01:43.801883Z",
     "shell.execute_reply": "2023-01-09T18:01:43.801295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic classifier' accuracy is 0.77\n"
     ]
    }
   ],
   "source": [
    "def build_model(data, name, test=None):\n",
    "    if test is None:\n",
    "        test = data\n",
    "        \n",
    "\n",
    "    parameters = {'C': (0.5, 1.0, 2.0), 'solver': ['lbfgs'], 'max_iter': [1000]}\n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(data[0], data[1])\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(test[0], test[1].values)\n",
    "    print(f\"Model '{name}' accuracy is {accuracy}\")\n",
    "    return model\n",
    "\n",
    "logistic_model = build_model((encoder(X_train.values), y_train),\n",
    "                        'Logistic classifier',\n",
    "                        test=(encoder(X_test.values), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Wrap up the model and the encoder so that Certifai sees it as part of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.805071Z",
     "iopub.status.busy": "2023-01-09T18:01:43.804893Z",
     "iopub.status.idle": "2023-01-09T18:01:43.808254Z",
     "shell.execute_reply": "2023-01-09T18:01:43.807558Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic_model_proxy = CertifaiPredictorWrapper(logistic_model, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Compute model's accuracy with the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.811834Z",
     "iopub.status.busy": "2023-01-09T18:01:43.811603Z",
     "iopub.status.idle": "2023-01-09T18:01:43.817904Z",
     "shell.execute_reply": "2023-01-09T18:01:43.817294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier model accuracy on test data is 0.77\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = logistic_model.score(encoder(X_test.values), y_test.values)\n",
    "print(f\"Logistic classifier model accuracy on test data is {logistic_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (2) Create the scan object using the ScanBuilder class\n",
    "\n",
    "**To allow easy working with Certifai from notebooks, or other programmatic use cases, the `ScanBuilder` class abstracts the scan definition and provides an object model to manipulate it.  Building up a definition in this way allows either direct running of the scan in the notebook, or export as a scan definition file, which can be run by the Certifai scanner.**\n",
    "\n",
    "**Task 1) Define the outcomes of the classification task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.821015Z",
     "iopub.status.busy": "2023-01-09T18:01:43.820836Z",
     "iopub.status.idle": "2023-01-09T18:01:43.824294Z",
     "shell.execute_reply": "2023-01-09T18:01:43.823608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Create the Certifai scan object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.827631Z",
     "iopub.status.busy": "2023-01-09T18:01:43.827419Z",
     "iopub.status.idle": "2023-01-09T18:01:43.831116Z",
     "shell.execute_reply": "2023-01-09T18:01:43.830328Z"
    }
   },
   "outputs": [],
   "source": [
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Create the Certifai dataset from the local dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.834151Z",
     "iopub.status.busy": "2023-01-09T18:01:43.833974Z",
     "iopub.status.idle": "2023-01-09T18:01:43.836931Z",
     "shell.execute_reply": "2023-01-09T18:01:43.836346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv(all_data_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Create the Certifai model from the local model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.839951Z",
     "iopub.status.busy": "2023-01-09T18:01:43.839768Z",
     "iopub.status.idle": "2023-01-09T18:01:43.843144Z",
     "shell.execute_reply": "2023-01-09T18:01:43.842522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add our local model\n",
    "first_model = CertifaiModel('logistic_regression',\n",
    "                            local_predictor=logistic_model_proxy)\n",
    "scan.add_model(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Setup an evaluation for fairness, robustness, and explainability on the above dataset using the model**\n",
    "\n",
    "**We can have one or many of the following analysis types:**\n",
    "- fairness\n",
    "- robustness\n",
    "- explainability\n",
    "- explanation\n",
    "- performance\n",
    "\n",
    "**More information on these analyses can be found at our docs: https://cognitivescale.github.io/cortex-certifai/docs/information/factors/fairness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.846342Z",
     "iopub.status.busy": "2023-01-09T18:01:43.846165Z",
     "iopub.status.idle": "2023-01-09T18:01:43.849701Z",
     "shell.execute_reply": "2023-01-09T18:01:43.849106Z"
    }
   },
   "outputs": [],
   "source": [
    "scan.add_dataset(eval_dataset)\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.add_evaluation_type('explainability')\n",
    "scan.add_evaluation_type('robustness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Because the dataset contains a ground truth outcome column which the model does not expect to receive as input we need to state that in the dataset schema (since it cannot be inferred from the CSV) so that the scan can be rerun from the definition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.852920Z",
     "iopub.status.busy": "2023-01-09T18:01:43.852739Z",
     "iopub.status.idle": "2023-01-09T18:01:43.855743Z",
     "shell.execute_reply": "2023-01-09T18:01:43.855064Z"
    }
   },
   "outputs": [],
   "source": [
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Run the scan. \n",
    "    By default this will write the results into individual report files (one per model and evaluation\n",
    "    type) in the 'reports' directory relative to the notebook.  This may be disabled by specifying\n",
    "    `write_reports=False` as below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:01:43.858828Z",
     "iopub.status.busy": "2023-01-09T18:01:43.858653Z",
     "iopub.status.idle": "2023-01-09T18:06:14.744839Z",
     "shell.execute_reply": "2023-01-09T18:06:14.744209Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 12:01:43,917 root   WARNING  Insufficient examples of some fairness classes to guarantee convergence (smallest included class size is for status='male : divorced/separated' with 50 samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scan with model_use_case_id: 'test_user_case' and scan_id: '5924c1cd0855'\n",
      "[--------------------] 2023-01-09 12:01:43.907821 - 0 of 4 reports (0.0% complete) - Running fairness evaluation for model: logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 12:02:16,452 root   WARNING  Examples of protected class ('status', 'male : divorced/separated') exhausted before convergence after 50 samples\n",
      "2023-01-09 12:02:41,977 root   WARNING  Examples of protected class ('status', 'male : married/widowed') exhausted before convergence after 92 samples\n",
      "2023-01-09 12:02:57,607 root   WARNING  Examples of protected class ('age', '<= 25 years') exhausted before convergence after 190 samples\n",
      "2023-01-09 12:03:29,168 root   WARNING  Examples of protected class ('status', 'female : divorced/separated/married') exhausted before convergence after 310 samples\n",
      "2023-01-09 12:03:33,063 root   WARNING  Examples of protected class ('age', '> 25 years') exhausted before convergence after 810 samples\n",
      "2023-01-09 12:03:33,064 root   WARNING  Examples of protected class ('status', 'male : single') exhausted before convergence after 548 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#####---------------] 2023-01-09 12:03:51.988622 - 1 of 4 reports (25.0% complete) - Running explainability evaluation for model: logistic_regression\n",
      "[##########----------] 2023-01-09 12:05:06.843828 - 2 of 4 reports (50.0% complete) - Running robustness evaluation for model: logistic_regression\n",
      "[###############-----] 2023-01-09 12:06:14.739678 - 3 of 4 reports (75.0% complete) - Running atx evaluation for model: logistic_regression\n",
      "[####################] 2023-01-09 12:06:14.742022 - 4 of 4 reports (100.0% complete) - Completed all evaluations\n"
     ]
    }
   ],
   "source": [
    "#Run the Scan\n",
    "result = scan.run(write_reports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result is a dictionary keyed on analysis, containing reports keyed on model id (in our case 'local')**\n",
    "\n",
    "**We will be extracting the score information in the form of a DataFrame from this dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:06:14.748003Z",
     "iopub.status.busy": "2023-01-09T18:06:14.747800Z",
     "iopub.status.idle": "2023-01-09T18:06:14.775501Z",
     "shell.execute_reply": "2023-01-09T18:06:14.774893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>fairness</th>\n",
       "      <th>Feature (age)</th>\n",
       "      <th>type in Feature (age)</th>\n",
       "      <th>Group details (&lt;= 25 years)</th>\n",
       "      <th>type in Feature (age)</th>\n",
       "      <th>Group details (&gt; 25 years)</th>\n",
       "      <th>Feature (status)</th>\n",
       "      <th>type in Feature (status)</th>\n",
       "      <th>Group details (female : divorced/separated/married)</th>\n",
       "      <th>type in Feature (status)</th>\n",
       "      <th>Group details (male : divorced/separated)</th>\n",
       "      <th>type in Feature (status)</th>\n",
       "      <th>Group details (male : married/widowed)</th>\n",
       "      <th>type in Feature (status)</th>\n",
       "      <th>Group details (male : single)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression (burden)</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>burden</td>\n",
       "      <td>68.744011</td>\n",
       "      <td>68.744011</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.081351</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.042567</td>\n",
       "      <td>72.706751</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.074222</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.074287</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>burden</td>\n",
       "      <td>0.036696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          context    type   fairness  \\\n",
       "logistic_regression (burden)  logistic_regression  burden  68.744011   \n",
       "\n",
       "                              Feature (age) type in Feature (age)  \\\n",
       "logistic_regression (burden)      68.744011                burden   \n",
       "\n",
       "                              Group details (<= 25 years)  \\\n",
       "logistic_regression (burden)                     0.081351   \n",
       "\n",
       "                             type in Feature (age)  \\\n",
       "logistic_regression (burden)                burden   \n",
       "\n",
       "                              Group details (> 25 years)  Feature (status)  \\\n",
       "logistic_regression (burden)                    0.042567         72.706751   \n",
       "\n",
       "                             type in Feature (status)  \\\n",
       "logistic_regression (burden)                   burden   \n",
       "\n",
       "                              Group details (female : divorced/separated/married)  \\\n",
       "logistic_regression (burden)                                           0.074222     \n",
       "\n",
       "                             type in Feature (status)  \\\n",
       "logistic_regression (burden)                   burden   \n",
       "\n",
       "                              Group details (male : divorced/separated)  \\\n",
       "logistic_regression (burden)                                   0.074287   \n",
       "\n",
       "                             type in Feature (status)  \\\n",
       "logistic_regression (burden)                   burden   \n",
       "\n",
       "                              Group details (male : married/widowed)  \\\n",
       "logistic_regression (burden)                                0.032653   \n",
       "\n",
       "                             type in Feature (status)  \\\n",
       "logistic_regression (burden)                   burden   \n",
       "\n",
       "                              Group details (male : single)  \n",
       "logistic_regression (burden)                       0.036696  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>robustness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>86.935109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 context  robustness\n",
       "logistic_regression  logistic_regression   86.935109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>explainability</th>\n",
       "      <th>Num features (1)</th>\n",
       "      <th>Num features (10)</th>\n",
       "      <th>Num features (2)</th>\n",
       "      <th>Num features (3)</th>\n",
       "      <th>Num features (4)</th>\n",
       "      <th>Num features (5)</th>\n",
       "      <th>Num features (6)</th>\n",
       "      <th>Num features (7)</th>\n",
       "      <th>Num features (8)</th>\n",
       "      <th>Num features (9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>91.132812</td>\n",
       "      <td>47.65625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>10.15625</td>\n",
       "      <td>3.90625</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 context  explainability  Num features (1)  \\\n",
       "logistic_regression  logistic_regression       91.132812          47.65625   \n",
       "\n",
       "                     Num features (10)  Num features (2)  Num features (3)  \\\n",
       "logistic_regression                0.0              37.5          10.15625   \n",
       "\n",
       "                     Num features (4)  Num features (5)  Num features (6)  \\\n",
       "logistic_regression           3.90625           0.78125               0.0   \n",
       "\n",
       "                     Num features (7)  Num features (8)  Num features (9)  \n",
       "logistic_regression               0.0               0.0               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = construct_scores_dataframe(scores('fairness', result), include_confidence=False)\n",
    "display(df)\n",
    "\n",
    "df = construct_scores_dataframe(scores('robustness', result), include_confidence=False)\n",
    "display(df)\n",
    "\n",
    "df = construct_scores_dataframe(scores('explainability', result), include_confidence=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (3) Creating the exportable scan object\n",
    "**Task 1) Next we'll make modify the scan definition to make it suitable for running against a version of the model deployed as a web service, and export this scan definition as a YAML file. We show how to  deploy the model as a web service and scan it using this scan definition file and the Certifai command line interface in Part 2 of this tutorial.**\n",
    "\n",
    "**The two things that need to be changed are:**\n",
    "- *predict_endpoint*: Since the model will be running in a web service, we need to provide the URL for its intended predict endpoint\n",
    "- *dataset url*: Similarly, since the data will be read from persistent storage rather than an already populated DataFrame, we'll need to modify the data source accordingly. If the URL is a relative file path, it will be interpreted relative to where the scan definition is stored.\n",
    "\n",
    "**Note that we could simply export the definition we have already, and add these fields to the resulting YAML (or have the deploying engineer do so), but it's a bit friendlier if we create placeholders that can be replaced later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:06:14.778446Z",
     "iopub.status.busy": "2023-01-09T18:06:14.778267Z",
     "iopub.status.idle": "2023-01-09T18:06:14.781618Z",
     "shell.execute_reply": "2023-01-09T18:06:14.781017Z"
    }
   },
   "outputs": [],
   "source": [
    "scan.models[0].predict_endpoint = 'http://mymodel/predict'\n",
    "scan.datasets[0].source = CertifaiDatasetSource.csv('somefile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scan object contains the scan definition, which consists of all of the metadata needed to rerun the scan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Viewing the scan definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:06:14.784689Z",
     "iopub.status.busy": "2023-01-09T18:06:14.784496Z",
     "iopub.status.idle": "2023-01-09T18:06:14.797607Z",
     "shell.execute_reply": "2023-01-09T18:06:14.796932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation:\n",
      "  evaluation_dataset_id: evaluation\n",
      "  evaluation_types:\n",
      "  - fairness\n",
      "  - explainability\n",
      "  - robustness\n",
      "  fairness_grouping_features:\n",
      "  - name: age\n",
      "  - name: status\n",
      "  prediction_values:\n",
      "  - name: Loan granted\n",
      "    value: 1\n",
      "    favorable: true\n",
      "  - name: Loan denied\n",
      "    value: 2\n",
      "    favorable: false\n",
      "  prediction_favorability: explicit\n",
      "  name: test_user_case\n",
      "  prediction_description: Determine whether a loan should be granted\n",
      "model_use_case:\n",
      "  name: test_user_case\n",
      "  model_use_case_id: test_user_case\n",
      "  task_type: binary-classification\n",
      "dataset_schema:\n",
      "  outcome_column: outcome\n",
      "datasets:\n",
      "- dataset_id: evaluation\n",
      "  url: somefile.csv\n",
      "  has_header: true\n",
      "  file_type: csv\n",
      "  delimiter: ','\n",
      "  quote_character: '\"'\n",
      "models:\n",
      "- model_id: logistic_regression\n",
      "  name: logistic_regression\n",
      "  predict_endpoint: http://mymodel/predict\n",
      "  prediction_value_order:\n",
      "  - 1\n",
      "  - 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scan.extract_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Save the Scan Definition locally.**\n",
    "\n",
    "**Save the scan definition to a file. The file path is relative to the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T18:06:14.801480Z",
     "iopub.status.busy": "2023-01-09T18:06:14.801243Z",
     "iopub.status.idle": "2023-01-09T18:06:14.815968Z",
     "shell.execute_reply": "2023-01-09T18:06:14.815112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved template to: ./scan_definition.yaml\n"
     ]
    }
   ],
   "source": [
    "scan_file=\"./scan_definition.yaml\"\n",
    "with open(scan_file, \"w\") as f:\n",
    "    scan.save(f)\n",
    "    print(f\"Saved template to: {scan_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will see how to use this definition to kickstart scans in the CLI in part 2 of this tutorial.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
