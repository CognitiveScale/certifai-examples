{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020. Cognitive Scale Inc. All rights reserved.\n",
    "Licensed under CognitiveScale Example Code [License](https://github.com/CognitiveScale/cortex-certifai-examples/blob/7998b8a481fccd467463deb1fc46d19622079b0e/LICENSE.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a remote scan programmatically with your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we will be demonstrating how to create a remote scan using Certifai Enterprise instance. We will show some examples of how to use models and datasets to run scans**\n",
    "\n",
    "**Documentation for Certifai can be found at https://cognitivescale.github.io/cortex-certifai/docs/about**\n",
    "\n",
    "**To begin, we will import the libraries required to run Certifai scans via Jupyter Lab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1628245140901
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from copy import copy\n",
    "import yaml\n",
    "\n",
    "from certifai.scanner.builder import (CertifaiScanBuilder, CertifaiPredictorWrapper, CertifaiModel, CertifaiModelMetric,\n",
    "                                      CertifaiDataset, CertifaiGroupingFeature, CertifaiDatasetSource,\n",
    "                                      CertifaiPredictionTask, CertifaiTaskOutcomes, CertifaiOutcomeValue)\n",
    "from certifai.scanner.report_utils import scores, construct_scores_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For multiprocessing to work in a Notebook, we need the encoder to be outside of the notebook. This code imports the encoder from the common library in a way that works in hosted notebooks as well as locally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1628245143614
    }
   },
   "outputs": [],
   "source": [
    "from certifai.common.utils.encoding import CatEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP (1): Setting up the dataset and model to be scanned\n",
    "\n",
    "**Task 1): Setting up the dataset**\n",
    "\n",
    "**Load the data into a DataFrame for use in both training and later analysing the model. In this example we use the German Credit dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1628245145756
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkingstatus</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>status</th>\n",
       "      <th>others</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>otherplans</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>job</th>\n",
       "      <th>liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>... &gt;= 200 DM / salary assignments for at leas...</td>\n",
       "      <td>6</td>\n",
       "      <td>critical account/ other credits existing (not ...</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1343</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>.. &gt;= 7 years</td>\n",
       "      <td>1</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>2</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>... &lt; 0 DM</td>\n",
       "      <td>28</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>4006</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>unskilled - resident</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - none</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>2284</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>4 &lt;= ... &lt; 7 years</td>\n",
       "      <td>4</td>\n",
       "      <td>male : single</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>24</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>1533</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>... &lt; 1 year</td>\n",
       "      <td>4</td>\n",
       "      <td>female : divorced/separated/married</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>car or other, not in attribute 6</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>stores</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no checking account</td>\n",
       "      <td>12</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>1101</td>\n",
       "      <td>... &lt; 100 DM</td>\n",
       "      <td>1 &lt;= ... &lt; 4 years</td>\n",
       "      <td>3</td>\n",
       "      <td>male : married/widowed</td>\n",
       "      <td>others - none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>&gt; 25 years</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee / official</td>\n",
       "      <td>1</td>\n",
       "      <td>phone - yes, registered under the customers name</td>\n",
       "      <td>foreign - yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      checkingstatus  duration  \\\n",
       "0  ... >= 200 DM / salary assignments for at leas...         6   \n",
       "1                                         ... < 0 DM        28   \n",
       "2                                no checking account        24   \n",
       "3                                no checking account        24   \n",
       "4                                no checking account        12   \n",
       "\n",
       "                                             history           purpose  \\\n",
       "0  critical account/ other credits existing (not ...         car (new)   \n",
       "1           existing credits paid back duly till now         car (new)   \n",
       "2           existing credits paid back duly till now  radio/television   \n",
       "3           existing credits paid back duly till now  radio/television   \n",
       "4           existing credits paid back duly till now         car (new)   \n",
       "\n",
       "   amount       savings              employ  installment  \\\n",
       "0    1343  ... < 100 DM       .. >= 7 years            1   \n",
       "1    4006  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "2    2284  ... < 100 DM  4 <= ... < 7 years            4   \n",
       "3    1533  ... < 100 DM        ... < 1 year            4   \n",
       "4    1101  ... < 100 DM  1 <= ... < 4 years            3   \n",
       "\n",
       "                                status         others   ...    \\\n",
       "0                        male : single  others - none   ...     \n",
       "1                        male : single  others - none   ...     \n",
       "2                        male : single  others - none   ...     \n",
       "3  female : divorced/separated/married  others - none   ...     \n",
       "4               male : married/widowed  others - none   ...     \n",
       "\n",
       "                           property         age otherplans housing cards  \\\n",
       "0                       real estate  > 25 years       none     own     2   \n",
       "1  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "2  car or other, not in attribute 6  > 25 years       none     own     1   \n",
       "3  car or other, not in attribute 6  > 25 years     stores     own     1   \n",
       "4                       real estate  > 25 years       none     own     2   \n",
       "\n",
       "                           job liable  \\\n",
       "0  skilled employee / official      2   \n",
       "1         unskilled - resident      1   \n",
       "2  skilled employee / official      1   \n",
       "3  skilled employee / official      1   \n",
       "4  skilled employee / official      1   \n",
       "\n",
       "                                          telephone        foreign outcome  \n",
       "0                                      phone - none   foreign - no       1  \n",
       "1                                      phone - none  foreign - yes       2  \n",
       "2  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "3  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "4  phone - yes, registered under the customers name  foreign - yes       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_data_file = \"datasets/german_credit_eval.csv\"\n",
    "df = pd.read_csv(all_data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2): Set the categorical columns of the dataset up for the encoder (in our case we will encapsulate this in the CatEncoder class, which may be found in the same directory as this notebook). We also note the column that contains the ground truth labels for training in 'label_column' (in this dataset this is 'outcome').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1628245150832
    }
   },
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'checkingstatus',\n",
    "    'history',\n",
    "    'purpose',\n",
    "    'savings',\n",
    "    'employ',\n",
    "    'status',\n",
    "    'others',\n",
    "    'property',\n",
    "    'age',\n",
    "    'otherplans',\n",
    "    'housing',\n",
    "    'job',\n",
    "    'telephone',\n",
    "    'foreign'\n",
    "    ]\n",
    "\n",
    "label_column = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In our example we use a simple logistic classifier from sklearn. This is where you can add your own model. Rather than using the one provided, you can import and set up your model to be used here.**\n",
    "\n",
    "**Note that the predictor must be picklable.  Specifically if the predictor class itself is defined in a notebook rather than an imported module then it *must* be in a different notebook file for Python muti-processing to handle it correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Because the outcome column won't be presented to the model at prediction time we need to drop it from the dataset. We then split into a test and train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1628245155869
    }
   },
   "outputs": [],
   "source": [
    "y = df[label_column]\n",
    "X = df.drop(label_column, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Set the encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1628245157947
    }
   },
   "outputs": [],
   "source": [
    "encoder = CatEncoder(cat_columns, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Fit the classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1628245161394
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic classifier' accuracy is 0.77\n"
     ]
    }
   ],
   "source": [
    "def build_model(data, name, test=None):\n",
    "    if test is None:\n",
    "        test = data\n",
    "        \n",
    "\n",
    "    parameters = {'C': (0.5, 1.0, 2.0), 'solver': ['lbfgs'], 'max_iter': [1000]}\n",
    "    m = LogisticRegression()\n",
    "    model = GridSearchCV(m, parameters, cv=3)\n",
    "    model.fit(data[0], data[1])\n",
    "\n",
    "    # Assess on the test data\n",
    "    accuracy = model.score(test[0], test[1].values)\n",
    "    print(f\"Model '{name}' accuracy is {accuracy}\")\n",
    "    return model\n",
    "\n",
    "logistic_model = build_model((encoder(X_train.values), y_train),\n",
    "                        'Logistic classifier',\n",
    "                        test=(encoder(X_test.values), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Wrap up the model and the encoder so that Certifai sees it as part of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1628245163553
    }
   },
   "outputs": [],
   "source": [
    "logistic_model_proxy = CertifaiPredictorWrapper(logistic_model, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7) Compute model's accuracy with the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1628245165686
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier model accuracy on test data is 0.77\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = logistic_model.score(encoder(X_test.values), y_test.values)\n",
    "print(f\"Logistic classifier model accuracy on test data is {logistic_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (2) Create the scan object using the ScanBuilder class\n",
    "\n",
    "**To allow easy working with Certifai from notebooks, or other programmatic use cases, the `ScanBuilder` class abstracts the scan definition and provides an object model to manipulate it.  Building up a definition in this way allows either direct running of the scan in the notebook, or export as a scan definition file, which can be run by the Certifai scanner.**\n",
    "\n",
    "**Task 1) Define the outcomes of the classification task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1628245170216
    }
   },
   "outputs": [],
   "source": [
    "# Define the possible prediction outcomes\n",
    "task = CertifaiPredictionTask(CertifaiTaskOutcomes.classification(\n",
    "    [\n",
    "        CertifaiOutcomeValue(1, name='Loan granted', favorable=True),\n",
    "        CertifaiOutcomeValue(2, name='Loan denied')\n",
    "    ]),\n",
    "    prediction_description='Determine whether a loan should be granted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Create the Certifai scan object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1628246839314
    }
   },
   "outputs": [],
   "source": [
    "scan = CertifaiScanBuilder.create('test_user_case',\n",
    "                                  prediction_task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Create the Certifai dataset from the local dataset**\n",
    "\n",
    "**Overwrite to the path to your cloud storage dataset path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1628244052044
    }
   },
   "outputs": [],
   "source": [
    "# Add the eval dataset\n",
    "eval_dataset = CertifaiDataset('evaluation',\n",
    "                               CertifaiDatasetSource.csv('abfs://{path to your dataset}'))\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4) Create the Certifai model from the local model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1628243909996
    }
   },
   "outputs": [],
   "source": [
    "# Add our local model\n",
    "first_model = CertifaiModel('logistic_regression',\n",
    "                            local_predictor=logistic_model_proxy)\n",
    "scan.add_model(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5) Setup an evaluation for fairness, robustness, and explainability on the above dataset using the model**\n",
    "\n",
    "**We can have one or many of the following analysis types:**\n",
    "- fairness\n",
    "- robustness\n",
    "- explainability\n",
    "- explanation\n",
    "- performance\n",
    "\n",
    "**More information on these analyses can be found at our docs: https://cognitivescale.github.io/cortex-certifai/docs/information/factors/fairness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1628243913304
    }
   },
   "outputs": [],
   "source": [
    "scan.add_dataset(eval_dataset)\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('age'))\n",
    "scan.add_fairness_grouping_feature(CertifaiGroupingFeature('status'))\n",
    "scan.add_evaluation_type('fairness')\n",
    "scan.add_evaluation_type('explainability')\n",
    "scan.add_evaluation_type('robustness')\n",
    "scan.evaluation_dataset_id = 'evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6) Because the dataset contains a ground truth outcome column which the model does not expect to receive as input we need to state that in the dataset schema (since it cannot be inferred from the CSV) so that the scan can be rerun from the definition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1628243915111
    }
   },
   "outputs": [],
   "source": [
    "scan.dataset_schema.outcome_feature_name = 'outcome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result is a dictionary keyed on analysis, containing reports keyed on model id (in our case 'local')**\n",
    "\n",
    "**We will be extracting the score information in the form of a DataFrame from this dictionary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (3) Creating the exportable scan object\n",
    "**Task 1) Next we'll make modify the scan definition to make it suitable for running against a version of the model deployed as a web service, and export this scan definition as a YAML file. We show how to  deploy the model as a web service and scan it using Certifai remote scan functionality.**\n",
    "\n",
    "**The two things that need to be changed are:**\n",
    "- *predict_endpoint*: Since the model will be running in a web service, we need to provide the URL for its intended predict endpoint.\n",
    "- *dataset url*: Similarly, since the data will be read from persistent storage rather than an already populated DataFrame, we'll need to modify the data source accordingly. If the URL is a relative file path, it will be interpreted relative to where the scan definition is stored.\n",
    "\n",
    "**Note that we could simply export the definition we have already, and add these fields to the resulting YAML (or have the deploying engineer do so), but it's a bit friendlier if we create placeholders that can be replaced later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1628243918205
    }
   },
   "outputs": [],
   "source": [
    "scan.models[0].predict_endpoint = '{add_the_url_for_the_model_endpoint}'\n",
    "scan.datasets[0].source = CertifaiDatasetSource.csv('add_the_storage_path_to_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scan object contains the scan definition, which consists of all of the metadata needed to rerun the scan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Viewing the scan definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1628245185420
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_use_case:\n",
      "  name: test_user_case\n",
      "  model_use_case_id: test_user_case\n",
      "  task_type: binary-classification\n",
      "evaluation:\n",
      "  evaluation_dataset_id: evaluation\n",
      "  evaluation_types:\n",
      "  - fairness\n",
      "  - explainability\n",
      "  - robustness\n",
      "  fairness_grouping_features:\n",
      "  - name: age\n",
      "  - name: status\n",
      "  prediction_values:\n",
      "  - name: Loan granted\n",
      "    value: 1\n",
      "    favorable: true\n",
      "  - name: Loan denied\n",
      "    value: 2\n",
      "    favorable: false\n",
      "  prediction_favorability: explicit\n",
      "  name: test_user_case\n",
      "  prediction_description: Determine whether a loan should be granted\n",
      "dataset_schema:\n",
      "  outcome_column: outcome\n",
      "datasets:\n",
      "- dataset_id: evaluation\n",
      "  url: abfs://certifai-testing/definitions/scan_definition.yaml\n",
      "  has_header: true\n",
      "  file_type: csv\n",
      "  delimiter: ','\n",
      "  quote_character: '\"'\n",
      "models:\n",
      "- model_id: logistic_regression\n",
      "  name: logistic_regression\n",
      "  predict_endpoint: http://mymodel/predict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scan.extract_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3) Save the Scan Definition locally.**\n",
    "\n",
    "**Save the scan definition to a file. The file path is relative to the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "gather": {
     "logged": 1628243932506
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved template to: ./scan_definition.yaml\n"
     ]
    }
   ],
   "source": [
    "scan_file=\"./scan_definition.yaml\"\n",
    "with open(scan_file, \"w\") as f:\n",
    "    scan.save(f)\n",
    "    print(f\"Saved template to: {scan_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step (4) Use Certifai Remote Scan for this saved definition file\n",
    "**Task 1) Create a remote config using the kubeconfig.json file and the alias**\n",
    "\n",
    "**The two things that need to be changed are:**\n",
    "- *file*: In order to run remote scan jobs use the certifai-kubeconfig.json file that is downloaded during the Certifai Enterprise setup.\n",
    "- *remote_alias*: Alias name to retrieve the Certifai remote config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1628246584611
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for access to Kubernetes cluster with context - certifai-pro\n",
      "Connection to cluster succeeded, found API - v1\n",
      "Updating alias - gke\n",
      "Configuration updated from - ~/.kube/config\n"
     ]
    }
   ],
   "source": [
    "from certifai.client.remote import remote_config, remote_list\n",
    "\n",
    "class Options:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "remote_alias = '' #Add name for the alias\n",
    "pro_kubeconf_locn = '' # Enter the path for'certifai-kubeconfig.json'\n",
    "\n",
    "args = Options(file=pro_kubeconf_locn,  \n",
    "                alias=remote_alias,\n",
    "                context='current-context',\n",
    "                namespace='certifai',\n",
    "                timeout=15)\n",
    "\n",
    "r_conf = remote_config.remote_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2) Run a remote scan using the scan definition file that we have created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "gather": {
     "logged": 1628246587187
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created certifai scan ID aa15ea4f59c8\n"
     ]
    }
   ],
   "source": [
    "from certifai.client.remote.remote_scan import remote_scan\n",
    "scan_file = \"scan_definition.yaml\"\n",
    "list_args = Options(alias=remote_alias, definition_file=scan_file, config=[], cpu_req=None, details=False, dry_run=False, info=False, mem_req=None, model=None, model_id_tags=None, output=None, parallel=0, preflight=False, report=None)\n",
    "remote_scan(parsed_args=list_args, args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View a list of remote scans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "gather": {
     "logged": 1628247347399
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan ID        Total Reports   Completed Reports   Failed Reports   Active Reports   Progress   State      Scan Duration   \n",
      "aa15ea4f59c8   4               0                   0                4                0          Scanning   --Scanning--    \n",
      "cc952eac92cc   4               4                   0                0                100        Complete   26m41s          \n",
      "087ce699130c   4               4                   0                0                100        Complete   27m36s          \n",
      "414f6de83270   4               4                   0                0                100        Complete   26m38s          \n",
      "69df92ca9b87   4               4                   0                0                100        Complete   23m16s          \n"
     ]
    }
   ],
   "source": [
    "from certifai.client.remote import remote_list\n",
    "model_use_case=None # you can search scans for specific usecases\n",
    "output = 'table' #json or table\n",
    "list_args = Options(alias=remote_alias, model_use_case=model_use_case, output=output)\n",
    "remote_list.remote_list(list_args)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
